{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# خلف الكواليس (باستخدام بايتورتش)\n",
        "\n",
        "قم بتثبيت مكتبات\n",
        "\n",
        "transformers, datasets, evaluate\n",
        "\n",
        "لتشغيل هذا الدفتر."
      ],
      "metadata": {
        "id": "ZwjM7JIeB9CA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVzGc8qqBzDM"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentimentAnalysisModelName = 'MaagDeveloper/CAMeL-Lab-arabic-sentiment-analysis'\n",
        "classifier = pipeline(\"sentiment-analysis\", model=sentimentAnalysisModelName)\n",
        "classifier(\n",
        "    [\n",
        "        \"لقد كنتُ أترقّب الدورة من هاجِّنغ فيس طوال حياتي.\",\n",
        "        \"أكره هذا بشدّة!\"\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WgqjvDXCY7U",
        "outputId": "b49b851b-688e-487b-b56a-c80195553f0d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9497042894363403},\n",
              " {'label': 'negative', 'score': 0.9927158951759338}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "تحميل محول النصوص\n",
        "\n",
        "ال tokenizer\n",
        "\n",
        "هو المسؤول عن تحويل الكلام لأرقام لان المحولات لا تفهم الكلام ولكن الأرقام فقط."
      ],
      "metadata": {
        "id": "OM7zR68PDrjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "checkpoint = \"MaagDeveloper/CAMeL-Lab-arabic-sentiment-analysis\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "srPaCrRqDE5k"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "لو لاحظنا، الجملتين مش بنفس الطول – واحدة أطول من الثانية. وهنا عندنا خيارين عشان نخليهم بنفس الطول:\n",
        "\n",
        "1. الحشو (Padding): نضيف رموز إضافية (غالباً أصفار) في نهاية الجمل الأقصر عشان توصل لطول الجملة الأطول.\n",
        "\n",
        "2. الاقتطاع (Truncation): نقطع الجمل الأطول ونخليها بنفس طول الجمل الأقصر أو الطول اللي نحدده.\n",
        "\n",
        "الهدف إن النموذج ياخذ مدخلات بطول موحد، لأن النماذج ما تشتغل بكفاءة على جمل بطول متغير.\n",
        "\n",
        "# مثال 1: الحشو فقط"
      ],
      "metadata": {
        "id": "CZXqXpkjDxbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    \"لقد كنتُ أترقّب الدورة من هاجِّنغ فيس طوال حياتي.\",\n",
        "    \"أكره هذا بشدّة!\"\n",
        "]\n",
        "\n",
        "inputs = tokenizer(raw_inputs, padding=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q_ypdwJDM1u",
        "outputId": "eed00c4d-fc73-483d-a3a8-4d90bf3a2672"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2,  3863,     1,     1,  6371,  1908,     1, 11256,  8026,  5097,\n",
            "            18,     3],\n",
            "        [    2,  5983,  2197,  2085,     1,     5,     3,     0,     0,     0,\n",
            "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# مثال 2: الحشو + الاقتطاع"
      ],
      "metadata": {
        "id": "sj5zo8RNFiRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_inputs = [\n",
        "    \"لقد كنتُ أترقّب الدورة من هاجِّنغ فيس طوال حياتي.\",\n",
        "    \"أكره هذا بشدّة!\"\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, max_length=5, return_tensors=\"pt\")\n",
        "print(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn_2W5DkFWlY",
        "outputId": "8d4e0efe-87e1-4562-ecdf-76ec2110b5e5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   2, 3863,    1,    1,    3],\n",
            "        [   2, 5983, 2197, 2085,    3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# مثال 3: الحشو لعدد معين دائمًا"
      ],
      "metadata": {
        "id": "DeVok23TFlSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_inputs = [\n",
        "    \"لقد كنتُ أترقّب الدورة من هاجِّنغ فيس طوال حياتي.\",\n",
        "    \"أكره هذا بشدّة!\"\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding='max_length', truncation=True, max_length=5, return_tensors=\"pt\")\n",
        "print(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSFJEKMvFbI1",
        "outputId": "e19efe17-964d-4968-f351-17ab8e44a328"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   2, 3863,    1,    1,    3],\n",
            "        [   2, 5983, 2197, 2085,    3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# تحميل المحول نفسه"
      ],
      "metadata": {
        "id": "Wyua4fKiF93o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "checkpoint = \"MaagDeveloper/CAMeL-Lab-arabic-sentiment-analysis\"\n",
        "model = AutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "8Hpu61W6FuDU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " شكل (أبعاد) تمثيل الكلمات داخل النموذج.\n",
        "\n",
        "last_hidden_state هو مصفوفة فيها التمثيلات النهائية لكل كلمة في الجملة.\n",
        "\n",
        "الشكل بيكون: (batch_size, sequence_length, hidden_size)\n",
        "\n",
        "يعني: عدد الجمل × طول الجملة (عدد التوكنز) × عدد الخصائص (الأبعاد) لكل كلمة."
      ],
      "metadata": {
        "id": "DiKmUJoCGa9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s3i2HOhGK95",
        "outputId": "82230058-bc8d-4a78-e107-ad7713d5b67b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# أول حاجة بنجيب موديل جاهز للتصنيف من مكتبة\n",
        "\n",
        "transformers:"
      ],
      "metadata": {
        "id": "wSNcacOzGvbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "fT7rJH2TGhsv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "بعدين بنحدد نقطة التحميل (checkpoint) للموديل اللي مدربينه على تحليل المشاعر بالعربي:"
      ],
      "metadata": {
        "id": "xbHXqsaSHBqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"MaagDeveloper/CAMeL-Lab-arabic-sentiment-analysis\"\n"
      ],
      "metadata": {
        "id": "89rK9EPUHERZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "نحمّل الموديل الجاهز ده:"
      ],
      "metadata": {
        "id": "1Ihd6-k2HF4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "w_xmFwRVHHc9"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "بعدين ندخل عليه البيانات اللي جهزناها (inputs) عشان يطلع النتائج:"
      ],
      "metadata": {
        "id": "1LodEcs7HNe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "pKX_1J7kHO2i"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "هنا بنطبع شكل النواتج:\n",
        "\n",
        "logits دي الأرقام الخام اللي النموذج حسبها قبل ما نطلع منها التوقع النهائي.\n",
        "\n",
        "شكلها بيكون (batch_size, num_labels) يعني: عدد الجمل × عدد الفئات اللي بنصنفها (مثلاً إيجابي، سلبي، محايد)."
      ],
      "metadata": {
        "id": "tvPWNZ4kHYsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4781_FHHY6Y",
        "outputId": "19a0dd91-203d-4586-b457-56b4916f0087"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "القيم نفسها:\n",
        "\n",
        "دي الأرقام اللي النموذج حسبها لكل فئة قبل ما نطبق عليها دالة مثل softmax لتحويلها لاحتمالات."
      ],
      "metadata": {
        "id": "s0BQbghbHhyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPtm7HgjHk01",
        "outputId": "f1afc6d5-9050-41d8-a153-ff71180b316f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0743, -0.7427, -0.4310],\n",
            "        [-2.6578,  3.5516, -1.4452]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "أول شيء بنستخدم دالة\n",
        "\n",
        "softmax\n",
        "\n",
        "لتحويل الأرقام الخام\n",
        "\n",
        "(logits)\n",
        "\n",
        "اللي طلعها النموذج إلى احتمالات فعلية:\n",
        "\n",
        "\n",
        "ليه softmax\n",
        "\n",
        "لأن\n",
        "\n",
        "logits\n",
        "\n",
        "هي أرقام ممكن تكون موجبة أو سالبة، مش مقيّدة بين 0 و1، ومش بتعبر عن احتمال.\n",
        "\n",
        "دالة\n",
        "\n",
        "softmax\n",
        "\n",
        "بتحولهم لمجموعة احتمالات مجموعها 1 لكل جملة، يعني كل رقم صار يمثل احتمال إن الجملة تنتمي لكل فئة.\n",
        "\n",
        "dim=-1\n",
        "\n",
        " معناها بنطبق العملية على آخر بعد في المصفوفة، اللي هو عدد الفئات.\n",
        "\n"
      ],
      "metadata": {
        "id": "iSNhKO4DHtpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjmDg3JmH8C2",
        "outputId": "8d3b7eb6-2cb1-4a83-d4b8-d28faadedfe6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4890, 0.2160, 0.2950],\n",
            "        [0.0020, 0.9913, 0.0067]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "دي حاجة موجودة في إعدادات الموديل، وتربط بين أرقام الفئات وتسمياتها الحقيقية.\n",
        "\n",
        "يعني بدل ما تشوف رقم زي 0 أو 1 أو 2، تقدر تعرف إذا الرقم ده يعني \"سلبي\" أو \"محايد\" أو \"إيجابي\".\n",
        "\n",
        "ببساطة، هي \"قاموس\" بيربط كل رقم تصنيف بالاسم أو الوصف بتاعه.\n",
        "\n",
        "تقدر تستخدمها عشان تفهم نتائج النموذج بشكل أوضح."
      ],
      "metadata": {
        "id": "MxhK8UWJIWCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5WLyO2BIWNs",
        "outputId": "6a63a7be-b993-4bdb-9d94-6f1316b7513d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'positive', 1: 'negative', 2: 'neutral'}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}