{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning supervis√© avec SFTTrainer\n",
    "\n",
    "Ce notebook montre comment finetuner le mod√®le `HuggingFaceTB/SmolLM2-135M` en utilisant le `SFTTrainer` de la biblioth√®que `trl`. Les cellules du notebook s'ex√©cutent et vont finetuner le mod√®le. Vous pouvez choisir votre difficult√© en essayant diff√©rents jeux de donn√©es.\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercice : Finetuning de SmolLM2 avec SFTTrainer</h2>\n",
    "    <p>Prenez un jeu de donn√©es provenant du Hub d'Hugging Face et finetun√© un mod√®le sur dessus. </p> \n",
    "    <p><b>Niveaux de difficult√©</b></p>\n",
    "    <p>üê¢ Utilisez le jeu de donn√©es `HuggingFaceTB/smoltalk`</p>\n",
    "    <p>üêï Essayez le jeu de donn√©es `bigcode/the-stack-smol` et finetunez un mod√®le de g√©n√©ration de code sur un sous-ensemble sp√©cifique `data/python`</p>\n",
    "    <p>ü¶Å S√©lectionnez un jeu de donn√©es en rapport avec un cas d'utilisation r√©el qui vous int√©resse</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les pr√©requis dans Google Colab\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# S'authentifier sur Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# Pour plus de facilit√©, vous pouvez cr√©er une variable d'environnement contenant votre jeton de hub sous la forme HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les biblioth√®ques n√©cessaires\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Charger le mod√®le et le tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# D√©finir le format de chat\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# D√©finir le nom du finetuning √† sauvegarder et/ou √† t√©l√©charger\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G√©n√©rer avec le mod√®le de base\n",
    "\n",
    "Ici, nous allons essayer le mod√®le de base qui n'a pas de gabarit de chat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons le mod√®le de base avant l'entra√Ænement\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# Format avec gabarit\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# G√©n√©rer une r√©ponse\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©paration du jeu de donn√©es\n",
    "\n",
    "Nous allons charger un √©chantillon du jeu de donn√©es et le formater pour l'entra√Ænement. Le jeu de donn√©es doit √™tre structur√© avec des paires entr√©e-sortie, o√π chaque entr√©e est une instruction et la sortie est la r√©ponse attendue du mod√®le.\n",
    "\n",
    "**TRL va formater les messages d'entr√©e en se basant sur les gabarits de chat du mod√®le.** Ils doivent √™tre repr√©sent√©s sous la forme d'une liste de dictionnaires avec les cl√©s : `role` et `content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement d'un √©chantillon du jeu de donn√©es\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO : d√©finir votre jeu de donn√©es et votre configuration en utilisant les param√®tres path et name\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ü¶Å Si votre jeu de donn√©es n'est pas dans un format que TRL peut convertir en gabarit de chat, vous devrez le traiter. Reportez-vous au [module](../chat_templates.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurer le SFTTrainer\n",
    "\n",
    "Le `SFTTrainer` est configur√© avec diff√©rents param√®tres qui contr√¥lent le processus d'apprentissage. Ceux-ci incluent le nombre d'√©tapes d'entra√Ænement, la taille de batch, le taux d'apprentissage et la strat√©gie d'√©valuation. Ajustez ces param√®tres en fonction de vos besoins sp√©cifiques et de vos ressources de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer le SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # Ajuster en fonction de la taille du jeu de donn√©es et de la dur√©e d'entra√Ænement souhait√©e\n",
    "    per_device_train_batch_size=4,  # R√©gler en fonction de la capacit√© de m√©moire de votre GPU\n",
    "    learning_rate=5e-5,  # Point de d√©part commun pour le finetuning\n",
    "    logging_steps=10,  # Fr√©quence d'enregistrement des m√©triques d'entra√Ænement\n",
    "    save_steps=100,  # Fr√©quence de sauvegarde des checkpoints du mod√®le\n",
    "    evaluation_strategy=\"steps\",  # √âvaluer le mod√®le √† intervalles r√©guliers\n",
    "    eval_steps=50,  # Fr√©quence de l'√©valuation\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # Utiliser MPS pour un entra√Ænement √† pr√©cision mixte\n",
    "    hub_model_id=finetune_name,  # D√©finissez un nom unique pour votre mod√®le\n",
    ")\n",
    "\n",
    "# Initialiser le SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "# TODO : ü¶Å üêï aligner les param√®tres de SFTTrainer avec le jeu de donn√©es que vous avez choisi. \n",
    "# Par exemple, si vous utilisez le jeu de donn√©es `bigcode/the-stack-smol`, vous devrez choisir la colonne `content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entra√Ænement du mod√®le\n",
    "\n",
    "Une fois le Trainer configur√©, nous pouvons maintenant proc√©der √† l'entra√Ænement du mod√®le. Le processus d'entra√Ænement consiste √† it√©rer sur le jeu de donn√©es, √† calculer la perte et √† mettre √† jour les param√®tres du mod√®le afin de minimiser cette perte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Æner le mod√®le\n",
    "trainer.train()\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercice bonus : G√©n√©rer avec un mod√®le finetun√©</h2>\n",
    "    <p>üêï Utiliser le mod√®le finetun√© pour g√©n√©rer une r√©ponse, comme dans l'exemple de base</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester le mod√®le finetun√© sur la m√™me instruction\n",
    "\n",
    "# Testons le mod√®le de base avant l'entra√Ænement\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# Format avec gabarit\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# G√©n√©rer une r√©ponse\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO : utiliser le mod√®le finetun√© pour g√©n√©rer une r√©ponse, comme dans l'exemple de base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê Vous avez termin√© !\n",
    "\n",
    "Ce *notebook* fournit un guide √©tape par √©tape pour finetuner le mod√®le `HuggingFaceTB/SmolLM2-135M` en utilisant le `SFTTrainer`. En suivant ces √©tapes, vous pouvez adapter le mod√®le pour effectuer des t√¢ches sp√©cifiques plus efficacement. Si vous voulez continuer √† travailler sur ce cours, voici quelques √©tapes que vous pouvez essayer :\n",
    "\n",
    "- Essayez ce *notebook*  avec un niveau de difficult√© plus √©lev√©\n",
    "- Examiner la PR d'un coll√®gue\n",
    "- Am√©liorez le mat√©riel de cours par le biais d'une *issue* ou d'une PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
