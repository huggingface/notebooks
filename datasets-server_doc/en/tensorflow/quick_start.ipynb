{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this quickstart, you'll learn how to use the Datasets Server's REST API to:\n",
    "\n",
    "- Check whether a dataset on the Hub is functional.\n",
    "- Return the configuration and splits of a dataset.\n",
    "- Preview the first 100 rows of a dataset.\n",
    "- Download slices of rows of a dataset.\n",
    "- Access the dataset as parquet files.\n",
    "\n",
    "Each feature is served through an endpoint summarized in the table below:\n",
    "\n",
    "| Endpoint                    | Method | Description                                                                      | Query parameters                                                                                   |\n",
    "| --------------------------- | ------ | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n",
    "| [/valid](./valid)           | GET    | Get the list of datasets hosted in the Hub and supported by the datasets server. | none                                                                                               |\n",
    "| [/is-valid](./valid)        | GET    | Check whether a specific dataset is valid.                                       | `dataset`: name of the dataset                                                                     |\n",
    "| [/splits](./splits)         | GET    | Get the list of configurations and splits of a dataset.                          | `dataset`: name of the dataset                                                                     |\n",
    "| [/first-rows](./first_rows) | GET    | Get the first rows of a dataset split.                                           | - `dataset`: name of the dataset<br>- `config`: name of the config<br>- `split`: name of the split |\n",
    "| [/rows](./rows)             | GET    | Get a slice of rows of a dataset split.                                          | - `dataset`: name of the dataset<br>- `config`: name of the config<br>- `split`: name of the split<br>- `offset`: offset of the slice<br>- `length`: length of the slice (maximum 100) |\n",
    "| [/parquet](./parquet)       | GET    | Get the list of parquet files of a dataset.                                      | `dataset`: name of the dataset                                                                     |\n",
    "\n",
    "There is no installation or setup required to use Datasets Server.\n",
    "\n",
    "<Tip>\n",
    "  Sign up for a <a href=\"https://huggingface.co/join\">Hugging Face account</a>{\" \"}\n",
    "  if you don't already have one! While you can use Datasets Server without a\n",
    "  Hugging Face account, you won't be able to access{\" \"}\n",
    "  <a href=\"https://huggingface.co/docs/hub/datasets-gated\">gated datasets</a>{\" \"}\n",
    "  like{\" \"}\n",
    "  <a href=\"https://huggingface.co/datasets/mozilla-foundation/common_voice_10_0\">\n",
    "    CommonVoice\n",
    "  </a>{\" \"}\n",
    "  and <a href=\"https://huggingface.co/datasets/imagenet-1k\">ImageNet</a> without\n",
    "  providing a <a href=\"https://huggingface.co/settings/tokens\">user token</a>{\" \"}\n",
    "  which you can find in your user settings.\n",
    "</Tip>\n",
    "\n",
    "Feel free to try out the API in [Postman](https://www.postman.com/huggingface/workspace/hugging-face-apis/documentation/23242779-d068584e-96d1-4d92-a703-7cb12cbd8053), [ReDoc](https://redocly.github.io/redoc/?url=https://datasets-server.huggingface.co/openapi.json) or [RapidAPI](https://rapidapi.com/hugging-face-hugging-face-default/api/hugging-face-datasets-api/). This quickstart will show you how to query the endpoints programmatically.\n",
    "\n",
    "The base URL of the REST API is:\n",
    "\n",
    "```\n",
    "https://datasets-server.huggingface.co\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For gated datasets, you'll need to provide your user token in `headers` of your query. Otherwise, you'll get an error message to retry with authentication.\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "API_URL = \"https://datasets-server.huggingface.co/is-valid?dataset=mozilla-foundation/common_voice_10_0\"\n",
    "def query():\n",
    "    response = requests.get(API_URL, headers=headers)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/is-valid?dataset=rotten_tomatoes\",\n",
    "        {\n",
    "            headers: { Authorization: `Bearer ${API_TOKEN}` },\n",
    "            method: \"GET\",\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/is-valid?dataset=rotten_tomatoes \\\n",
    "        -X GET \\\n",
    "        -H \"Authorization: Bearer ${API_TOKEN}\"\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "You'll see the following error if you're trying to access a gated dataset without providing your user token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{'error': 'The dataset does not exist, or is not accessible without authentication (private or gated). Please check the spelling of the dataset name or retry with authentication.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataset validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/valid` endpoint returns a JSON list of datasets stored on the Hub that load without any errors:\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_URL = \"https://datasets-server.huggingface.co/valid\"\n",
    "def query():\n",
    "    response = requests.get(API_URL)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/valid\",\n",
    "        {\n",
    "            method: \"GET\"\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/valid \\\n",
    "        -X GET\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "This returns a list of all the datasets that load without an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{\n",
    "  \"valid\": [\n",
    "    \"0n1xus/codexglue\",\n",
    "    \"0n1xus/pytorrent-standalone\",\n",
    "    \"0x7194633/rupile\",\n",
    "    \"51la5/keyword-extraction\",\n",
    "    ...,\n",
    "    ...,\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether a specific dataset is valid, for example, [Rotten Tomatoes](https://huggingface.co/datasets/rotten_tomatoes), use the `/is-valid` endpoint instead:\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_URL = \"https://datasets-server.huggingface.co/is-valid?dataset=rotten_tomatoes\"\n",
    "def query():\n",
    "    response = requests.get(API_URL)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/is-valid?dataset=rotten_tomatoes\",\n",
    "        {\n",
    "            method: \"GET\"\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/is-valid?dataset=rotten_tomatoes \\\n",
    "        -X GET\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "This returns whether the `valid` key is `true` or `false`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{'valid': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List configurations and splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/splits` endpoint returns a JSON list of the splits in a dataset:\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_URL = \"https://datasets-server.huggingface.co/splits?dataset=rotten_tomatoes\"\n",
    "def query():\n",
    "    response = requests.get(API_URL)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/splits?dataset=rotten_tomatoes\",\n",
    "        {\n",
    "            method: \"GET\"\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/splits?dataset=rotten_tomatoes \\\n",
    "        -X GET\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "This returns the available configuration and splits in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{'splits': \n",
    "    [\n",
    "        {'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'train'}, \n",
    "        {'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'validation'}, \n",
    "        {'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'test'}\n",
    "    ], \n",
    " 'pending': [], \n",
    " 'failed': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/first-rows` endpoint returns a JSON list of the first 100 rows of a dataset. It also returns the types of data features (\"columns\" data types). You should specify the dataset name, configuration name (you can find out the configuration name from the `/splits` endpoint), and split name of the dataset you'd like to preview:\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_URL = \"https://datasets-server.huggingface.co/first-rows?dataset=rotten_tomatoes&config=default&split=train\"\n",
    "def query():\n",
    "    response = requests.get(API_URL)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/first-rows?dataset=rotten_tomatoes&config=default&split=train\",\n",
    "        {\n",
    "            method: \"GET\"\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/first-rows?dataset=rotten_tomatoes&config=default&split=train \\\n",
    "        -X GET\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "This returns the first 100 rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'train', \n",
    " 'features': \n",
    "    [\n",
    "        {'feature_idx': 0, 'name': 'text', 'type': {'dtype': 'string', '_type': 'Value'}}, \n",
    "        {'feature_idx': 1, 'name': 'label', 'type': {'names': ['neg', 'pos'], '_type': 'ClassLabel'}}\n",
    "    ], \n",
    " 'rows': \n",
    "    [\n",
    "        {'row_idx': 0, 'row': {'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1}, 'truncated_cells': []}, \n",
    "        {'row_idx': 1, 'row': {'text': 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'label': 1}, 'truncated_cells': []}\n",
    "        ...,\n",
    "        ...,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download slices of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/rows` endpoint returns a JSON list of a slice of rows of a dataset at any given location (offset).\n",
    "It also returns the types of data features (\"columns\" data types).\n",
    "You should specify the dataset name, configuration name (you can find out the configuration name from the `/splits` endpoint), the split name and the offset and length of the slice you'd like to download:\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_URL = \"https://datasets-server.huggingface.co/rows?dataset=rotten_tomatoes&config=default&split=train&offset=150&length=10\"\n",
    "def query():\n",
    "    response = requests.get(API_URL)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/rows?dataset=rotten_tomatoes&config=default&split=train&offset=150&length=10\",\n",
    "        {\n",
    "            method: \"GET\"\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/rows?dataset=rotten_tomatoes&config=default&split=train&offset=150&length=10 \\\n",
    "        -X GET\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "You can download slices of 100 rows maximum at a time.\n",
    "\n",
    "The response looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{'features': \n",
    "    [\n",
    "        {'feature_idx': 0, 'name': 'text', 'type': {'dtype': 'string', '_type': 'Value'}}, \n",
    "        {'feature_idx': 1, 'name': 'label', 'type': {'names': ['neg', 'pos'], '_type': 'ClassLabel'}}], \n",
    " 'rows': \n",
    "    [\n",
    "        {'row_idx': 150, 'row': {'text': 'enormously likable , partly because it is aware of its own grasp of the absurd .', 'label': 1}, 'truncated_cells': []}, \n",
    "        {'row_idx': 151, 'row': {'text': \"here's a british flick gleefully unconcerned with plausibility , yet just as determined to entertain you .\", 'label': 1}, 'truncated_cells': []}, \n",
    "        {'row_idx': 152, 'row': {'text': \"it's an old story , but a lively script , sharp acting and partially animated interludes make just a kiss seem minty fresh .\", 'label': 1}, 'truncated_cells': []}, \n",
    "        {'row_idx': 153, 'row': {'text': 'must be seen to be believed .', 'label': 1}, 'truncated_cells': []}, \n",
    "        {'row_idx': 154, 'row': {'text': \"ray liotta and jason patric do some of their best work in their underwritten roles , but don't be fooled : nobody deserves any prizes here .\", 'label': 1}, 'truncated_cells': []}, \n",
    "        ...,\n",
    "        ...,\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets Server converts every public dataset on the Hub to the [Parquet](https://parquet.apache.org/) format. The `/parquet` endpoint returns a JSON list of the Parquet URLs for a dataset:\n",
    "\n",
    "<inferencesnippet>\n",
    "<python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_URL = \"https://datasets-server.huggingface.co/parquet?dataset=rotten_tomatoes\"\n",
    "def query():\n",
    "    response = requests.get(API_URL)\n",
    "    return response.json()\n",
    "data = query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</python>\n",
    "<js>\n",
    "```js\n",
    "import fetch from \"node-fetch\";\n",
    "async function query(data) {\n",
    "    const response = await fetch(\n",
    "        \"https://datasets-server.huggingface.co/parquet?dataset=rotten_tomatoes\",\n",
    "        {\n",
    "            method: \"GET\"\n",
    "        }\n",
    "    );\n",
    "    const result = await response.json();\n",
    "    return result;\n",
    "}\n",
    "query().then((response) => {\n",
    "    console.log(JSON.stringify(response));\n",
    "});\n",
    "```\n",
    "</js>\n",
    "<curl>\n",
    "```curl\n",
    "curl https://datasets-server.huggingface.co/parquet?dataset=rotten_tomatoes \\\n",
    "        -X GET\n",
    "```\n",
    "</curl>\n",
    "</inferencesnippet>\n",
    "\n",
    "This returns a URL to the Parquet file for each split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "{'parquet_files': \n",
    "    [\n",
    "        {'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'test', 'url': 'https://huggingface.co/datasets/rotten_tomatoes/resolve/refs%2Fconvert%2Fparquet/default/test/0000.parquet', 'filename': '0000.parquet', 'size': 92206}, \n",
    "        {'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'train', 'url': 'https://huggingface.co/datasets/rotten_tomatoes/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet', 'filename': '0000.parquet' 'size': 698845}, \n",
    "        {'dataset': 'rotten_tomatoes', 'config': 'default', 'split': 'validation', 'url': 'https://huggingface.co/datasets/rotten_tomatoes/resolve/refs%2Fconvert%2Fparquet/default/validation/0000.parquet', 'filename': '0000.parquet' 'size': 90001}\n",
    "    ], \n",
    " 'pending': [], \n",
    " 'failed': []\n",
    "}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
