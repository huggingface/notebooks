{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æœ‰æ•ˆä¸”é«˜æ•ˆçš„æ‰©æ•£"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®© `DiffusionPipeline` ç”Ÿæˆç‰¹å®šé£æ ¼æˆ–åŒ…å«ä½ æ‰€æƒ³è¦çš„å†…å®¹çš„å›¾åƒå¯èƒ½ä¼šæœ‰äº›æ£˜æ‰‹ã€‚ é€šå¸¸æƒ…å†µä¸‹ï¼Œä½ éœ€è¦å¤šæ¬¡è¿è¡Œ `DiffusionPipeline` æ‰èƒ½å¾—åˆ°æ»¡æ„çš„å›¾åƒã€‚ä½†æ˜¯ä»æ— åˆ°æœ‰ç”Ÿæˆå›¾åƒæ˜¯ä¸€ä¸ªè®¡ç®—å¯†é›†çš„è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯å¦‚æœä½ è¦ä¸€éåˆä¸€éåœ°è¿›è¡Œæ¨ç†è¿ç®—ã€‚\n",
    "\n",
    "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»pipelineä¸­è·å¾—æœ€é«˜çš„ *computational* (speed) å’Œ *memory* (GPU RAM) éå¸¸é‡è¦ ï¼Œä»¥å‡å°‘æ¨ç†å‘¨æœŸä¹‹é—´çš„æ—¶é—´ï¼Œä»è€Œä½¿è¿­ä»£é€Ÿåº¦æ›´å¿«ã€‚\n",
    "\n",
    "\n",
    "æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨å¦‚ä½•é€šè¿‡ `DiffusionPipeline`  æ›´å¿«ã€æ›´å¥½åœ°ç”Ÿæˆå›¾åƒã€‚\n",
    "\n",
    "\n",
    "é¦–å…ˆï¼ŒåŠ è½½ [`stable-diffusion-v1-5/stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5) æ¨¡å‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "model_id = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "pipeline = DiffusionPipeline.from_pretrained(model_id, use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ¬æ•™ç¨‹å°†ä½¿ç”¨çš„æç¤ºè¯æ˜¯ `portrait photo of a old warrior chief` ï¼Œä½†æ˜¯ä½ å¯ä»¥éšå¿ƒæ‰€æ¬²çš„æƒ³è±¡å’Œæ„é€ è‡ªå·±çš„æç¤ºè¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"portrait photo of a old warrior chief\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é€Ÿåº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ğŸ’¡ å¦‚æœä½ æ²¡æœ‰ GPU, ä½ å¯ä»¥ä»åƒ [Colab](https://colab.research.google.com/) è¿™æ ·çš„ GPU æä¾›å•†è·å–å…è´¹çš„ GPU !\n",
    "\n",
    "</Tip>\n",
    "\n",
    "åŠ é€Ÿæ¨ç†çš„æœ€ç®€å•æ–¹æ³•ä¹‹ä¸€æ˜¯å°† pipeline æ”¾åœ¨ GPU ä¸Š ï¼Œå°±åƒä½¿ç”¨ä»»ä½• PyTorch æ¨¡å—ä¸€æ ·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ç¡®ä¿æ‚¨å¯ä»¥ä½¿ç”¨ç›¸åŒçš„å›¾åƒå¹¶å¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œä½¿ç”¨ [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html) æ–¹æ³•ï¼Œç„¶åè®¾ç½®ä¸€ä¸ªéšæœºæ•°ç§å­ ä»¥ç¡®ä¿å…¶ [å¤ç°æ€§](https://huggingface.co/docs/diffusers/main/zh/./using-diffusers/reusing_seeds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œä½ å¯ä»¥ç”Ÿæˆä¸€ä¸ªå›¾åƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipeline(prompt, generator=generator).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_1.png\">\n",
    "</div>\n",
    "\n",
    "åœ¨ T4 GPU ä¸Šï¼Œè¿™ä¸ªè¿‡ç¨‹å¤§æ¦‚è¦30ç§’ï¼ˆå¦‚æœä½ çš„ GPU æ¯” T4 å¥½ï¼Œå¯èƒ½ä¼šæ›´å¿«ï¼‰ã€‚åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œ`DiffusionPipeline` ä½¿ç”¨å®Œæ•´çš„ `float32` ç²¾åº¦è¿›è¡Œ 50 æ­¥æ¨ç†ã€‚ä½ å¯ä»¥é€šè¿‡é™ä½ç²¾åº¦ï¼ˆå¦‚ `float16` ï¼‰æˆ–è€…å‡å°‘æ¨ç†æ­¥æ•°æ¥åŠ é€Ÿæ•´ä¸ªè¿‡ç¨‹\n",
    "\n",
    "\n",
    "è®©æˆ‘ä»¬æŠŠæ¨¡å‹çš„ç²¾åº¦é™ä½è‡³ `float16` ï¼Œç„¶åç”Ÿæˆä¸€å¼ å›¾åƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True)\n",
    "pipeline = pipeline.to(\"cuda\")\n",
    "generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "image = pipeline(prompt, generator=generator).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_2.png\">\n",
    "</div>\n",
    "\n",
    "è¿™ä¸€æ¬¡ï¼Œç”Ÿæˆå›¾åƒåªèŠ±äº†çº¦ 11 ç§’ï¼Œæ¯”ä¹‹å‰å¿«äº†è¿‘ 3 å€ï¼\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ğŸ’¡ æˆ‘ä»¬å¼ºçƒˆå»ºè®®æŠŠ pipeline ç²¾åº¦é™ä½è‡³ `float16` , åˆ°ç›®å‰ä¸ºæ­¢, æˆ‘ä»¬å¾ˆå°‘çœ‹åˆ°è¾“å‡ºè´¨é‡æœ‰ä»»ä½•ä¸‹é™ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "å¦ä¸€ä¸ªé€‰æ‹©æ˜¯å‡å°‘æ¨ç†æ­¥æ•°ã€‚ ä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªæ›´é«˜æ•ˆçš„è°ƒåº¦å™¨ (*scheduler*) å¯ä»¥å‡å°‘æ¨ç†æ­¥æ•°åŒæ—¶ä¿è¯è¾“å‡ºè´¨é‡ã€‚æ‚¨å¯ä»¥åœ¨ [DiffusionPipeline] ä¸­é€šè¿‡è°ƒç”¨compatiblesæ–¹æ³•æ‰¾åˆ°ä¸å½“å‰æ¨¡å‹å…¼å®¹çš„è°ƒåº¦å™¨ (*scheduler*)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.scheduler.compatibles\n",
    "[\n",
    "    diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,\n",
    "    diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,\n",
    "    diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,\n",
    "    diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,\n",
    "    diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,\n",
    "    diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,\n",
    "    diffusers.schedulers.scheduling_ddpm.DDPMScheduler,\n",
    "    diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,\n",
    "    diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,\n",
    "    diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,\n",
    "    diffusers.schedulers.scheduling_pndm.PNDMScheduler,\n",
    "    diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,\n",
    "    diffusers.schedulers.scheduling_ddim.DDIMScheduler,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion æ¨¡å‹é»˜è®¤ä½¿ç”¨çš„æ˜¯ `PNDMScheduler` ï¼Œé€šå¸¸è¦å¤§æ¦‚50æ­¥æ¨ç†, ä½†æ˜¯åƒ `DPMSolverMultistepScheduler` è¿™æ ·æ›´é«˜æ•ˆçš„è°ƒåº¦å™¨åªè¦å¤§æ¦‚ 20 æˆ– 25 æ­¥æ¨ç†. ä½¿ç”¨ `ConfigMixin.from_config()` æ–¹æ³•åŠ è½½æ–°çš„è°ƒåº¦å™¨:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨å°† `num_inference_steps` è®¾ç½®ä¸º 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "image = pipeline(prompt, generator=generator, num_inference_steps=20).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_3.png\">\n",
    "</div>\n",
    "\n",
    "å¤ªæ£’äº†ï¼ä½ æˆåŠŸæŠŠæ¨ç†æ—¶é—´ç¼©çŸ­åˆ° 4 ç§’ï¼âš¡ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†…å­˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ”¹å–„ pipeline æ€§èƒ½çš„å¦ä¸€ä¸ªå…³é”®æ˜¯å‡å°‘å†…å­˜çš„ä½¿ç”¨é‡ï¼Œè¿™é—´æ¥æ„å‘³ç€é€Ÿåº¦æ›´å¿«ï¼Œå› ä¸ºä½ ç»å¸¸è¯•å›¾æœ€å¤§åŒ–æ¯ç§’ç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚è¦æƒ³çŸ¥é“ä½ ä¸€æ¬¡å¯ä»¥ç”Ÿæˆå¤šå°‘å¼ å›¾ç‰‡ï¼Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯å°è¯•ä¸åŒçš„batch sizeï¼Œç›´åˆ°å‡ºç°`OutOfMemoryError` (OOM)ã€‚\n",
    "\n",
    "åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä¸ºæ¯ä¸€æ‰¹è¦ç”Ÿæˆçš„å›¾åƒåˆ†é…æç¤ºè¯å’Œ `Generators` ã€‚è¯·åŠ¡å¿…ä¸ºæ¯ä¸ª`Generator` åˆ†é…ä¸€ä¸ªç§å­ï¼Œä»¥ä¾¿äºå¤ç°è‰¯å¥½çš„ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(batch_size=1):\n",
    "    generator = [torch.Generator(\"cuda\").manual_seed(i) for i in range(batch_size)]\n",
    "    prompts = batch_size * [prompt]\n",
    "    num_inference_steps = 20\n",
    "\n",
    "    return {\"prompt\": prompts, \"generator\": generator, \"num_inference_steps\": num_inference_steps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®¾ç½® `batch_size=4` ï¼Œç„¶åçœ‹ä¸€çœ‹æˆ‘ä»¬æ¶ˆè€—äº†å¤šå°‘å†…å­˜:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "images = pipeline(**get_inputs(batch_size=4)).images\n",
    "make_image_grid(images, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é™¤éä½ æœ‰ä¸€ä¸ªæ›´å¤§å†…å­˜çš„GPU, å¦åˆ™ä¸Šè¿°ä»£ç ä¼šè¿”å› `OOM` é”™è¯¯! å¤§éƒ¨åˆ†å†…å­˜è¢« cross-attention å±‚ä½¿ç”¨ã€‚æŒ‰é¡ºåºè¿è¡Œå¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ï¼Œè€Œä¸æ˜¯åœ¨æ‰¹å¤„ç†ä¸­è¿›è¡Œã€‚ä½ å¯ä»¥ä¸º pipeline é…ç½® `enable_attention_slicing()` å‡½æ•°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨å°è¯•æŠŠ `batch_size` å¢åŠ åˆ° 8!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pipeline(**get_inputs(batch_size=8)).images\n",
    "make_image_grid(images, rows=2, cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_5.png\">\n",
    "</div>\n",
    "\n",
    "ä»¥å‰ä½ ä¸èƒ½ä¸€æ‰¹ç”Ÿæˆ 4 å¼ å›¾ç‰‡ï¼Œè€Œç°åœ¨ä½ å¯ä»¥åœ¨ä¸€å¼ å›¾ç‰‡é‡Œé¢ç”Ÿæˆå…«å¼ å›¾ç‰‡è€Œåªéœ€è¦å¤§æ¦‚3.5ç§’ï¼è¿™å¯èƒ½æ˜¯ T4 GPU åœ¨ä¸ç‰ºç‰²è´¨é‡çš„æƒ…å†µè¿è¡Œé€Ÿåº¦æœ€å¿«çš„ä¸€ç§æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è´¨é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æœ€åä¸¤èŠ‚ä¸­, ä½ è¦å­¦ä¹ å¦‚ä½•é€šè¿‡ `fp16` æ¥ä¼˜åŒ– pipeline çš„é€Ÿåº¦, é€šè¿‡ä½¿ç”¨æ€§èƒ½æ›´é«˜çš„è°ƒåº¦å™¨æ¥å‡å°‘æ¨ç†æ­¥æ•°, ä½¿ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ï¼ˆ*enabling attention slicing*ï¼‰æ–¹æ³•æ¥èŠ‚çœå†…å­˜ã€‚ç°åœ¨ï¼Œä½ å°†å…³æ³¨çš„æ˜¯å¦‚ä½•æé«˜å›¾åƒçš„è´¨é‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ›´å¥½çš„ checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„æ–¹æ³•æ˜¯ä½¿ç”¨æ›´å¥½çš„ checkpointsã€‚ Stable Diffusion æ¨¡å‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹, è‡ªæ­£å¼å‘å¸ƒä»¥æ¥ï¼Œè¿˜å‘å¸ƒäº†å‡ ä¸ªæ”¹è¿›ç‰ˆæœ¬ã€‚ç„¶è€Œ, ä½¿ç”¨æ›´æ–°çš„ç‰ˆæœ¬å¹¶ä¸æ„å‘³ç€ä½ ä¼šå¾—åˆ°æ›´å¥½çš„ç»“æœã€‚ä½ ä»ç„¶éœ€è¦å°è¯•ä¸åŒçš„ checkpoints ï¼Œå¹¶åšä¸€äº›ç ”ç©¶ (ä¾‹å¦‚ä½¿ç”¨ [negative prompts](https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/)) æ¥è·å¾—æ›´å¥½çš„ç»“æœã€‚\n",
    "\n",
    "éšç€è¯¥é¢†åŸŸçš„å‘å±•, æœ‰è¶Šæ¥è¶Šå¤šç»è¿‡å¾®è°ƒçš„é«˜è´¨é‡çš„ checkpoints ç”¨æ¥ç”Ÿæˆä¸ä¸€æ ·çš„é£æ ¼. åœ¨ [Hub](https://huggingface.co/models?library=diffusers&sort=downloads) å’Œ [Diffusers Gallery](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery) å¯»æ‰¾ä½ æ„Ÿå…´è¶£çš„ä¸€ç§!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ›´å¥½çš„ pipeline ç»„ä»¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¹Ÿå¯ä»¥å°è¯•ç”¨æ–°ç‰ˆæœ¬æ›¿æ¢å½“å‰ pipeline ç»„ä»¶ã€‚è®©æˆ‘ä»¬åŠ è½½æœ€æ–°çš„ [autodecoder](https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main/vae) ä» Stability AI åŠ è½½åˆ° pipeline, å¹¶ç”Ÿæˆä¸€äº›å›¾åƒ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipeline.vae = vae\n",
    "images = pipeline(**get_inputs(batch_size=8)).images\n",
    "make_image_grid(images, rows=2, cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_6.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ›´å¥½çš„æç¤ºè¯å·¥ç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”¨äºç”Ÿæˆå›¾åƒçš„æ–‡æœ¬éå¸¸é‡è¦, å› æ­¤è¢«ç§°ä¸º *æç¤ºè¯å·¥ç¨‹*ã€‚ åœ¨è®¾è®¡æç¤ºè¯å·¥ç¨‹åº”æ³¨æ„å¦‚ä¸‹äº‹é¡¹:\n",
    "\n",
    "- æˆ‘æƒ³ç”Ÿæˆçš„å›¾åƒæˆ–ç±»ä¼¼å›¾åƒå¦‚ä½•å­˜å‚¨åœ¨äº’è”ç½‘ä¸Šï¼Ÿ\n",
    "- æˆ‘å¯ä»¥æä¾›å“ªäº›é¢å¤–çš„ç»†èŠ‚æ¥å¼•å¯¼æ¨¡å‹æœç€æˆ‘æƒ³è¦çš„é£æ ¼ç”Ÿæˆï¼Ÿ\n",
    "\n",
    "è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ”¹è¿›æç¤ºè¯ï¼Œä»¥åŒ…å«é¢œè‰²å’Œæ›´é«˜è´¨é‡çš„ç»†èŠ‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt += \", tribal panther make up, blue on red, side profile, looking away, serious eyes\"\n",
    "prompt += \" 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨æ–°çš„æç¤ºè¯ç”Ÿæˆä¸€æ‰¹å›¾åƒ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pipeline(**get_inputs(batch_size=8)).images\n",
    "make_image_grid(images, rows=2, cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_7.png\">\n",
    "</div>\n",
    "\n",
    "éå¸¸çš„ä»¤äººå°è±¡æ·±åˆ»! Let's tweak the second image - æŠŠ `Generator` çš„ç§å­è®¾ç½®ä¸º `1` - æ·»åŠ ä¸€äº›å…³äºå¹´é¾„çš„ä¸»é¢˜æ–‡æœ¬:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"portrait photo of the oldest warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta\",\n",
    "    \"portrait photo of a old warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta\",\n",
    "    \"portrait photo of a warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta\",\n",
    "    \"portrait photo of a young warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta\",\n",
    "]\n",
    "\n",
    "generator = [torch.Generator(\"cuda\").manual_seed(1) for _ in range(len(prompts))]\n",
    "images = pipeline(prompt=prompts, generator=generator, num_inference_steps=25).images\n",
    "make_image_grid(images, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/stable_diffusion_101/sd_101_8.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ€å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æœ¬æ•™ç¨‹ä¸­, æ‚¨å­¦ä¹ äº†å¦‚ä½•ä¼˜åŒ–`DiffusionPipeline`ä»¥æé«˜è®¡ç®—å’Œå†…å­˜æ•ˆç‡ï¼Œä»¥åŠæé«˜ç”Ÿæˆè¾“å‡ºçš„è´¨é‡. å¦‚æœä½ æœ‰å…´è¶£è®©ä½ çš„ pipeline æ›´å¿«, å¯ä»¥çœ‹ä¸€çœ‹ä»¥ä¸‹èµ„æº:\n",
    "\n",
    "- å­¦ä¹  [PyTorch 2.0](https://huggingface.co/docs/diffusers/main/zh/./optimization/torch2.0) å’Œ [`torch.compile`](https://pytorch.org/docs/stable/generated/torch.compile.html) å¯ä»¥è®©æ¨ç†é€Ÿåº¦æé«˜ 5 - 300% . åœ¨ A100 GPU ä¸Š, æ¨ç†é€Ÿåº¦å¯ä»¥æé«˜ 50% !\n",
    "- å¦‚æœä½ æ²¡æ³•ç”¨ PyTorch 2, æˆ‘ä»¬å»ºè®®ä½ å®‰è£… [xFormers](https://huggingface.co/docs/diffusers/main/zh/./optimization/xformers)ã€‚å®ƒçš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ï¼ˆ*memory-efficient attention mechanism*ï¼‰ä¸PyTorch 1.13.1é…åˆä½¿ç”¨ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œå†…å­˜æ¶ˆè€—æ›´å°‘ã€‚\n",
    "- å…¶ä»–çš„ä¼˜åŒ–æŠ€æœ¯, å¦‚ï¼šæ¨¡å‹å¸è½½ï¼ˆ*model offloading*ï¼‰, åŒ…å«åœ¨ [è¿™ä»½æŒ‡å—](https://huggingface.co/docs/diffusers/main/zh/./optimization/fp16)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
