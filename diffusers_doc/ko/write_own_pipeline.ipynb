{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íŒŒì´í”„ë¼ì¸, ëª¨ë¸ ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì´í•´í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§¨ DiffusersëŠ” ì‚¬ìš©ì ì¹œí™”ì ì´ë©° ìœ ì—°í•œ ë„êµ¬ ìƒìë¡œ, ì‚¬ìš©ì‚¬ë¡€ì— ë§ê²Œ diffusion ì‹œìŠ¤í…œì„ êµ¬ì¶• í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë„êµ¬ ìƒìì˜ í•µì‹¬ì€ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ì…ë‹ˆë‹¤. `DiffusionPipeline`ì€ í¸ì˜ë¥¼ ìœ„í•´ ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë¥¼ ë²ˆë“¤ë¡œ ì œê³µí•˜ì§€ë§Œ, íŒŒì´í”„ë¼ì¸ì„ ë¶„ë¦¬í•˜ê³  ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‚¬ìš©í•´ ìƒˆë¡œìš´ diffusion ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ë¶€í„° ì‹œì‘í•´ Stable Diffusion íŒŒì´í”„ë¼ì¸ê¹Œì§€ ì§„í–‰í•˜ë©° ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•´ ì¶”ë¡ ì„ ìœ„í•œ diffusion ì‹œìŠ¤í…œì„ ì¡°ë¦½í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ í•´ì²´í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íŒŒì´í”„ë¼ì¸ì€ ì¶”ë¡ ì„ ìœ„í•´ ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ë¹ ë¥´ê³  ì‰¬ìš´ ë°©ë²•ìœ¼ë¡œ, ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ì½”ë“œê°€ 4ì¤„ ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "\n",
    "ddpm = DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\").to(\"cuda\")\n",
    "image = ddpm(num_inference_steps=25).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/ddpm-cat.png\" alt=\"Image of cat created from DDPMPipeline\"/>\n",
    "</div>\n",
    "\n",
    "ì •ë§ ì‰½ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° íŒŒì´í”„ë¼ì¸ì€ ì–´ë–»ê²Œ ì´ë ‡ê²Œ í•  ìˆ˜ ìˆì—ˆì„ê¹Œìš”? íŒŒì´í”„ë¼ì¸ì„ ì„¸ë¶„í™”í•˜ì—¬ ë‚´ë¶€ì—ì„œ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ ì˜ˆì‹œì—ì„œ íŒŒì´í”„ë¼ì¸ì—ëŠ” `UNet2DModel` ëª¨ë¸ê³¼ `DDPMScheduler`ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ì›í•˜ëŠ” ì¶œë ¥ í¬ê¸°ì˜ ëœë¤ ë…¸ì´ì¦ˆë¥¼ ë°›ì•„ ëª¨ë¸ì„ ì—¬ëŸ¬ë²ˆ í†µê³¼ì‹œì¼œ ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤. ê° timestepì—ì„œ ëª¨ë¸ì€ *noise residual*ì„ ì˜ˆì¸¡í•˜ê³  ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ì´ì¦ˆê°€ ì ì€ ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ì§€ì •ëœ ì¶”ë¡  ìŠ¤í…ìˆ˜ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì´ ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë³„ë„ë¡œ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ë‹¤ì‹œ ìƒì„±í•˜ê¸° ìœ„í•´ ìì²´ì ì¸ ë…¸ì´ì¦ˆ ì œê±° í”„ë¡œì„¸ìŠ¤ë¥¼ ì‘ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> from diffusers import DDPMScheduler, UNet2DModel\n",
    "\n",
    "    >>> scheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\n",
    "    >>> model = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\").to(\"cuda\")\n",
    "    ```\n",
    "\n",
    "2. ë…¸ì´ì¦ˆ ì œê±° í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•  timestep ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> scheduler.set_timesteps(50)\n",
    "    ```\n",
    "\n",
    "3. ìŠ¤ì¼€ì¤„ëŸ¬ì˜ timestepì„ ì„¤ì •í•˜ë©´ ê· ë“±í•œ ê°„ê²©ì˜ êµ¬ì„± ìš”ì†Œë¥¼ ê°€ì§„ í…ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤.(ì´ ì˜ˆì‹œì—ì„œëŠ” 50ê°œ) ê° ìš”ì†ŒëŠ” ëª¨ë¸ì´ ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” ì‹œê°„ ê°„ê²©ì— í•´ë‹¹í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ë¥¼ ë§Œë“¤ ë•Œ ì´ í…ì„œë¥¼ ë°˜ë³µí•˜ì—¬ ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> scheduler.timesteps\n",
    "    tensor([980, 960, 940, 920, 900, 880, 860, 840, 820, 800, 780, 760, 740, 720,\n",
    "        700, 680, 660, 640, 620, 600, 580, 560, 540, 520, 500, 480, 460, 440,\n",
    "        420, 400, 380, 360, 340, 320, 300, 280, 260, 240, 220, 200, 180, 160,\n",
    "        140, 120, 100,  80,  60,  40,  20,   0])\n",
    "    ```\n",
    "\n",
    "4. ì›í•˜ëŠ” ì¶œë ¥ê³¼ ê°™ì€ ëª¨ì–‘ì„ ê°€ì§„ ëœë¤ ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> import torch\n",
    "\n",
    "    >>> sample_size = model.config.sample_size\n",
    "    >>> noise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "    ```\n",
    "\n",
    "5. ì´ì œ timestepì„ ë°˜ë³µí•˜ëŠ” ë£¨í”„ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ê° timestepì—ì„œ ëª¨ë¸ì€ `UNet2DModel.forward()`ë¥¼ í†µí•´ noisy residualì„ ë°˜í™˜í•©ë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ëŸ¬ì˜ `step()` ë©”ì„œë“œëŠ” noisy residual, timestep, ê·¸ë¦¬ê³  ì…ë ¥ì„ ë°›ì•„ ì´ì „ timestepì—ì„œ ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ ì¶œë ¥ì€ ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ì˜ ëª¨ë¸ì— ëŒ€í•œ ë‹¤ìŒ ì…ë ¥ì´ ë˜ë©°, `timesteps` ë°°ì—´ì˜ ëì— ë„ë‹¬í•  ë•Œê¹Œì§€ ë°˜ë³µë©ë‹ˆë‹¤.\n",
    "\n",
    "    ```py\n",
    "    >>> input = noise\n",
    "\n",
    "    >>> for t in scheduler.timesteps:\n",
    "    ...     with torch.no_grad():\n",
    "    ...         noisy_residual = model(input, t).sample\n",
    "    ...     previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "    ...     input = previous_noisy_sample\n",
    "    ```\n",
    "\n",
    "    ì´ê²ƒì´ ì „ì²´ ë…¸ì´ì¦ˆ ì œê±° í”„ë¡œì„¸ìŠ¤ì´ë©°, ë™ì¼í•œ íŒ¨í„´ì„ ì‚¬ìš©í•´ ëª¨ë“  diffusion ì‹œìŠ¤í…œì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "6. ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ë…¸ì´ì¦ˆê°€ ì œê±°ëœ ì¶œë ¥ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> from PIL import Image\n",
    "    >>> import numpy as np\n",
    "\n",
    "    >>> image = (input / 2 + 0.5).clamp(0, 1)\n",
    "    >>> image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "    >>> image = Image.fromarray((image * 255).round().astype(\"uint8\"))\n",
    "    >>> image\n",
    "    ```\n",
    "\n",
    "ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” ì—¬ëŸ¬ë¶„ì˜ ê¸°ìˆ ì„ ì‹œí—˜í•´ë³´ê³  ì¢€ ë” ë³µì¡í•œ Stable Diffusion íŒŒì´í”„ë¼ì¸ì„ ë¶„ì„í•´ ë³´ê² ìŠµë‹ˆë‹¤. ë°©ë²•ì€ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤. í•„ìš”í•œ êµ¬ì„±ìš”ì†Œë“¤ì„ ì´ˆê¸°í™”í•˜ê³  timestepìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ `timestep` ë°°ì—´ì„ ìƒì„±í•©ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ì—ì„œ `timestep` ë°°ì—´ì´ ì‚¬ìš©ë˜ë©°, ì´ ë°°ì—´ì˜ ê° ìš”ì†Œì— ëŒ€í•´ ëª¨ë¸ì€ ë…¸ì´ì¦ˆê°€ ì ì€ ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ëŠ” `timestep`ì„ ë°˜ë³µí•˜ê³  ê° timestepì—ì„œ noise residualì„ ì¶œë ¥í•˜ê³  ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ timestepì—ì„œ ë…¸ì´ì¦ˆê°€ ëœí•œ ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ í”„ë¡œì„¸ìŠ¤ëŠ” `timestep` ë°°ì—´ì˜ ëì— ë„ë‹¬í•  ë•Œê¹Œì§€ ë°˜ë³µë©ë‹ˆë‹¤.\n",
    "\n",
    "í•œë²ˆ ì‚¬ìš©í•´ ë´…ì‹œë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion íŒŒì´í”„ë¼ì¸ í•´ì²´í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion ì€ text-to-image *latent diffusion* ëª¨ë¸ì…ë‹ˆë‹¤. latent diffusion ëª¨ë¸ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì´ìœ ëŠ” ì‹¤ì œ í”½ì…€ ê³µê°„ ëŒ€ì‹  ì´ë¯¸ì§€ì˜ ì €ì°¨ì›ì˜ í‘œí˜„ìœ¼ë¡œ ì‘ì—…í•˜ê¸° ë•Œë¬¸ì´ê³ , ë©”ëª¨ë¦¬ íš¨ìœ¨ì´ ë” ë†’ìŠµë‹ˆë‹¤. ì¸ì½”ë”ëŠ” ì´ë¯¸ì§€ë¥¼ ë” ì‘ì€ í‘œí˜„ìœ¼ë¡œ ì••ì¶•í•˜ê³ , ë””ì½”ë”ëŠ” ì••ì¶•ëœ í‘œí˜„ì„ ë‹¤ì‹œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. text-to-image ëª¨ë¸ì˜ ê²½ìš° í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ìœ„í•´ tokenizerì™€ ì¸ì½”ë”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ì „ ì˜ˆì œì—ì„œ ì´ë¯¸ UNet ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì€ ì•Œê³  ê³„ì…¨ì„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë³´ì‹œë‹¤ì‹œí”¼, ì´ê²ƒì€ UNet ëª¨ë¸ë§Œ í¬í•¨ëœ DDPM íŒŒì´í”„ë¼ì¸ë³´ë‹¤ ë” ë³µì¡í•©ë‹ˆë‹¤. Stable Diffusion ëª¨ë¸ì—ëŠ” ì„¸ ê°œì˜ ê°œë³„ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> [!TIP]\n",
    "> ğŸ’¡ VAE, UNet ë° í…ìŠ¤íŠ¸ ì¸ì½”ë” ëª¨ë¸ì˜ ì‘ë™ë°©ì‹ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [How does Stable Diffusion work?](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work) ë¸”ë¡œê·¸ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "ì´ì œ Stable Diffusion íŒŒì´í”„ë¼ì¸ì— í•„ìš”í•œ êµ¬ì„±ìš”ì†Œë“¤ì´ ë¬´ì—‡ì¸ì§€ ì•Œì•˜ìœ¼ë‹ˆ, `from_pretrained()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ëª¨ë“  êµ¬ì„±ìš”ì†Œë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì‚¬ì „í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ [`stable-diffusion-v1-5/stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìœ¼ë©°, ê° êµ¬ì„±ìš”ì†Œë“¤ì€ ë³„ë„ì˜ í•˜ìœ„ í´ë”ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"text_encoder\")\n",
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ `PNDMScheduler` ëŒ€ì‹ , `UniPCMultistepScheduler`ë¡œ êµì²´í•˜ì—¬ ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì–¼ë§ˆë‚˜ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UniPCMultistepScheduler\n",
    "\n",
    "scheduler = UniPCMultistepScheduler.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶”ë¡  ì†ë„ë¥¼ ë†’ì´ë ¤ë©´ ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë‹¬ë¦¬ í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë¯€ë¡œ ëª¨ë¸ì„ GPUë¡œ ì˜®ê¸°ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\"\n",
    "vae.to(torch_device)\n",
    "text_encoder.to(torch_device)\n",
    "unet.to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ë‹¨ê³„ëŠ” ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ëŠ” UNet ëª¨ë¸ì—ì„œ conditionìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ ìœ ì‚¬í•œ ë°©í–¥ìœ¼ë¡œ diffusion í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "> [!TIP]\n",
    "> ğŸ’¡ `guidance_scale` ë§¤ê°œë³€ìˆ˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ í”„ë¡¬í”„íŠ¸ì— ì–¼ë§ˆë‚˜ ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì‹¶ë‹¤ë©´ ì›í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ììœ ë¡­ê²Œ ì„ íƒí•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"a photograph of an astronaut riding a horse\"]\n",
    "height = 512  # Stable Diffusionì˜ ê¸°ë³¸ ë†’ì´\n",
    "width = 512  # Stable Diffusionì˜ ê¸°ë³¸ ë„ˆë¹„\n",
    "num_inference_steps = 25  # ë…¸ì´ì¦ˆ ì œê±° ìŠ¤í… ìˆ˜\n",
    "guidance_scale = 7.5  # classifier-free guidanceë¥¼ ìœ„í•œ scale\n",
    "generator = torch.manual_seed(0)  # ì´ˆê¸° ì ì¬ ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•˜ëŠ” seed generator\n",
    "batch_size = len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  í”„ë¡¬í”„íŠ¸ì—ì„œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tokenizer(\n",
    "    prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜í•œ íŒ¨ë”© í† í°ì˜ ì„ë² ë”©ì¸ *unconditional í…ìŠ¤íŠ¸ ì„ë² ë”©*ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì„ë² ë”©ì€ ì¡°ê±´ë¶€ `text_embeddings`ê³¼ ë™ì¼í•œ shape(`batch_size` ê·¸ë¦¬ê³  `seq_length`)ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‘ë²ˆì˜ forward passë¥¼ í”¼í•˜ê¸° ìœ„í•´ conditional ì„ë² ë”©ê³¼ unconditional ì„ë² ë”©ì„ ë°°ì¹˜(batch)ë¡œ ì—°ê²°í•˜ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëœë¤ ë…¸ì´ì¦ˆ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë‹¤ìŒ diffusion í”„ë¡œì„¸ìŠ¤ì˜ ì‹œì‘ì ìœ¼ë¡œ ì´ˆê¸° ëœë¤ ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ê²ƒì´ ì´ë¯¸ì§€ì˜ ì ì¬ì  í‘œí˜„ì´ë©° ì ì°¨ì ìœ¼ë¡œ ë…¸ì´ì¦ˆê°€ ì œê±°ë©ë‹ˆë‹¤. ì´ ì‹œì ì—ì„œ `latent` ì´ë¯¸ì§€ëŠ” ìµœì¢… ì´ë¯¸ì§€ í¬ê¸°ë³´ë‹¤ ì‘ì§€ë§Œ ë‚˜ì¤‘ì— ëª¨ë¸ì´ ì´ë¥¼ 512x512 ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜í•˜ë¯€ë¡œ ê´œì°®ìŠµë‹ˆë‹¤.\n",
    "\n",
    "> [!TIP]\n",
    "> ğŸ’¡ `vae` ëª¨ë¸ì—ëŠ” 3ê°œì˜ ë‹¤ìš´ ìƒ˜í”Œë§ ë ˆì´ì–´ê°€ ìˆê¸° ë•Œë¬¸ì— ë†’ì´ì™€ ë„ˆë¹„ê°€ 8ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    ">\n",
    "> ```py\n",
    "> 2 ** (len(vae.config.block_out_channels) - 1) == 8\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = torch.randn(\n",
    "    (batch_size, unet.config.in_channels, height // 8, width // 8),\n",
    "    generator=generator,\n",
    "    device=torch_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì € `UniPCMultistepScheduler`ì™€ ê°™ì€ í–¥ìƒëœ ìŠ¤ì¼€ì¤„ëŸ¬ì— í•„ìš”í•œ ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¼ ê°’ì¸ ì´ˆê¸° ë…¸ì´ì¦ˆ ë¶„í¬ *sigma* ë¡œ ì…ë ¥ì„ ìŠ¤ì¼€ì¼ë§ í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = latents * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” `latent`ì˜ ìˆœìˆ˜í•œ ë…¸ì´ì¦ˆë¥¼ ì ì§„ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ì„¤ëª…ëœ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ëŠ” ì„¸ ê°€ì§€ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”:\n",
    "\n",
    "1. ë…¸ì´ì¦ˆ ì œê±° ì¤‘ì— ì‚¬ìš©í•  ìŠ¤ì¼€ì¤„ëŸ¬ì˜ timestepsë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "2. timestepì„ ë”°ë¼ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "3. ê° timestepì—ì„œ UNet ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ noise residualì„ ì˜ˆì¸¡í•˜ê³  ìŠ¤ì¼€ì¤„ëŸ¬ì— ì „ë‹¬í•˜ì—¬ ì´ì „ ë…¸ì´ì¦ˆ ìƒ˜í”Œì„ ê³„ì‚°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "for t in tqdm(scheduler.timesteps):\n",
    "    # classifier-free guidanceë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²½ìš° ë‘ë²ˆì˜ forward passë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šë„ë¡ latentë¥¼ í™•ì¥.\n",
    "    latent_model_input = torch.cat([latents] * 2)\n",
    "\n",
    "    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n",
    "\n",
    "    # noise residual ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "\n",
    "    # guidance ìˆ˜í–‰\n",
    "    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "    # ì´ì „ ë…¸ì´ì¦ˆ ìƒ˜í”Œì„ ê³„ì‚° x_t -> x_t-1\n",
    "    latents = scheduler.step(noise_pred, t, latents).prev_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ë¯¸ì§€ ë””ì½”ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” `vae`ë¥¼ ì´ìš©í•˜ì—¬ ì ì¬ í‘œí˜„ì„ ì´ë¯¸ì§€ë¡œ ë””ì½”ë”©í•˜ê³  `sample`ê³¼ í•¨ê»˜ ë””ì½”ë”©ëœ ì¶œë ¥ì„ ì–»ëŠ” ê²ƒì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latentë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ê³  vaeë¡œ ì´ë¯¸ì§€ ë””ì½”ë”©\n",
    "latents = 1 / 0.18215 * latents\n",
    "with torch.no_grad():\n",
    "    image = vae.decode(latents).sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ `PIL.Image`ë¡œ ë³€í™˜í•˜ë©´ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (image / 2 + 0.5).clamp(0, 1)\n",
    "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "images = (image * 255).round().astype(\"uint8\")\n",
    "pil_images = [Image.fromarray(image) for image in images]\n",
    "pil_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_k_lms.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ë¶€í„° ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ê¹Œì§€, ìì‹ ë§Œì˜ diffusion ì‹œìŠ¤í…œì„ ì‘ì„±í•˜ëŠ” ë° í•„ìš”í•œ ê²ƒì€ ë…¸ì´ì¦ˆ ì œê±° ë£¨í”„ë¿ì´ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ ë£¨í”„ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ì˜ timestepsë¥¼ ì„¤ì •í•˜ê³ , ì´ë¥¼ ë°˜ë³µí•˜ë©°, UNet ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ noise residualì„ ì˜ˆì¸¡í•˜ê³  ìŠ¤ì¼€ì¤„ëŸ¬ì— ì „ë‹¬í•˜ì—¬ ì´ì „ ë…¸ì´ì¦ˆ ìƒ˜í”Œì„ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì„ ë²ˆê°ˆì•„ ê°€ë©° ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ê²ƒì´ ë°”ë¡œ ğŸ§¨ Diffusersê°€ ì„¤ê³„ëœ ëª©ì ì…ë‹ˆë‹¤: ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•´ ìì‹ ë§Œì˜ diffusion ì‹œìŠ¤í…œì„ ì§ê´€ì ì´ê³  ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ë‹¨ê³„ë¥¼ ììœ ë¡­ê²Œ ì§„í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "* ğŸ§¨ Diffusersì— [íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° ê¸°ì—¬](https://huggingface.co/docs/diffusers/main/ko/using-diffusers/using-diffusers/#contribute_pipeline)í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”. ì—¬ëŸ¬ë¶„ì´ ì–´ë–¤ ì•„ì´ë””ì–´ë¥¼ ë‚´ë†“ì„ì§€ ê¸°ëŒ€ë©ë‹ˆë‹¤!\n",
    "* ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ [ê¸°ë³¸ íŒŒì´í”„ë¼ì¸](https://huggingface.co/docs/diffusers/main/ko/using-diffusers/./api/pipelines/overview)ì„ ì‚´í´ë³´ê³ , ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë³„ë„ë¡œ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì²˜ìŒë¶€í„° í•´ì²´í•˜ê³  ë¹Œë“œí•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
