{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "! pip install smolagents\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# ! pip install git+https://github.com/huggingface/smolagents.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ìš©í•˜ê¸° [[using-different-models]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`smolagents`ëŠ” ë‹¤ì–‘í•œ í”„ë¡œë°”ì´ë”ì˜ ì—¬ëŸ¬ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìœ ì—°í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ì´ ê°€ì´ë“œëŠ” ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ë‹¤ì–‘í•œ ëª¨ë¸ ìœ í˜•ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìœ í˜• [[available-model-types]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`smolagents`ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì—¬ëŸ¬ ëª¨ë¸ ìœ í˜•ì„ ì§€ì›í•©ë‹ˆë‹¤:\n",
    "1. [InferenceClientModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.InferenceClientModel): Hugging Faceì˜ ì¶”ë¡  APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ì ‘ê·¼\n",
    "2. [TransformersModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.TransformersModel): ğŸ¤— Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ ëª¨ë¸ ì‹¤í–‰\n",
    "3. [VLLMModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.VLLMModel): ìµœì í™”ëœ ì„œë¹™ìœ¼ë¡œ ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ vLLM ì‚¬ìš©\n",
    "4. [MLXModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.MLXModel): MLXë¥¼ ì‚¬ìš©í•˜ì—¬ Apple Silicon ë””ë°”ì´ìŠ¤ì— ìµœì í™”\n",
    "5. [LiteLLMModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.LiteLLMModel): LiteLLMì„ í†µí•´ ìˆ˜ë°± ê°œì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ì ‘ê·¼ ì œê³µ\n",
    "6. [LiteLLMRouterModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.LiteLLMRouterModel): ì—¬ëŸ¬ ëª¨ë¸ ê°„ì— ìš”ì²­ì„ ë¶„ì‚°\n",
    "7. [OpenAIServerModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.OpenAIModel): OpenAI í˜¸í™˜ APIë¥¼ êµ¬í˜„í•˜ëŠ” ëª¨ë“  í”„ë¡œë°”ì´ë”ì— ì ‘ê·¼ ì œê³µ\n",
    "8. [AzureOpenAIServerModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.AzureOpenAIModel): Azureì˜ OpenAI ì„œë¹„ìŠ¤ ì‚¬ìš©\n",
    "9. [AmazonBedrockServerModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.AmazonBedrockModel): AWS Bedrockì˜ APIì— ì—°ê²°\n",
    "\n",
    "ëª¨ë“  ëª¨ë¸ í´ë˜ìŠ¤ëŠ” ì¸ìŠ¤í„´ìŠ¤í™” ì‹œì ì— ì¶”ê°€ í‚¤ì›Œë“œ ì¸ìˆ˜ë“¤(`temperature`, `max_tokens`, `top_p` ë“±)ì„ ì§ì ‘ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "ì´ëŸ¬í•œ ë§¤ê°œë³€ìˆ˜ë“¤ì€ ìë™ìœ¼ë¡œ ê¸°ë³¸ ëª¨ë¸ì˜ ì™„ì„± í˜¸ì¶œë¡œ ì „ë‹¬ë˜ì–´, ì°½ì˜ì„±, ì‘ë‹µ ê¸¸ì´, ìƒ˜í”Œë§ ì „ëµê³¼ ê°™ì€ ëª¨ë¸ ë™ì‘ì„ êµ¬ì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemini ëª¨ë¸ ì‚¬ìš©í•˜ê¸° [[using-google-gemini-models]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Gemini API ë¬¸ì„œ(https://ai.google.dev/gemini-api/docs/openai)ì—ì„œ ì„¤ëª…í•œ ë°”ì™€ ê°™ì´,\n",
    "Googleì€ Gemini ëª¨ë¸ì— ëŒ€í•´ OpenAI í˜¸í™˜ APIë¥¼ ì œê³µí•˜ë¯€ë¡œ, ì ì ˆí•œ ë² ì´ìŠ¤ URLì„ ì„¤ì •í•˜ì—¬\n",
    "[OpenAIServerModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.OpenAIModel)ì„ Gemini ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì €, í•„ìš”í•œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:\n",
    "```bash\n",
    "pip install 'smolagents[openai]'\n",
    "```\n",
    "\n",
    "ê·¸ë‹¤ìŒ, [Gemini API í‚¤ë¥¼ ì–»ê³ ](https://ai.google.dev/gemini-api/docs/api-key) ì½”ë“œì—ì„œ ì„¤ì •í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = <YOUR-GEMINI-API-KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `OpenAIServerModel` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê³  `api_base` ë§¤ê°œë³€ìˆ˜ë¥¼ Gemini API ë² ì´ìŠ¤ URLë¡œ ì„¤ì •í•˜ì—¬\n",
    "Gemini ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import OpenAIServerModel\n",
    "\n",
    "model = OpenAIServerModel(\n",
    "    model_id=\"gemini-2.0-flash\",\n",
    "    # Google Gemini OpenAI í˜¸í™˜ API ë² ì´ìŠ¤ URL\n",
    "    api_base=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenRouter ëª¨ë¸ ì‚¬ìš©í•˜ê¸° [[using-openrouter-models]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenRouterëŠ” í†µí•©ëœ OpenAI í˜¸í™˜ APIë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ì ‘ê·¼ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ì ì ˆí•œ ë² ì´ìŠ¤ URLì„ ì„¤ì •í•˜ì—¬ [OpenAIServerModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.OpenAIModel)ì„ ì‚¬ìš©í•´ OpenRouterì— ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì €, í•„ìš”í•œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:\n",
    "```bash\n",
    "pip install 'smolagents[openai]'\n",
    "```\n",
    "\n",
    "ê·¸ë‹¤ìŒ, [OpenRouter API í‚¤ë¥¼ ì–»ê³ ](https://openrouter.ai/keys) ì½”ë“œì—ì„œ ì„¤ì •í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = <YOUR-OPENROUTER-API-KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `OpenAIServerModel` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ OpenRouterì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import OpenAIServerModel\n",
    "\n",
    "model = OpenAIServerModel(\n",
    "    # OpenRouterì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ IDë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "    model_id=\"openai/gpt-4o\",\n",
    "    # OpenRouter API ë² ì´ìŠ¤ URL\n",
    "    api_base=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xAIì˜ Grok ëª¨ë¸ ì‚¬ìš©í•˜ê¸° [[using-xais-grok-models]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xAIì˜ Grok ëª¨ë¸ì€ [LiteLLMModel](https://huggingface.co/docs/smolagents/main/ko/reference/models#smolagents.LiteLLMModel)ì„ í†µí•´ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì¼ë¶€ ëª¨ë¸(\"grok-4\" ë° \"grok-3-mini\" ë“±)ì€ `stop` ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ,\n",
    "API í˜¸ì¶œì—ì„œ ì´ë¥¼ ì œì™¸í•˜ê¸° ìœ„í•´ `REMOVE_PARAMETER`ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì €, í•„ìš”í•œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:\n",
    "```bash\n",
    "pip install smolagents[litellm]\n",
    "```\n",
    "\n",
    "ê·¸ë‹¤ìŒ, [xAI API í‚¤ë¥¼ ì–»ê³ ](https://console.x.ai/) ì½”ë“œì—ì„œ ì„¤ì •í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XAI_API_KEY = <YOUR-XAI-API-KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `LiteLLMModel` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Grok ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  í•´ë‹¹ë˜ëŠ” ê²½ìš° `stop` ë§¤ê°œë³€ìˆ˜ë¥¼ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel, REMOVE_PARAMETER\n",
    "\n",
    "# Grok-4 ì‚¬ìš©\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"xai/grok-4\",\n",
    "    api_key=XAI_API_KEY,\n",
    "    stop=REMOVE_PARAMETER,  # grok-4 ëª¨ë¸ì´ ì´ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ stop ë§¤ê°œë³€ìˆ˜ ì œê±°\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ë˜ëŠ” Grok-3-mini ì‚¬ìš©\n",
    "model_mini = LiteLLMModel(\n",
    "    model_id=\"xai/grok-3-mini\",\n",
    "    api_key=XAI_API_KEY,\n",
    "    stop=REMOVE_PARAMETER,  # grok-3-mini ëª¨ë¸ì´ ì´ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ stop ë§¤ê°œë³€ìˆ˜ ì œê±°\n",
    "    max_tokens=1000\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
