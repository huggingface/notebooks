{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "! pip install smolagents\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# ! pip install git+https://github.com/huggingface/smolagents.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-Augmented-Generation (RAG) æ˜¯â€œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ï¼Œä½†åŸºäºä»çŸ¥è¯†åº“ä¸­æ£€ç´¢çš„ä¿¡æ¯â€ã€‚å®ƒæ¯”ä½¿ç”¨æ™®é€šæˆ–å¾®è°ƒçš„ LLM å…·æœ‰è®¸å¤šä¼˜åŠ¿ï¼šä¸¾å‡ ä¸ªä¾‹å­ï¼Œå®ƒå…è®¸å°†ç­”æ¡ˆåŸºäºçœŸå®äº‹å®å¹¶å‡å°‘è™šæ„ï¼›å®ƒå…è®¸æä¾› LLM é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†ï¼›å¹¶å…è®¸å¯¹çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯è®¿é—®è¿›è¡Œç²¾ç»†æ§åˆ¶ã€‚\n",
    "\n",
    "ä½†æ˜¯ï¼Œæ™®é€šçš„ RAG å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œä»¥ä¸‹ä¸¤ç‚¹å°¤ä¸ºçªå‡ºï¼š\n",
    "\n",
    "- å®ƒåªæ‰§è¡Œä¸€æ¬¡æ£€ç´¢æ­¥éª¤ï¼šå¦‚æœç»“æœä¸å¥½ï¼Œç”Ÿæˆçš„å†…å®¹ä¹Ÿä¼šä¸å¥½ã€‚\n",
    "- è¯­ä¹‰ç›¸ä¼¼æ€§æ˜¯ä»¥ç”¨æˆ·æŸ¥è¯¢ä¸ºå‚è€ƒè®¡ç®—çš„ï¼Œè¿™å¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„ï¼šä¾‹å¦‚ï¼Œç”¨æˆ·æŸ¥è¯¢é€šå¸¸æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œè€ŒåŒ…å«çœŸå®ç­”æ¡ˆçš„æ–‡æ¡£é€šå¸¸æ˜¯è‚¯å®šè¯­æ€ï¼Œå› æ­¤å…¶ç›¸ä¼¼æ€§å¾—åˆ†ä¼šæ¯”å…¶ä»–ä»¥ç–‘é—®å½¢å¼å‘ˆç°çš„æºæ–‡æ¡£ä½ï¼Œä»è€Œå¯¼è‡´é”™å¤±ç›¸å…³ä¿¡æ¯çš„é£é™©ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ¶ä½œä¸€ä¸ª RAG  agentæ¥ç¼“è§£è¿™äº›é—®é¢˜ï¼šéå¸¸ç®€å•ï¼Œä¸€ä¸ªé…å¤‡äº†æ£€ç´¢å·¥å…·çš„agentï¼è¿™ä¸ª agent å°†\n",
    "ä¼šï¼šâœ… è‡ªå·±æ„å»ºæŸ¥è¯¢å’Œæ£€ç´¢ï¼Œâœ… å¦‚æœéœ€è¦çš„è¯ä¼šé‡æ–°æ£€ç´¢ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œå®ƒå°†æ¯”æ™®é€š RAG æ›´æ™ºèƒ½ï¼Œå› ä¸ºå®ƒå¯ä»¥è‡ªå·±æ„å»ºæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨ç”¨æˆ·æŸ¥è¯¢ä½œä¸ºå‚è€ƒã€‚è¿™æ ·ï¼Œå®ƒå¯ä»¥æ›´\n",
    "æ¥è¿‘ç›®æ ‡æ–‡æ¡£ï¼Œä»è€Œæé«˜æ£€ç´¢çš„å‡†ç¡®æ€§ï¼Œ [HyDE](https://huggingface.co/papers/2212.10496)ã€‚æ­¤ agent å¯ä»¥\n",
    "ä½¿ç”¨ç”Ÿæˆçš„ç‰‡æ®µï¼Œå¹¶åœ¨éœ€è¦æ—¶é‡æ–°æ£€ç´¢ï¼Œå°±åƒ [Self-Query](https://docs.llamaindex.ai/en/stable/examples/evaluation/RetryQuery/)ã€‚\n",
    "\n",
    "æˆ‘ä»¬ç°åœ¨å¼€å§‹æ„å»ºè¿™ä¸ªç³»ç»Ÿ. ğŸ› ï¸\n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç ä»¥å®‰è£…æ‰€éœ€çš„ä¾èµ–åŒ…ï¼š\n",
    "```bash\n",
    "!pip install smolagents pandas langchain langchain-community sentence-transformers rank_bm25 --upgrade -q\n",
    "```\n",
    "\n",
    "ä½ éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„ token ä½œä¸ºç¯å¢ƒå˜é‡ `HF_TOKEN` æ¥è°ƒç”¨ Inference Providersã€‚æˆ‘ä»¬ä½¿ç”¨ python-dotenv æ¥åŠ è½½å®ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸€ä¸ªçŸ¥è¯†åº“ä»¥åœ¨å…¶ä¸Šæ‰§è¡Œ RAGï¼šæ­¤æ•°æ®é›†æ˜¯è®¸å¤š Hugging Face åº“çš„æ–‡æ¡£é¡µé¢çš„æ±‡ç¼–ï¼Œå­˜å‚¨ä¸º markdown æ ¼å¼ã€‚æˆ‘ä»¬å°†ä»…ä¿ç•™ `transformers` åº“çš„æ–‡æ¡£ã€‚ç„¶åé€šè¿‡å¤„ç†æ•°æ®é›†å¹¶å°†å…¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œä¸ºæ£€ç´¢å™¨å‡†å¤‡çŸ¥è¯†åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [LangChain](https://python.langchain.com/docs/introduction/) æ¥åˆ©ç”¨å…¶å‡ºè‰²çš„å‘é‡æ•°æ®åº“å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
    "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ–‡æ¡£å·²å‡†å¤‡å¥½ã€‚æˆ‘ä»¬æ¥ä¸€èµ·æ„å»ºæˆ‘ä»¬çš„ agent RAG ç³»ç»Ÿï¼\n",
    "ğŸ‘‰ æˆ‘ä»¬åªéœ€è¦ä¸€ä¸ª RetrieverToolï¼Œæˆ‘ä»¬çš„ agent å¯ä»¥åˆ©ç”¨å®ƒä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ã€‚\n",
    "\n",
    "ç”±äºæˆ‘ä»¬éœ€è¦å°† vectordb æ·»åŠ ä¸ºå·¥å…·çš„å±æ€§ï¼Œæˆ‘ä»¬ä¸èƒ½ç®€å•åœ°ä½¿ç”¨å¸¦æœ‰ `@tool` è£…é¥°å™¨çš„ç®€å•å·¥å…·æ„é€ å‡½æ•°ï¼šå› æ­¤æˆ‘ä»¬å°†éµå¾ª [tools æ•™ç¨‹](https://huggingface.co/docs/smolagents/main/zh/examples/../tutorials/tools) ä¸­çªå‡ºæ˜¾ç¤ºçš„é«˜çº§è®¾ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=10\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 æ£€ç´¢æ–¹æ³•æ˜¯ä¸€ä¸ªç»å…¸çš„æ£€ç´¢æ–¹æ³•ï¼Œå› ä¸ºå®ƒçš„è®¾ç½®é€Ÿåº¦éå¸¸å¿«ã€‚ä¸ºäº†æé«˜æ£€ç´¢å‡†ç¡®æ€§ï¼Œä½ å¯ä»¥ä½¿ç”¨è¯­ä¹‰æœç´¢ï¼Œä½¿ç”¨æ–‡æ¡£çš„å‘é‡è¡¨ç¤ºæ›¿æ¢ BM25ï¼šå› æ­¤ä½ å¯ä»¥å‰å¾€ [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) é€‰æ‹©ä¸€ä¸ªå¥½çš„åµŒå…¥æ¨¡å‹ã€‚\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ä¸€ä¸ªå¯ä»¥ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯çš„å·¥å…·ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°åˆ›å»ºä¸€ä¸ªåˆ©ç”¨è¿™ä¸ª\n",
    "`retriever_tool` çš„ agentï¼æ­¤ agent å°†ä½¿ç”¨å¦‚ä¸‹å‚æ•°åˆå§‹åŒ–ï¼š\n",
    "- `tools`ï¼šä»£ç†å°†èƒ½å¤Ÿè°ƒç”¨çš„å·¥å…·åˆ—è¡¨ã€‚\n",
    "- `model`ï¼šä¸ºä»£ç†æä¾›åŠ¨åŠ›çš„ LLMã€‚\n",
    "\n",
    "æˆ‘ä»¬çš„ `model` å¿…é¡»æ˜¯ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå®ƒæ¥å—ä¸€ä¸ªæ¶ˆæ¯çš„ list ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›æ–‡æœ¬ã€‚å®ƒè¿˜éœ€è¦æ¥å—ä¸€ä¸ª stop_sequences å‚æ•°ï¼ŒæŒ‡ç¤ºä½•æ—¶åœæ­¢ç”Ÿæˆã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨åŒ…ä¸­æä¾›çš„ `HfEngine` ç±»æ¥è·å–è°ƒç”¨ Hugging Face çš„ Inference API çš„ LLM å¼•æ“ã€‚\n",
    "\n",
    "æ¥ç€ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/docs/smolagents/main/zh/examples/meta-llama/Llama-3.3-70B-Instruct) ä½œä¸º llm å¼•\n",
    "æ“ï¼Œå› ä¸ºï¼š\n",
    "- å®ƒæœ‰ä¸€ä¸ªé•¿ 128k ä¸Šä¸‹æ–‡ï¼Œè¿™å¯¹å¤„ç†é•¿æºæ–‡æ¡£å¾ˆæœ‰ç”¨ã€‚\n",
    "- å®ƒåœ¨ HF çš„ Inference API ä¸Šå§‹ç»ˆå…è´¹æä¾›ï¼\n",
    "\n",
    "_Note:_ æ­¤ Inference API æ‰˜ç®¡åŸºäºå„ç§æ ‡å‡†çš„æ¨¡å‹ï¼Œéƒ¨ç½²çš„æ¨¡å‹å¯èƒ½ä¼šåœ¨æ²¡æœ‰äº‹å…ˆé€šçŸ¥çš„æƒ…å†µä¸‹è¿›è¡Œæ›´æ–°æˆ–æ›¿æ¢ã€‚äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](https://huggingface.co/docs/api-inference/supported-models)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import InferenceClientModel, CodeAgent\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool], model=InferenceClientModel(model_id=\"meta-llama/Llama-3.3-70B-Instruct\"), max_steps=4, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“æˆ‘ä»¬åˆå§‹åŒ– CodeAgent æ—¶ï¼Œå®ƒå·²ç»è‡ªåŠ¨è·å¾—äº†ä¸€ä¸ªé»˜è®¤çš„ç³»ç»Ÿæç¤ºï¼Œå‘Šè¯‰ LLM å¼•æ“æŒ‰æ­¥éª¤å¤„ç†å¹¶ç”Ÿæˆå·¥å…·è°ƒç”¨ä½œä¸ºä»£ç ç‰‡æ®µï¼Œä½†ä½ å¯ä»¥æ ¹æ®éœ€è¦æ›¿æ¢æ­¤æç¤ºæ¨¡æ¿ã€‚æ¥ç€ï¼Œå½“å…¶ `.run()` æ–¹æ³•è¢«è°ƒç”¨æ—¶ï¼Œä»£ç†å°†è´Ÿè´£è°ƒç”¨ LLM å¼•æ“ï¼Œå¹¶åœ¨å¾ªç¯ä¸­æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œç›´åˆ°å·¥å…· `final_answer` è¢«è°ƒç”¨ï¼Œè€Œå…¶å‚æ•°ä¸ºæœ€ç»ˆç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
