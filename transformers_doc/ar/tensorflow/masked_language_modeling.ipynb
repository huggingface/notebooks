{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers installation\n",
    "! pip install transformers datasets evaluate accelerate\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© (Masked language modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/mqElG5QJWUg?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/mqElG5QJWUg?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ØªØªÙ†Ø¨Ø£ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ø¨Ø±Ù…Ø² Ù…Ù‚Ù†Ø¹ ÙÙŠ ØªØ³Ù„Ø³Ù„ØŒ ÙˆÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø±Ù…ÙˆØ² Ø¨Ø´ÙƒÙ„ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø§ØªØ¬Ø§Ù‡. Ù‡Ø°Ø§\n",
    "ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¯ÙŠÙ‡ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø± ÙˆØ§Ù„ÙŠÙ…ÙŠÙ†. ØªØ¹Ø¯ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ù…Ù…ØªØ§Ø²Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªÙŠ\n",
    "ØªØªØ·Ù„Ø¨ ÙÙ‡Ù…Ù‹Ø§ Ø³ÙŠØ§Ù‚ÙŠÙ‹Ø§ Ø¬ÙŠØ¯Ù‹Ø§ Ù„ØªØ³Ù„Ø³Ù„ ÙƒØ§Ù…Ù„. BERT Ù‡Ùˆ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ù„ØºØ© Ù…Ù‚Ù†Ø¹.\n",
    "\n",
    "Ø³ÙŠÙˆØ¶Ø­ Ù„Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ©:\n",
    "\n",
    "1. ØªÙƒÙŠÙŠÙ [DistilRoBERTa](https://huggingface.co/distilbert/distilroberta-base) Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙØ±Ø¹ÙŠØ© [r/askscience](https://www.reddit.com/r/askscience/) Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [ELI5](https://huggingface.co/datasets/eli5).\n",
    "2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "Ù„Ù…Ø¹Ø±ÙØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨Ù†Ù‰ ÙˆØ§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ Ù†ÙˆØµÙŠ Ø¨Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† [ØµÙØ­Ø© Ø§Ù„Ù…Ù‡Ù…Ø©](https://huggingface.co/tasks/fill-mask)\n",
    "\n",
    "</Tip>\n",
    "\n",
    "Ù‚Ø¨Ù„ Ø£Ù† ØªØ¨Ø¯Ø£ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:\n",
    "\n",
    "```bash\n",
    "pip install transformers datasets evaluate\n",
    "```\n",
    "\n",
    "Ù†Ø­Ù† Ù†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ø¹Ù†Ø¯Ù…Ø§ ØªØªÙ… Ù…Ø·Ø§Ù„Ø¨ØªÙƒØŒ Ø£Ø¯Ø®Ù„ Ø±Ù…Ø²Ùƒ Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ELI5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ø£ÙˆÙ„ 5000 Ù…Ø«Ø§Ù„ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [ELI5-Category](https://huggingface.co/datasets/eli5_category) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© ğŸ¤— Datasets. Ø³ÙŠØ¹Ø·ÙŠÙƒ Ù‡Ø°Ø§ ÙØ±ØµØ© Ù„Ù„ØªØ¬Ø±Ø¨Ø© ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† ÙƒÙ„ Ø´ÙŠØ¡ ÙŠØ¹Ù…Ù„ Ù‚Ø¨Ù„ Ù‚Ø¶Ø§Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eli5 = load_dataset(\"eli5_category\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ù‚Ù… Ø¨ØªÙ‚Ø³ÙŠÙ… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª `train` Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹ØªÙŠ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© `train_test_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø«Ù… Ø£Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '7h191n',\n",
       " 'title': 'What does the tax bill that was passed today mean? How will it affect Americans in each tax bracket?',\n",
       " 'selftext': '',\n",
       " 'category': 'Economics',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dqnds8l', 'dqnd1jl', 'dqng3i1', 'dqnku5x'],\n",
       "  'text': [\"The tax bill is 500 pages long and there were a lot of changes still going on right to the end. It's not just an adjustment to the income tax brackets, it's a whole bunch of changes. As such there is no good answer to your question. The big take aways are: - Big reduction in corporate income tax rate will make large companies very happy. - Pass through rate change will make certain styles of business (law firms, hedge funds) extremely happy - Income tax changes are moderate, and are set to expire (though it's the kind of thing that might just always get re-applied without being made permanent) - People in high tax states (California, New York) lose out, and many of them will end up with their taxes raised.\",\n",
       "   'None yet. It has to be reconciled with a vastly different house bill and then passed again.',\n",
       "   'Also: does this apply to 2017 taxes? Or does it start with 2018 taxes?',\n",
       "   'This article explains both the House and senate bills, including the proposed changes to your income taxes based on your income level. URL_0'],\n",
       "  'score': [21, 19, 5, 3],\n",
       "  'text_urls': [[],\n",
       "   [],\n",
       "   [],\n",
       "   ['https://www.investopedia.com/news/trumps-tax-reform-what-can-be-done/']]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ù‡Ø°Ø§ Ù‚Ø¯ ÙŠØ¨Ø¯Ùˆ ÙƒØ«ÙŠØ±Ù‹Ø§ØŒ Ø¥Ù„Ø§ Ø£Ù†Ùƒ Ù…Ù‡ØªÙ… Ø­Ù‚Ù‹Ø§ Ø¨Ø­Ù‚Ù„ `text`. Ù…Ø§ Ù‡Ùˆ Ø±Ø§Ø¦Ø¹ Ø­ÙˆÙ„ Ù…Ù‡Ø§Ù… Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ù‡Ùˆ Ø£Ù†Ùƒ Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ³Ù…ÙŠØ§Øª (ØªÙØ¹Ø±Ù Ø£ÙŠØ¶Ù‹Ø§ Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ù‡Ù…Ø© ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹Ø© Ù„Ù„Ø¥Ø´Ø±Ø§Ù) Ù„Ø£Ù† Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© *Ù‡ÙŠ* Ø§Ù„ØªØ³Ù…ÙŠØ©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© (Preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8PmhEIXhBvI?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8PmhEIXhBvI?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©ØŒ ÙØ¥Ù† Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ DistilRoBERTa Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚Ù„ `text` Ø§Ù„ÙØ±Ø¹ÙŠ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø³ØªÙ„Ø§Ø­Ø¸ Ù…Ù† Ø§Ù„Ù…Ø«Ø§Ù„ Ø£Ø¹Ù„Ø§Ù‡ØŒ Ø£Ù† Ø­Ù‚Ù„ `text` Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¯Ø§Ø®Ù„ `answers`. Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ùƒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ù‚Ù„ `text` Ø§Ù„ÙØ±Ø¹ÙŠ Ù…Ù† Ø¨Ù†ÙŠØªÙ‡ Ø§Ù„Ù…Ø¶Ù…Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© [`flatten`](https://huggingface.co/docs/datasets/process#flatten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '7h191n',\n",
       " 'title': 'What does the tax bill that was passed today mean? How will it affect Americans in each tax bracket?',\n",
       " 'selftext': '',\n",
       " 'category': 'Economics',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers.a_id': ['dqnds8l', 'dqnd1jl', 'dqng3i1', 'dqnku5x'],\n",
       " 'answers.text': [\"The tax bill is 500 pages long and there were a lot of changes still going on right to the end. It's not just an adjustment to the income tax brackets, it's a whole bunch of changes. As such there is no good answer to your question. The big take aways are: - Big reduction in corporate income tax rate will make large companies very happy. - Pass through rate change will make certain styles of business (law firms, hedge funds) extremely happy - Income tax changes are moderate, and are set to expire (though it's the kind of thing that might just always get re-applied without being made permanent) - People in high tax states (California, New York) lose out, and many of them will end up with their taxes raised.\",\n",
       "  'None yet. It has to be reconciled with a vastly different house bill and then passed again.',\n",
       "  'Also: does this apply to 2017 taxes? Or does it start with 2018 taxes?',\n",
       "  'This article explains both the House and senate bills, including the proposed changes to your income taxes based on your income level. URL_0'],\n",
       " 'answers.score': [21, 19, 5, 3],\n",
       " 'answers.text_urls': [[],\n",
       "  [],\n",
       "  [],\n",
       "  ['https://www.investopedia.com/news/trumps-tax-reform-what-can-be-done/']],\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5 = eli5.flatten()\n",
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÙƒÙ„ Ø­Ù‚Ù„ ÙØ±Ø¹ÙŠ Ù‡Ùˆ Ø§Ù„Ø¢Ù† Ø¹Ù…ÙˆØ¯ Ù…Ù†ÙØµÙ„ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ Ø¨ÙˆØ§Ø³Ø·Ø© Ø¨Ø§Ø¯Ø¦Ø© `answers`ØŒ ÙˆØ­Ù‚Ù„ `text` Ù‡Ùˆ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¢Ù†. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†\n",
    "Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¬Ù…Ù„Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„ØŒ Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ø¨Ø´ÙƒÙ„ Ù…Ø´ØªØ±Ùƒ.\n",
    "\n",
    "Ù‡Ù†Ø§ Ø£ÙˆÙ„ Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ø±Ø¨Ø· Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ù„ÙƒÙ„ Ù…Ø«Ø§Ù„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§Ù„Ø© ğŸ¤— Datasets `map`. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ³Ø±ÙŠØ¹ Ø¯Ø§Ù„Ø© `map` Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† `batched=True` Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ø© Ø¹Ù†Ø§ØµØ± ÙÙŠ ÙˆÙ‚Øª ÙˆØ§Ø­Ø¯ØŒ ÙˆØ²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `num_proc`. Ø§Ø­Ø°Ù Ø£ÙŠ Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠØ©:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=eli5[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ØªØ­ØªÙˆÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‡Ø°Ù‡ Ø¹Ù„Ù‰ ØªØ³Ù„Ø³Ù„Ø§Øª Ø±Ù…Ø²ÙŠØ©ØŒ ÙˆÙ„ÙƒÙ† Ø¨Ø¹Ø¶Ù‡Ø§ Ø£Ø·ÙˆÙ„ Ù…Ù† Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬.\n",
    "\n",
    "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ø«Ø§Ù†ÙŠØ© Ù„Ù€:\n",
    "- ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª\n",
    "- ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ù‘Ø¹Ø© Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ø£Ù‚ØµØ± Ù…Ø­Ø¯Ø¯Ø© Ø¨Ù€ `block_size`ØŒ ÙˆØ§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£Ù‚ØµØ± Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆÙ…Ù†Ø§Ø³Ø¨Ø© Ù„Ø°Ø§ÙƒØ±Ø© GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ Ø§Ù„ØµØºÙŠØ±ØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø´Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯Ø¹Ù…Ù‡ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø³Ù‚Ø§Ø·ØŒ ÙŠÙ…ÙƒÙ†Ùƒ\n",
    "    # ØªØ®ØµÙŠØµ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø­Ø³Ø¨ Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # ØªÙ‚Ø³ÙŠÙ…Ù‡Ø§ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ø¨Ø­Ø¬Ù… block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø·Ø¨Ù‚ Ø¯Ø§Ù„Ø© `group_texts` Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø§Ù„Ø¢Ù†ØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `DataCollatorForLanguageModeling`. Ù…Ù† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© Ø£Ù† ØªÙ‚ÙˆÙ… Ø¨Ù€ *Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ* Ù„ÙŠØµÙ„ Ø·ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø£Ø·ÙˆÙ„ Ø¬Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø´Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰.\n",
    "\n",
    "\n",
    "Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…Ø² Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ³Ù„Ø³Ù„ ÙƒØ±Ù…Ø² Ø§Ù„Ø­Ø´Ùˆ ÙˆØ­Ø¯Ø¯ `mlm_probability` Ù„Ø­Ø¬Ø¨ Ø§Ù„Ø±Ù…ÙˆØ² Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹ ÙƒÙ„ Ù…Ø±Ø© ØªÙƒØ±Ø± ÙÙŠÙ‡Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø¹Ù„Ù‰ Ø¯Ø±Ø§ÙŠØ© Ø¨ØªØ¹Ø¯ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… KerasØŒ Ø£Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ [Ù‡Ù†Ø§](https://huggingface.co/docs/transformers/main/ar/tasks/../training#train-a-tensorflow-model-with-keras)!\n",
    "\n",
    "</Tip>\n",
    "Ù„ØªØ¹Ø¯ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ TensorFlowØŒ Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù†ØŒ ÙˆØ¬Ø¯ÙˆÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…ØŒ ÙˆØ¨Ø¹Ø¶ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer, AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø«Ù… ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ DistilRoBERTa Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `TFAutoModelForMaskedLM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ `tf.data.Dataset` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `~transformers.TFPreTrainedModel.prepare_tf_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    lm_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    lm_dataset[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ù‚Ù… Ø¨ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`compile`](https://keras.io/api/models/model_training_apis/#compile-method). Ù„Ø§Ø­Ø¸ Ø£Ù† Ù†Ù…Ø§Ø°Ø¬ Transformers Ù„Ø¯ÙŠÙ‡Ø§ Ø¬Ù…ÙŠØ¹Ù‡Ø§ Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø°Ø§Øª ØµÙ„Ø© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ Ù„Ø°Ù„Ùƒ Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ ÙˆØ§Ø­Ø¯Ø© Ù…Ø§ Ù„Ù… ØªÙƒÙ† ØªØ±ÙŠØ¯ Ø°Ù„Ùƒ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)  # Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø¬Ø© Ù„Ù„Ø®Ø³Ø§Ø±Ø©!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÙŠÙ…ÙƒÙ† Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ­Ø¯ÙŠØ¯ Ù…ÙƒØ§Ù† Ø¯ÙØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø±Ù…ÙˆØ² ÙÙŠ `~transformers.PushToHubCallback`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "callback = PushToHubCallback(\n",
    "    output_dir=\"my_awesome_eli5_mlm_model\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø£Ø®ÙŠØ±Ø§Ù‹ØŒ Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬Ùƒ! Ù‚Ù… Ø¨Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ØŒ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø¹ØµÙˆØ±ØŒ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø¨Ù…Ø¬Ø±Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ù„Ù‰ Hub Ø­ØªÙ‰ ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡!\n",
    "\n",
    "<Tip>\n",
    "\n",
    "Ù„Ù…Ø«Ø§Ù„ Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ¹Ø¯ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©ØŒ Ø£Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙØªØ± Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„\n",
    "[Ø¯ÙØªØ± PyTorch](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)\n",
    "Ø£Ùˆ [Ø¯ÙØªØ± TensorFlow](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb).\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø±Ø§Ø¦Ø¹ØŒ Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ Ø£Ù† Ù‚Ù…Øª Ø¨ØªØ¹Ø¯ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„!\n",
    "\n",
    "Ø¬Ù‡Ù‘Ø² Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø£Ù† ÙŠÙ…Ù„Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø§ØºØ§Øª ÙÙŠÙ‡Ø§ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ø®Ø§Øµ `<mask>` Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙØ±Ø§Øº:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Milky Way is a <mask> galaxy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø£Ø¨Ø³Ø· Ø·Ø±ÙŠÙ‚Ø© Ù„ØªØ¬Ø±Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù…Ø¹Ø¯Ù„ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù‡ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ `pipeline()`. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù†  `pipeline` Ù„Ù…Ù„Ø¡ Ø§Ù„ÙØ±Ø§Øº Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙˆÙ…Ø±Ø± Ù†ØµÙƒ Ø¥Ù„ÙŠÙ‡. Ø¥Ø°Ø§ Ø£Ø±Ø¯ØªØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø© `top_k` Ù„ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø¥Ø±Ø¬Ø§Ø¹Ù‡Ø§:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5150994658470154,\n",
       "  'token': 21300,\n",
       "  'token_str': ' spiral',\n",
       "  'sequence': 'The Milky Way is a spiral galaxy.'},\n",
       " {'score': 0.07087188959121704,\n",
       "  'token': 2232,\n",
       "  'token_str': ' massive',\n",
       "  'sequence': 'The Milky Way is a massive galaxy.'},\n",
       " {'score': 0.06434620916843414,\n",
       "  'token': 650,\n",
       "  'token_str': ' small',\n",
       "  'sequence': 'The Milky Way is a small galaxy.'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", \"username/my_awesome_eli5_mlm_model\")\n",
    "mask_filler(text, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ù‚Ù… Ø¨ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù…ÙˆØ² ÙˆØ¥Ø±Ø¬Ø§Ø¹ `input_ids` ÙƒÙ€ TensorFlow tensors. Ø³ØªØ­ØªØ§Ø¬ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¶Ø¹ Ø±Ù…Ø² `<mask>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"username/my_awesome_eli5_mlm_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "mask_token_index = tf.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ¥Ø±Ø¬Ø§Ø¹ `logits` Ù„Ù„Ø±Ù…Ø² Ø§Ù„Ù…Ù‚Ù†Ø¹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"username/my_awesome_eli5_mlm_model\")\n",
    "logits = model(**inputs).logits\n",
    "mask_token_logits = logits[0, mask_token_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ø«Ù… Ù‚Ù… Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© Ø°Ø§Øª Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¹Ù„Ù‰ ÙˆØ·Ø¨Ø§Ø¹ØªÙ‡Ø§:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Milky Way is a spiral galaxy.\n",
       "The Milky Way is a massive galaxy.\n",
       "The Milky Way is a small galaxy."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_tokens = tf.math.top_k(mask_token_logits, 3).indices.numpy()\n",
    "\n",
    "for token in top_3_tokens:\n",
    "    print(text.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
