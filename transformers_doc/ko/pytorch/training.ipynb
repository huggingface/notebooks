{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¯¸ì„¸ íŠœë‹í•˜ê¸°[[finetune-a-pretrained-model]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ìƒë‹¹í•œ ì´ì ì´ ìˆìŠµë‹ˆë‹¤. ê³„ì‚° ë¹„ìš©ê³¼ íƒ„ì†Œë°œìêµ­ì„ ì¤„ì´ê³ , ì²˜ìŒë¶€í„° ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ í•„ìš” ì—†ì´ ìµœì‹  ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ¤— TransformersëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì„ ìœ„í•´ ì‚¬ì „ í•™ìŠµëœ ìˆ˜ì²œ ê°œì˜ ëª¨ë¸ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ìì‹ ì˜ ì‘ì—…ê³¼ ê´€ë ¨ëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ í•™ìŠµí•©ë‹ˆë‹¤. ì´ê²ƒì€ ë¯¸ì„¸ íŠœë‹ì´ë¼ê³  í•˜ëŠ” ë§¤ìš° ê°•ë ¥í•œ í›ˆë ¨ ê¸°ë²•ì…ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‹¹ì‹ ì´ ì„ íƒí•œ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ íŠœë‹í•©ë‹ˆë‹¤:\n",
    "\n",
    "* ğŸ¤— Transformersë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¯¸ì„¸ íŠœë‹í•˜ê¸° `Trainer`.\n",
    "* Kerasë¥¼ ì‚¬ìš©í•˜ì—¬ TensorFlowì—ì„œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ íŠœë‹í•˜ê¸°.\n",
    "* ê¸°ë³¸ PyTorchì—ì„œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ íŠœë‹í•˜ê¸°.\n",
    "\n",
    "<a id='data-processing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ì¤€ë¹„[[prepare-a-dataset]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/_BZearw7f0w?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/_BZearw7f0w?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ íŠœë‹í•˜ê¸° ìœ„í•´ì„œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  í›ˆë ¨í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•˜ì„¸ìš”. ì´ì „ íŠœí† ë¦¬ì–¼ì—ì„œ í›ˆë ¨ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë ¸ëŠ”ë°, ì§€ê¸ˆì´ ë°°ìš¸ ê±¸ ë˜ì§šì„ ê¸°íšŒì…ë‹ˆë‹¤!\n",
    "\n",
    "ë¨¼ì € [Yelp ë¦¬ë·°](https://huggingface.co/datasets/yelp_review_full) ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ì‹œí€€ìŠ¤ íŒ¨ë”© ë° ì˜ë¼ë‚´ê¸° ì „ëµì„ í¬í•¨í•˜ë ¤ë©´ í† í¬ë‚˜ì´ì €ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë ¤ë©´ ğŸ¤— Dataset [`map`](https://huggingface.co/docs/datasets/process.html#map) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•„ìš”í•œ ê²½ìš° ë¯¸ì„¸ íŠœë‹ì„ ìœ„í•´ ë°ì´í„°ì…‹ì˜ ì‘ì€ ë¶€ë¶„ ì§‘í•©ì„ ë§Œë“¤ì–´ ë¯¸ì„¸ íŠœë‹ ì‘ì—… ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trainer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—¬ê¸°ì„œë¶€í„°ëŠ” ì‚¬ìš©í•˜ë ¤ëŠ” í”„ë ˆì„ì›Œí¬ì— í•´ë‹¹í•˜ëŠ” ì„¹ì…˜ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì˜¤ë¥¸ìª½ ì‚¬ì´ë“œë°”ì˜ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¡œ ì´ë™í•  ìˆ˜ ìˆìœ¼ë©°, íŠ¹ì • í”„ë ˆì„ì›Œí¬ì˜ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ìˆ¨ê¸°ë ¤ë©´ í•´ë‹¹ í”„ë ˆì„ì›Œí¬ ë¸”ë¡ì˜ ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ìˆëŠ” ë²„íŠ¼ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nvBXf7s7vTI?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nvBXf7s7vTI?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## íŒŒì´í† ì¹˜ Trainerë¡œ í›ˆë ¨í•˜ê¸°[[train-with-pytorch-trainer]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤— TransformersëŠ” ğŸ¤— Transformers ëª¨ë¸ í›ˆë ¨ì— ìµœì í™”ëœ `Trainer` í´ë˜ìŠ¤ë¥¼ ì œê³µí•˜ì—¬ í›ˆë ¨ ë£¨í”„ë¥¼ ì§ì ‘ ì‘ì„±í•˜ì§€ ì•Šê³ ë„ ì‰½ê²Œ í›ˆë ¨ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `Trainer` APIëŠ” ë¡œê¹…(logging), ê²½ì‚¬ ëˆ„ì (gradient accumulation), í˜¼í•© ì •ë°€ë„(mixed precision) ë“± ë‹¤ì–‘í•œ í›ˆë ¨ ì˜µì…˜ê³¼ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € ëª¨ë¸ì„ ê°€ì ¸ì˜¤ê³  ì˜ˆìƒë˜ëŠ” ë ˆì´ë¸” ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. Yelp ë¦¬ë·° [ë°ì´í„°ì…‹ ì¹´ë“œ](https://huggingface.co/datasets/yelp_review_full#data-fields)ì—ì„œ 5ê°œì˜ ë ˆì´ë¸”ì´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì¤‘ ì¼ë¶€ê°€ ì‚¬ìš©ë˜ì§€ ì•Šê³  ì¼ë¶€ ê°€ì¤‘ì¹˜ê°€ ë¬´ì‘ìœ„ë¡œ í‘œì‹œëœë‹¤ëŠ” ê²½ê³ ê°€ í‘œì‹œë©ë‹ˆë‹¤.\n",
    "ê±±ì •ë§ˆì„¸ìš”. ì´ê²ƒì€ ì˜¬ë°”ë¥¸ ë™ì‘ì…ë‹ˆë‹¤! ì‚¬ì „ í•™ìŠµëœ BERT ëª¨ë¸ì˜ í—¤ë“œëŠ” íê¸°ë˜ê³  ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœ ë¶„ë¥˜ í—¤ë“œë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤. ì´ì œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ì§€ì‹ìœ¼ë¡œ ì‹œí€€ìŠ¤ ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë¸ í—¤ë“œë¥¼ ë¯¸ì„¸ íŠœë‹ í•©ë‹ˆë‹¤.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•˜ì´í¼íŒŒë¼ë¯¸í„° í›ˆë ¨[[training-hyperparameters]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ ì •í•  ìˆ˜ ìˆëŠ” ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ë‹¤ì–‘í•œ í›ˆë ¨ ì˜µì…˜ì„ í™œì„±í™”í•˜ê¸° ìœ„í•œ í”Œë˜ê·¸ë¥¼ í¬í•¨í•˜ëŠ” `TrainingArguments` í´ë˜ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ê¸°ë³¸ í›ˆë ¨ [í•˜ì´í¼íŒŒë¼ë¯¸í„°](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)ë¡œ ì‹œì‘í•˜ì§€ë§Œ, ììœ ë¡­ê²Œ ì‹¤í—˜í•˜ì—¬ ì—¬ëŸ¬ë¶„ë“¤ì—ê²Œ ë§ëŠ” ìµœì ì˜ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í›ˆë ¨ì—ì„œ ì²´í¬í¬ì¸íŠ¸(checkpoints)ë¥¼ ì €ì¥í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í‰ê°€ í•˜ê¸°[[evaluate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trainer`ëŠ” í›ˆë ¨ ì¤‘ì— ëª¨ë¸ ì„±ëŠ¥ì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ê³  ë³´ê³ í•  í•¨ìˆ˜ë¥¼ `Trainer`ì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. \n",
    "[ğŸ¤— Evaluate](https://huggingface.co/docs/evaluate/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” [`evaluate.load`](https://huggingface.co/spaces/evaluate-metric/accuracy) í•¨ìˆ˜ë¡œ ë¡œë“œí•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ `accuracy`í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤ (ìì„¸í•œ ë‚´ìš©ì€ [ë‘˜ëŸ¬ë³´ê¸°](https://huggingface.co/docs/evaluate/a_quick_tour)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`metric`ì—ì„œ `compute`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì˜ˆì¸¡ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì˜ˆì¸¡ì„ `compute`ì— ì „ë‹¬í•˜ê¸° ì „ì— ì˜ˆì¸¡ì„ ë¡œì§“ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤(ëª¨ë“  ğŸ¤— Transformers ëª¨ë¸ì€ ë¡œì§“ìœ¼ë¡œ ë°˜í™˜í•œë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¯¸ì„¸ íŠœë‹ ì¤‘ì— í‰ê°€ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë ¤ë©´ í›ˆë ¨ ì¸ìˆ˜ì— `evaluation_strategy` íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•˜ì—¬ ê° ì—í­ì´ ëë‚  ë•Œ í‰ê°€ ì§€í‘œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í›ˆë ¨ í•˜ê¸°[[trainer]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸, í›ˆë ¨ ì¸ìˆ˜, í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹, í‰ê°€ í•¨ìˆ˜ê°€ í¬í•¨ëœ `Trainer` ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë¦¬ê³  `train()`ì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ íŠœë‹í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pytorch_native'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ íŒŒì´í† ì¹˜ë¡œ í›ˆë ¨í•˜ê¸°[[train-in-native-pytorch]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Dh9CL8fyG80?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Dh9CL8fyG80?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trainer`ëŠ” í›ˆë ¨ ë£¨í”„ë¥¼ ì²˜ë¦¬í•˜ë©° í•œ ì¤„ì˜ ì½”ë“œë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ì ‘ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì„ ì„ í˜¸í•˜ëŠ” ì‚¬ìš©ìì˜ ê²½ìš°, ê¸°ë³¸ PyTorchì—ì„œ ğŸ¤— Transformers ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì‹œì ì—ì„œ ë…¸íŠ¸ë¶ì„ ë‹¤ì‹œ ì‹œì‘í•˜ê±°ë‚˜ ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ, 'í† í°í™”ëœ ë°ì´í„°ì…‹'ì„ ìˆ˜ë™ìœ¼ë¡œ í›„ì²˜ë¦¬í•˜ì—¬ í›ˆë ¨ë ¨ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "1. ëª¨ë¸ì´ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ í—ˆìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ `text` ì—´ì„ ì œê±°í•©ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "    ```\n",
    "\n",
    "2. ëª¨ë¸ì—ì„œ ì¸ìˆ˜ì˜ ì´ë¦„ì´ `labels`ë¡œ ì§€ì •ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒí•˜ë¯€ë¡œ `label` ì—´ì˜ ì´ë¦„ì„ `labels`ë¡œ ë³€ê²½í•©ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "    ```\n",
    "\n",
    "3. ë°ì´í„°ì…‹ì˜ í˜•ì‹ì„ List ëŒ€ì‹  PyTorch í…ì„œë¥¼ ë°˜í™˜í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤:\n",
    "\n",
    "    ```py\n",
    "    >>> tokenized_datasets.set_format(\"torch\")\n",
    "    ```\n",
    "\n",
    "ê·¸ë¦¬ê³  ì•ì„œ í‘œì‹œëœ ëŒ€ë¡œ ë°ì´í„°ì…‹ì˜ ë” ì‘ì€ í•˜ìœ„ ì§‘í•©ì„ ìƒì„±í•˜ì—¬ ë¯¸ì„¸ ì¡°ì • ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader[[dataloader]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ 'DataLoader'ë¥¼ ìƒì„±í•˜ì—¬ ë°ì´í„° ë°°ì¹˜ë¥¼ ë°˜ë³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì¸¡ì„ ìœ„í•œ ë ˆì´ë¸” ê°œìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµ ì†ë„ ìŠ¤ì¼€ì¤„ëŸ¬[[optimizer-and-learning-rate-scheduler]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜µí‹°ë§ˆì´ì €ì™€ í•™ìŠµ ì†ë„ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ìƒì„±í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. íŒŒì´í† ì¹˜ì—ì„œ ì œê³µí•˜ëŠ” [`AdamW`](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html) ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trainer`ì—ì„œ ê¸°ë³¸ í•™ìŠµ ì†ë„ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, GPUì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ê²½ìš° 'device'ë¥¼ ì§€ì •í•˜ì—¬ GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ CPUì—ì„œ í›ˆë ¨í•˜ë©° ëª‡ ë¶„ì´ ì•„ë‹Œ ëª‡ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "[Colaboratory](https://colab.research.google.com/) ë˜ëŠ” [SageMaker StudioLab](https://studiolab.sagemaker.aws/)ê³¼ ê°™ì€ í˜¸ìŠ¤íŒ… ë…¸íŠ¸ë¶ì´ ì—†ëŠ” ê²½ìš° í´ë¼ìš°ë“œ GPUì— ë¬´ë£Œë¡œ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì´ì œ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ¥³"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í›ˆë ¨ ë£¨í”„[[training-loop]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ë ¤ë©´ [tqdm](https://tqdm.github.io/) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹ ë‹¨ê³„ ìˆ˜ì— ì§„í–‰ë¥  í‘œì‹œì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í‰ê°€ í•˜ê¸°[[evaluate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trainer`ì— í‰ê°€ í•¨ìˆ˜ë¥¼ ì¶”ê°€í•œ ë°©ë²•ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, í›ˆë ¨ ë£¨í”„ë¥¼ ì§ì ‘ ì‘ì„±í•  ë•Œë„ ë™ì¼í•œ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ë²ˆì—ëŠ” ê° ì—í¬í¬ê°€ ëë‚  ë•Œë§ˆë‹¤ í‰ê°€ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ë³´ê³ í•˜ëŠ” ëŒ€ì‹ , `add_batch`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë°°ì¹˜ë¥¼ ëˆ„ì í•˜ê³  ë§¨ ë§ˆì§€ë§‰ì— í‰ê°€ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='additional-resources'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ê°€ ìë£Œ[[additional-resources]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë” ë§ì€ ë¯¸ì„¸ íŠœë‹ ì˜ˆì œëŠ” ë‹¤ìŒì„ ì°¸ì¡°í•˜ì„¸ìš”:\n",
    "\n",
    "- [ğŸ¤— Trnasformers ì˜ˆì œ](https://github.com/huggingface/transformers/tree/main/examples)ì—ëŠ” PyTorch ë° í…ì„œí”Œë¡œìš°ì—ì„œ ì¼ë°˜ì ì¸ NLP ì‘ì—…ì„ í›ˆë ¨í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- [ğŸ¤— Transformers ë…¸íŠ¸ë¶](https://huggingface.co/docs/transformers/main/ko/notebooks)ì—ëŠ” PyTorch ë° í…ì„œí”Œë¡œìš°ì—ì„œ íŠ¹ì • ì‘ì—…ì„ ìœ„í•´ ëª¨ë¸ì„ ë¯¸ì„¸ íŠœë‹í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ë‹¤ì–‘í•œ ë…¸íŠ¸ë¶ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
