{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìë™ ìŒì„± ì¸ì‹[[automatic-speech-recognition]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TksaY_FDgnk?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TksaY_FDgnk?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìë™ ìŒì„± ì¸ì‹(Automatic Speech Recognition, ASR)ì€ ìŒì„± ì‹ í˜¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ìŒì„± ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ ì¶œë ¥ì— ë§¤í•‘í•©ë‹ˆë‹¤. \n",
    "Siriì™€ Alexaì™€ ê°™ì€ ê°€ìƒ ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” ASR ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¼ìƒì ìœ¼ë¡œ ì‚¬ìš©ìë¥¼ ë•ê³  ìˆìœ¼ë©°, íšŒì˜ ì¤‘ ë¼ì´ë¸Œ ìº¡ì…˜ ë° ë©”ëª¨ ì‘ì„±ê³¼ ê°™ì€ ìœ ìš©í•œ ì‚¬ìš©ì ì¹œí™”ì  ì‘ìš© í”„ë¡œê·¸ë¨ë„ ë§ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œ ì†Œê°œí•  ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ë°ì´í„° ì„¸íŠ¸ì—ì„œ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "2. ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸ì„ ì¶”ë¡ ì— ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "<Tip>\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œ ì„¤ëª…í•˜ëŠ” ì‘ì—…ì€ ë‹¤ìŒ ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ì˜í•´ ì§€ì›ë©ë‹ˆë‹¤:\n",
    "\n",
    "<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n",
    "\n",
    "[Data2VecAudio](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/data2vec-audio), [Hubert](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/hubert), [M-CTC-T](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mctct), [SEW](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/sew), [SEW-D](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/sew-d), [UniSpeech](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/unispeech), [UniSpeechSat](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/unispeech-sat), [Wav2Vec2](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/wav2vec2), [Wav2Vec2-Conformer](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/wav2vec2-conformer), [WavLM](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/wavlm)\n",
    "\n",
    "<!--End of the generated tip-->\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:\n",
    "\n",
    "```bash\n",
    "pip install transformers datasets evaluate jiwer\n",
    "```\n",
    "\n",
    "Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ë©´ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì— ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í† í°ì„ ì…ë ¥í•˜ì—¬ ë¡œê·¸ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MInDS-14 ë°ì´í„° ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°[[load-minds-14-dataset]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì €, ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ë°ì´í„° ì„¸íŠ¸ì˜ ì¼ë¶€ë¶„ì„ ê°€ì ¸ì˜¤ì„¸ìš”. \n",
    "ì´ë ‡ê²Œ í•˜ë©´ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ í›ˆë ¨ì— ì‹œê°„ì„ ë“¤ì´ê¸° ì „ì— ëª¨ë“  ê²ƒì´ ì‘ë™í•˜ëŠ”ì§€ ì‹¤í—˜í•˜ê³  ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`~Dataset.train_test_split` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì„¸íŠ¸ì˜ `train`ì„ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë¦¬ê³  ë°ì´í„° ì„¸íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì„¸íŠ¸ì—ëŠ” `lang_id`ì™€ `english_transcription`ê³¼ ê°™ì€ ìœ ìš©í•œ ì •ë³´ê°€ ë§ì´ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ, ì´ ê°€ì´ë“œì—ì„œëŠ” `audio`ì™€ `transcription`ì— ì´ˆì ì„ ë§ì¶œ ê²ƒì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì€ `remove_columns` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œê±°í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.remove_columns([\"english_transcription\", \"intent_class\", \"lang_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì‹œë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'array': array([-0.00024414,  0.        ,  0.        , ...,  0.00024414,\n",
       "          0.00024414,  0.00024414], dtype=float32),\n",
       "  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n",
       "  'sampling_rate': 8000},\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n",
       " 'transcription': \"hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‘ ê°œì˜ í•„ë“œê°€ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- `audio`: ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì ¸ì˜¤ê³  ë¦¬ìƒ˜í”Œë§í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” ìŒì„± ì‹ í˜¸ì˜ 1ì°¨ì› `array(ë°°ì—´)`\n",
    "- `transcription`: ëª©í‘œ í…ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì „ì²˜ë¦¬[[preprocess]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ ì˜¤ë””ì˜¤ ì‹ í˜¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ Wav2Vec2 í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MInDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” 8000kHzì´ë¯€ë¡œ([ë°ì´í„° ì„¸íŠ¸ ì¹´ë“œ](https://huggingface.co/datasets/PolyAI/minds14)ì—ì„œ í™•ì¸), ì‚¬ì „ í›ˆë ¨ëœ Wav2Vec2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë°ì´í„° ì„¸íŠ¸ë¥¼ 16000kHzë¡œ ë¦¬ìƒ˜í”Œë§í•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'array': array([-2.38064706e-04, -1.58618059e-04, -5.43987835e-06, ...,\n",
       "          2.78103951e-04,  2.38446111e-04,  1.18740834e-04], dtype=float32),\n",
       "  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n",
       "  'sampling_rate': 16000},\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n",
       " 'transcription': \"hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ì˜ 'transcription'ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ í…ìŠ¤íŠ¸ëŠ” ëŒ€ë¬¸ìì™€ ì†Œë¬¸ìê°€ ì„ì—¬ ìˆìŠµë‹ˆë‹¤. Wav2Vec2 í† í¬ë‚˜ì´ì €ëŠ” ëŒ€ë¬¸ì ë¬¸ìì— ëŒ€í•´ì„œë§Œ í›ˆë ¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ í…ìŠ¤íŠ¸ê°€ í† í¬ë‚˜ì´ì €ì˜ ì–´íœ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppercase(example):\n",
    "    return {\"transcription\": example[\"transcription\"].upper()}\n",
    "\n",
    "\n",
    "minds = minds.map(uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•  ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. `audio` ì—´ì„ í˜¸ì¶œí•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì ¸ì˜¤ê³  ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤.\n",
    "2. ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ `input_values`ë¥¼ ì¶”ì¶œí•˜ê³  í”„ë¡œì„¸ì„œë¡œ `transcription` ì—´ì„ í† í°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"transcription\"])\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"][0])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë ¤ë©´ ğŸ¤— Datasets `map` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. `num_proc` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ `map`ì˜ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. `remove_columns` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•˜ì§€ ì•Šì€ ì—´ì„ ì œê±°í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_minds = minds.map(prepare_dataset, remove_columns=minds.column_names[\"train\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤— Transformersì—ëŠ” ìë™ ìŒì„± ì¸ì‹ìš© ë°ì´í„° ì½œë ˆì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì˜ˆì œ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ë ¤ë©´ `DataCollatorWithPadding`ì„ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë°ì´í„° ì½œë ˆì´í„°ëŠ” í…ìŠ¤íŠ¸ì™€ ë ˆì´ë¸”ì„ ë°°ì¹˜ì—ì„œ ê°€ì¥ ê¸´ ìš”ì†Œì˜ ê¸¸ì´ì— ë™ì ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ ê¸¸ì´ë¥¼ ê· ì¼í•˜ê²Œ í•©ë‹ˆë‹¤. `tokenizer` í•¨ìˆ˜ì—ì„œ `padding=True`ë¥¼ ì„¤ì •í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”©í•  ìˆ˜ ìˆì§€ë§Œ, ë™ì  íŒ¨ë”©ì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë¥¸ ë°ì´í„° ì½œë ˆì´í„°ì™€ ë‹¬ë¦¬ ì´ íŠ¹ì • ë°ì´í„° ì½œë ˆì´í„°ëŠ” `input_values`ì™€ `labels`ì— ëŒ€í•´ ë‹¤ë¥¸ íŒ¨ë”© ë°©ë²•ì„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: AutoProcessor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # ì…ë ¥ê³¼ ë ˆì´ë¸”ì„ ë¶„í• í•©ë‹ˆë‹¤\n",
    "        # ê¸¸ì´ê°€ ë‹¤ë¥´ê³ , ê°ê° ë‹¤ë¥¸ íŒ¨ë”© ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        # íŒ¨ë”©ì— ëŒ€í•´ ì†ì‹¤ì„ ì ìš©í•˜ì§€ ì•Šë„ë¡ -100ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `DataCollatorForCTCWithPadding`ì„ ì¸ìŠ¤í„´ìŠ¤í™”í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í‰ê°€í•˜ê¸°[[evaluate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ì¤‘ì— í‰ê°€ ì§€í‘œë¥¼ í¬í•¨í•˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ í‰ê°€ ë°©ë²•ì„ ë¹ ë¥´ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ì´ ì‘ì—…ì—ì„œëŠ” [ë‹¨ì–´ ì˜¤ë¥˜ìœ¨(Word Error Rate, WER)](https://huggingface.co/spaces/evaluate-metric/wer) í‰ê°€ ì§€í‘œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "(í‰ê°€ ì§€í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ê³„ì‚°í•˜ëŠ” ë°©ë²•ì€ ğŸ¤— Evaluate [ë‘˜ëŸ¬ë³´ê¸°](https://huggingface.co/docs/evaluate/a_quick_tour)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "wer = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ° ë‹¤ìŒ ì˜ˆì¸¡ê°’ê³¼ ë ˆì´ë¸”ì„ `compute`ì— ì „ë‹¬í•˜ì—¬ WERì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `compute_metrics` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìœ¼ë©°, í›ˆë ¨ì„ ì„¤ì •í•  ë•Œ ì´ í•¨ìˆ˜ë¡œ ë˜ëŒì•„ì˜¬ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í›ˆë ¨í•˜ê¸°[[train]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "`Trainer`ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì´ ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´, [ì—¬ê¸°](https://huggingface.co/docs/transformers/main/ko/tasks/../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•´ë³´ì„¸ìš”!\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì´ì œ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤! `AutoModelForCTC`ë¡œ Wav2Vec2ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”. `ctc_loss_reduction` ë§¤ê°œë³€ìˆ˜ë¡œ CTC ì†ì‹¤ì— ì ìš©í•  ì¶•ì†Œ(reduction) ë°©ë²•ì„ ì§€ì •í•˜ì„¸ìš”. ê¸°ë³¸ê°’ì¸ í•©ê³„ ëŒ€ì‹  í‰ê· ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì€ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\",\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì„¸ ë‹¨ê³„ë§Œ ë‚¨ì•˜ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. `TrainingArguments`ì—ì„œ í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ì„¸ìš”. `output_dir`ì€ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œë¥¼ ì§€ì •í•˜ëŠ” ìœ ì¼í•œ í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤. `push_to_hub=True`ë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì„ Hubì— ì—…ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ Hugging Faceì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤). `Trainer`ëŠ” ê° ì—í­ë§ˆë‹¤ WERì„ í‰ê°€í•˜ê³  í›ˆë ¨ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "2. ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸, í† í¬ë‚˜ì´ì €, ë°ì´í„° ì½œë ˆì´í„°, `compute_metrics` í•¨ìˆ˜ì™€ í•¨ê»˜ `Trainer`ì— í›ˆë ¨ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.\n",
    "3. `train()`ì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_asr_mind_model\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=2000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_minds[\"train\"],\n",
    "    eval_dataset=encoded_minds[\"test\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ëª¨ë‘ê°€ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ `push_to_hub()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ Hubì— ê³µìœ í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë” ìì„¸í•œ ì˜ˆì œëŠ” ì˜ì–´ ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•œ [ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸](https://huggingface.co/blog/fine-tune-wav2vec2-english)ì™€ ë‹¤êµ­ì–´ ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•œ [í¬ìŠ¤íŠ¸](https://huggingface.co/blog/fine-tune-xlsr-wav2vec2)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ë¡ í•˜ê¸°[[inference]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¢‹ì•„ìš”, ì´ì œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í–ˆìœ¼ë‹ˆ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì¶”ë¡ ì— ì‚¬ìš©í•  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì ¸ì˜¤ì„¸ìš”. í•„ìš”í•œ ê²½ìš° ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ìƒ˜í”Œë§ ë¹„ìœ¨ì„ ëª¨ë¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ì— ë§ê²Œ ë¦¬ìƒ˜í”Œë§í•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "audio_file = dataset[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‹œí—˜í•´ë³´ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ `pipeline()`ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•œ `pipeline`ì„ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ê³  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ë‹¬í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"stevhliu/my_awesome_asr_minds_model\")\n",
    "transcriber(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ëœ ê²°ê³¼ê°€ ê½¤ ê´œì°®ì§€ë§Œ ë” ì¢‹ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤! ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ë” ë§ì€ ì˜ˆì œë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì„¸ìš”!\n",
    "\n",
    "</Tip>\n",
    "\n",
    "`pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¬í˜„í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³  PyTorch í…ì„œë¡œ `input`ì„ ë°˜í™˜í•  í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"stevhliu/my_awesome_asr_mind_model\")\n",
    "inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì…ë ¥ì„ ëª¨ë¸ì— ì „ë‹¬í•˜ê³  ë¡œì§“ì„ ë°˜í™˜í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(\"stevhliu/my_awesome_asr_mind_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ `input_ids`ë¥¼ ì˜ˆì¸¡í•˜ê³ , í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ëœ `input_ids`ë¥¼ ë‹¤ì‹œ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "transcription"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
