{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets evaluate accelerate\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì†ë„ ë° ë©”ëª¨ë¦¬ ìµœì í™” [[optimizing-llms-for-speed-and-memory]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT3/4, [Falcon](https://huggingface.co/tiiuae/falcon-40b), [Llama](https://huggingface.co/meta-llama/Llama-2-70b-hf)ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¸ê°„ ì¤‘ì‹¬ ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, í˜„ëŒ€ ì§€ì‹ ê¸°ë°˜ ì‚°ì—…ì—ì„œ í•„ìˆ˜ ë„êµ¬ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ëª¨ë¸ì„ ì‹¤ì œ ê³¼ì œì— ë°°í¬í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤.\n",
    "\n",
    "-   ì¸ê°„ê³¼ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ì„ ë³´ì´ê¸° ìœ„í•´, í˜„ì¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (ì°¸ì¡°: [Kaplan et al](https://huggingface.co/papers/2001.08361), [Wei et. al](https://huggingface.co/papers/2206.07682)). ì´ëŠ” ì¶”ë¡ ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ë¥¼ í¬ê²Œ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
    "-   ë§ì€ ì‹¤ì œ ê³¼ì œì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë°©ëŒ€í•œ ë§¥ë½ ì •ë³´ë¥¼ ì œê³µë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì¶”ë¡  ê³¼ì •ì—ì„œ ë§¤ìš° ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ëœ»í•©ë‹ˆë‹¤.  \n",
    "\n",
    "ì´ëŸ¬í•œ ê³¼ì œì˜ í•µì‹¬ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê³„ì‚° ë° ë©”ëª¨ë¦¬ í™œìš© ëŠ¥ë ¥ì„ ì¦ëŒ€ì‹œí‚¤ëŠ” ë° ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë°©ëŒ€í•œ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ë•Œ ì´ëŸ¬í•œ ëŠ¥ë ¥ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” íš¨ìœ¨ì ì¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬ë¥¼ ìœ„í•œ íš¨ê³¼ì ì¸ ê¸°ë²•ë“¤ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "1.  **ë‚®ì€ ì •ë°€ë„:** ì—°êµ¬ì— ë”°ë¥´ë©´, [8ë¹„íŠ¸ì™€ 4ë¹„íŠ¸](https://huggingface.co/docs/transformers/main/ko/./main_classes/quantization)ì™€ ê°™ì´ ë‚®ì€ ìˆ˜ì¹˜ ì •ë°€ë„ë¡œ ì‘ë™í•˜ë©´ ëª¨ë¸ ì„±ëŠ¥ì˜ í° ì €í•˜ ì—†ì´ ê³„ì‚°ìƒì˜ ì´ì ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2.  **í”Œë˜ì‹œ ì–´í…ì…˜:** í”Œë˜ì‹œ ì–´í…ì…˜ì€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë†’ì¼ ë¿ë§Œ ì•„ë‹ˆë¼ ìµœì í™”ëœ GPU ë©”ëª¨ë¦¬ í™œìš©ì„ í†µí•´ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ì˜ ë³€í˜•ì…ë‹ˆë‹¤.\n",
    "\n",
    "3.  **ì•„í‚¤í…ì²˜ í˜ì‹ :** ì¶”ë¡  ì‹œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ì£¼ë¡œ ë™ì¼í•œ ë°©ì‹(ê¸´ ì…ë ¥ ë§¥ë½ì„ ê°€ì§„ ìê¸°íšŒê·€ í…ìŠ¤íŠ¸ ìƒì„± ë°©ì‹)ìœ¼ë¡œ ë°°í¬ë˜ëŠ”ë°, ë” íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” íŠ¹í™”ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ì˜ ê°€ì¥ ì¤‘ìš”í•œ ë°œì „ìœ¼ë¡œëŠ” [Alibi](https://huggingface.co/papers/2108.12409), [Rotary embeddings](https://huggingface.co/papers/2104.09864), [Multi-Query Attention (MQA)](https://huggingface.co/papers/1911.02150), [Grouped-Query-Attention (GQA)](https://huggingface.co/papers/2305.13245)ì´ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” í…ì„œì˜ ê´€ì ì—ì„œ ìê¸°íšŒê·€ ìƒì„±ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ë‚®ì€ ì •ë°€ë„ë¥¼ ì±„íƒí•˜ëŠ” ê²ƒì˜ ì¥ë‹¨ì ì„ ë…¼ì˜í•˜ê³ , ìµœì‹  ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ì„ í¬ê´„ì ìœ¼ë¡œ íƒêµ¬í•˜ë©°, í–¥ìƒëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ëŒ€í•´ ë…¼í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ê° ê¸°ëŠ¥ì˜ ê°œì„  ì‚¬í•­ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤ìš©ì ì¸ ì˜ˆì œë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë‚®ì€ ì •ë°€ë„ [[1-lower-precision]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ê°€ì¤‘ì¹˜ í–‰ë ¬ê³¼ ë²¡í„°ì˜ ì§‘í•©ìœ¼ë¡œ ë³´ê³ , í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë²¡í„°ì˜ ì‹œí€€ìŠ¤ë¡œ ë³¸ë‹¤ë©´, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ì„ ê°€ì¥ ì˜ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì–´ì§€ëŠ” ë‚´ìš©ì—ì„œ *ê°€ì¤‘ì¹˜*ëŠ” ëª¨ë¸ì˜ ëª¨ë“  ê°€ì¤‘ì¹˜ í–‰ë ¬ê³¼ ë²¡í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.   \n",
    "\n",
    "ì´ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ëŠ” ì‹œì ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ìµœì†Œ ëª‡ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ë§¤ê°œë³€ìˆ˜ëŠ” `4.5689`ì™€ ê°™ì€ ì‹­ì§„ìˆ˜ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, ë³´í†µ [float32](https://en.wikipedia.org/wiki/Single-precision_floating-point_format), [bfloat16](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format) ë˜ëŠ” [float16](https://en.wikipedia.org/wiki/Half-precision_floating-point_format) í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ëŠ” ë° í•„ìš”í•œ ë©”ëª¨ë¦¬ì˜ ìš”êµ¬ì‚¬í•­ì„ ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "> *X * 10ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ë ¤ë©´ float32 ì •ë°€ë„ì—ì„œ ëŒ€ëµ 4 * X GBì˜ VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.*\n",
    "\n",
    "ìš”ì¦˜ì—ëŠ” ëª¨ë¸ì´ float32 ì •ë°€ë„ë¡œ í›ˆë ¨ë˜ëŠ” ê²½ìš°ëŠ” ë“œë¬¼ê³ , ì¼ë°˜ì ìœ¼ë¡œ bfloat16 ì •ë°€ë„ë‚˜ ê°€ë” float16 ì •ë°€ë„ë¡œ í›ˆë ¨ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ê²½í—˜ì ìœ¼ë¡œ ì•Œì•„ë‚¸ ë²•ì¹™ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "> *X * 10ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ë ¤ë©´ bfloat16/float16 ì •ë°€ë„ì—ì„œ ëŒ€ëµ 2 * X GBì˜ VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.*\n",
    "\n",
    "ì§§ì€ í…ìŠ¤íŠ¸ ì…ë ¥(1024 í† í° ë¯¸ë§Œ)ì˜ ê²½ìš°, ì¶”ë¡ ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì˜ ëŒ€ë¶€ë¶„ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ëŠ” ë° í•„ìš”í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì§€ê¸ˆì€ ì¶”ë¡ ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ GPU VRAMì— ë¡œë“œí•˜ëŠ” ë° í•„ìš”í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ê³¼ ê°™ë‹¤ê³  ê°€ì •í•©ì‹œë‹¤.\n",
    "\n",
    "ëª¨ë¸ì„ bfloat16ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” ë° ëŒ€ëµ ì–¼ë§ˆë‚˜ ë§ì€ VRAMì´ í•„ìš”í•œì§€ ëª‡ ê°€ì§€ ì˜ˆë¥¼ ë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "-   **GPT3**ëŠ” 2 \\* 175 GB = **350 GB** VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "-   [**Bloom**](https://huggingface.co/bigscience/bloom)ì€ 2 \\* 176 GB = **352 GB** VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "-   [**Llama-2-70b**](https://huggingface.co/meta-llama/Llama-2-70b-hf)ëŠ” 2 \\* 70 GB = **140 GB** VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "-   [**Falcon-40b**](https://huggingface.co/tiiuae/falcon-40b)ëŠ” 2 \\* 40 GB = **80 GB** VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "-   [**MPT-30b**](https://huggingface.co/mosaicml/mpt-30b)ëŠ” 2 * 30 GB = **60 GB** VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "-   [**bigcode/starcoder**](https://huggingface.co/bigcode/starcoder)ëŠ” 2 * 15.5 GB = **31 GB** VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì‹œì ì—ì„œ, í˜„ì¬ ì‹œì¥ì—ì„œ ê°€ì¥ í° GPU ì¹©ì€ 80GBì˜ VRAMì„ ì œê³µí•˜ëŠ” A100ê³¼ H100ì…ë‹ˆë‹¤. ì•ì„œ ì–¸ê¸‰ëœ ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ë“¤ì€ ë¡œë“œí•˜ê¸° ìœ„í•´ì„œëŠ” ìµœì†Œ 80GB ì´ìƒì˜ ìš©ëŸ‰ì„ í•„ìš”ë¡œ í•˜ë©°, ë”°ë¼ì„œ [í…ì„œ ë³‘ë ¬ ì²˜ë¦¬](https://huggingface.co/docs/transformers/perf_train_gpu_many#tensor-parallelism) ë°/ë˜ëŠ” [íŒŒì´í”„ë¼ì¸ ë³‘ë ¬ ì²˜ë¦¬](https://huggingface.co/docs/transformers/perf_train_gpu_many#naive-model-parallelism-vertical-and-pipeline-parallelism)ë¥¼ ë°˜ë“œì‹œ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ¤— TransformersëŠ” í…ì„œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ë°”ë¡œ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ íŠ¹ì • ë°©ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í…ì„œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ì‘ì„±í•˜ëŠ” ë° ê´€ì‹¬ì´ ìˆë‹¤ë©´ [the text-generation-inference library](https://github.com/huggingface/text-generation-inference/tree/main/server/text_generation_server/models/custom_modeling)ë¥¼ ì°¸ì¡°í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë³¸ì ì¸ íŒŒì´í”„ë¼ì¸ ë³‘ë ¬ ì²˜ë¦¬ëŠ” ë°”ë¡œ ì§€ì›ë©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‹¨ìˆœíˆ ëª¨ë¸ì„ `device=\"auto\"`ë¡œ ë¡œë“œí•˜ë©´ [ì—¬ê¸°](https://huggingface.co/docs/accelerate/v0.22.0/en/concept_guides/big_model_inference)ì— ì„¤ëª…ëœ ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ GPUì— ëª¨ë¸ì˜ ì„œë¡œ ë‹¤ë¥¸ ë ˆì´ì–´ë¥¼ ìë™ìœ¼ë¡œ ë°°ì¹˜í•©ë‹ˆë‹¤. ì´ê²ƒì€ ë§¤ìš° íš¨ê³¼ì ì´ê¸´ í•˜ì§€ë§Œ ì´ëŸ¬í•œ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë³‘ë ¬ ì²˜ë¦¬ëŠ” GPU ìœ íœ´ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í•œë‹¤ëŠ” ì ì„ ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ë” ë°œì „ëœ íŒŒì´í”„ë¼ì¸ ë³‘ë ¬ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë©°, ì´ì— ëŒ€í•œ ì„¤ëª…ì€ [ì—¬ê¸°](https://huggingface.co/docs/transformers/en/perf_train_gpu_many#naive-model-parallelism-vertical-and-pipeline-parallelism)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "80GB A100 GPU 8ê°œë¥¼ ê°€ì§„ ë…¸ë“œì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤ë©´, BLOOMì„ ë‹¤ìŒê³¼ ê°™ì´ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "```bash\n",
    "!pip install transformers accelerate bitsandbytes optimum\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom\", device_map=\"auto\", pad_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`device_map=\"auto\"`ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ GPUì— ì–´í…ì…˜ ë ˆì´ì–´ê°€ ê³ ë¥´ê²Œ ë¶„ì‚°ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” [bigcode/octocoder](https://huggingface.co/bigcode/octocoder)ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë‹¨ì¼ 40GB A100 GPU ì¥ì¹˜ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ ì ìš©í•  ëª¨ë“  ë©”ëª¨ë¦¬ ë° ì†ë„ ìµœì í™”ëŠ” ëª¨ë¸ ë˜ëŠ” í…ì„œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í•„ìš”ë¡œ í•˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ì—ë„ ë™ì¼í•˜ê²Œ ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì´ bfloat16 ì •ë°€ë„ë¡œ ë¡œë“œë˜ê¸° ë•Œë¬¸ì—, ìœ„ì˜ ê²½í—˜ì ìœ¼ë¡œ ì•Œì•„ë‚¸ ë²•ì¹™ì„ ì‚¬ìš©í•˜ë©´ `bigcode/octocoder`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì´ ì•½ 31GB VRAMì¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. í•œ ë²ˆ ì‹œë„í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•œ ë‹¤ìŒ, ë‘˜ ë‹¤ Transformersì˜ [íŒŒì´í”„ë¼ì¸](https://huggingface.co/docs/transformers/main_classes/pipelines) ê°ì²´ì— ì „ë‹¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/octocoder\", dtype=torch.bfloat16, device_map=\"auto\", pad_token_id=0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/octocoder\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Question: Please write a function in Python that transforms bytes to Giga bytes.\\n\\nAnswer:\"\n",
    "\n",
    "result = pipe(prompt, max_new_tokens=60)[0][\"generated_text\"][len(prompt):]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "Here is a Python function that transforms bytes to Giga bytes:\\n\\n```python\\ndef bytes_to_giga_bytes(bytes):\\n    return bytes / 1024 / 1024 / 1024\\n```\\n\\nThis function takes a single\n",
    "```\n",
    "\n",
    "ì¢‹ìŠµë‹ˆë‹¤. ì´ì œ ê²°ê³¼ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë°”ì´íŠ¸ë¥¼ ê¸°ê°€ë°”ì´íŠ¸ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_giga_bytes(bytes):\n",
    "  return bytes / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`torch.cuda.max_memory_allocated`](https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_allocated.html)ë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœëŒ€ GPU ë©”ëª¨ë¦¬ í• ë‹¹ì„ ì¸¡ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_to_giga_bytes(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```bash\n",
    "29.0260648727417\n",
    "```\n",
    "\n",
    "ëŒ€ëµì ìœ¼ë¡œ ê³„ì‚°í•œ ê²°ê³¼ì™€ ê±°ì˜ ì¼ì¹˜í•©ë‹ˆë‹¤! ë°”ì´íŠ¸ì—ì„œ í‚¬ë¡œë°”ì´íŠ¸ë¡œ ë³€í™˜í•  ë•Œ 1000ì´ ì•„ë‹Œ 1024ë¡œ ê³±í•´ì•¼ í•˜ë¯€ë¡œ ìˆ«ìê°€ ì •í™•í•˜ì§€ ì•Šì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ëŒ€ëµì ìœ¼ë¡œ ê³„ì‚°í•  ë•Œ ê³µì‹ì€ \"ìµœëŒ€ X GB\"ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ìš°ë¦¬ê°€ ëª¨ë¸ì„ float32 ì •ë°€ë„ë¡œ ì‹¤í–‰í•˜ë ¤ê³  í–ˆë‹¤ë©´ ë” í° í¬ê¸°ì¸ 64GBì˜ VRAMì´ í•„ìš”í–ˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "> ê±°ì˜ ëª¨ë“  ëª¨ë¸ì´ ìš”ì¦˜ bfloat16ìœ¼ë¡œ í•™ìŠµë˜ë¯€ë¡œ, [GPUê°€ bfloat16ì„ ì§€ì›](https://discuss.pytorch.org/t/bfloat16-native-support/117155/5)í•œë‹¤ë©´ ëª¨ë¸ì„ float32 ì •ë°€ë„ë¡œ ì‹¤í–‰í•  ì´ìœ ê°€ ì—†ìŠµë‹ˆë‹¤. float32ë¡œ ëŒë¦¬ëŠ” ëª¨ë¸ì€ í•™ìŠµí•  ë•Œ ì‚¬ìš©í–ˆë˜ ì •ë°€ë„ë³´ë‹¤ ë” ë‚˜ì€ ì¶”ë¡  ê²°ê³¼ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì–´ë–¤ ì •ë°€ë„ í˜•ì‹ìœ¼ë¡œ Hubì— ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš°, HuggingFace Hubì—ì„œ í•´ë‹¹ ì²´í¬í¬ì¸íŠ¸ configì˜ `\"dtype\"`ì„ í™•ì¸í•˜ë©´ ë©ë‹ˆë‹¤, *ì˜ˆ*ë¥¼ ë“¤ì–´ [ì—¬ê¸°](https://huggingface.co/meta-llama/Llama-2-7b-hf/blob/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/config.json#L21)ë¥¼ í™•ì¸í•˜ì„¸ìš”. ëª¨ë¸ì„ `from_pretrained(..., dtype=...)`ë¡œ ë¡œë“œí•  ë•ŒëŠ” configì— ëª…ì‹œëœ ì •ë°€ë„ ìœ í˜•ê³¼ ë™ì¼í•œ ì •ë°€ë„ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤. ë‹¨, ì›ë˜ ìœ í˜•ì´ float32ì¸ ê²½ìš° ì¶”ë¡ ì„ ìœ„í•´ `float16` ë˜ëŠ” `bfloat16`ì„ ë‘˜ ë‹¤ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ `flush(...)` í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì—¬ ëª¨ë“  ë©”ëª¨ë¦¬ë¥¼ í•´ì œí•˜ê³ , GPU ë©”ëª¨ë¦¬ì˜ ìµœëŒ€ í• ë‹¹ëŸ‰ì„ ì •í™•í•˜ê²Œ ì¸¡ì •í•˜ë„ë¡ í•©ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe\n",
    "del model\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "def flush():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ì‹¤í—˜ì„ ìœ„í•´ ë°”ë¡œ í˜¸ì¶œí•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìµœê·¼ ë²„ì „ì˜ accelerate ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œëŠ” `release_memory()`ë¼ëŠ” ìœ í‹¸ë¦¬í‹° ë©”ì†Œë“œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import release_memory\n",
    "# ...\n",
    "\n",
    "release_memory(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§Œì•½ GPUì— 32GBì˜ VRAMì´ ì—†ë‹¤ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”? ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì„±ëŠ¥ì— í° ì†ì‹¤ ì—†ì´ 8ë¹„íŠ¸ ë˜ëŠ” 4ë¹„íŠ¸ë¡œ ì–‘ìí™”í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ ë°í˜€ì¡ŒìŠµë‹ˆë‹¤(ì°¸ê³ : [Dettmers et al.](https://huggingface.co/papers/2208.07339)). ìµœê·¼ì˜ [GPTQ ë…¼ë¬¸](https://huggingface.co/papers/2210.17323) ì—ì„œëŠ” ëª¨ë¸ì„ 3ë¹„íŠ¸ ë˜ëŠ” 2ë¹„íŠ¸ë¡œ ì–‘ìí™”í•´ë„ ì„±ëŠ¥ ì†ì‹¤ì´ í—ˆìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì„ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤ğŸ¤¯.\n",
    "\n",
    "ë„ˆë¬´ ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ë£¨ì§€ ì•Šê³  ì„¤ëª…í•˜ìë©´, ì–‘ìí™”ëŠ” ê°€ì¤‘ì¹˜ì˜ ì •ë°€ë„ë¥¼ ì¤„ì´ë©´ì„œ ëª¨ë¸ì˜ ì¶”ë¡  ê²°ê³¼ë¥¼ ê°€ëŠ¥í•œ í•œ ì •í™•í•˜ê²Œ(ì¦‰, bfloat16ê³¼ ìµœëŒ€í•œ ê°€ê¹ê²Œ) ìœ ì§€í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì–‘ìí™”ëŠ” íŠ¹íˆ í…ìŠ¤íŠ¸ ìƒì„±ì— ì˜ ì‘ë™í•˜ëŠ”ë°, ì´ëŠ” ìš°ë¦¬ê°€ *ê°€ì¥ ê°€ëŠ¥ì„± ìˆëŠ” ë‹¤ìŒ í† í° ì§‘í•©*ì„ ì„ íƒí•˜ëŠ” ê²ƒì— ì´ˆì ì„ ë‘ê³  ìˆê¸° ë•Œë¬¸ì´ë©°, ë‹¤ìŒ í† í°ì˜ *logit* ë¶„í¬ê°’ì„ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•  í•„ìš”ëŠ” ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í•µì‹¬ì€ ë‹¤ìŒ í† í° *logit* ë¶„í¬ê°€ ëŒ€ëµì ìœ¼ë¡œ ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ì–´ `argmax` ë˜ëŠ” `topk` ì—°ì‚°ì´ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ì–‘í•œ ì–‘ìí™” ê¸°ë²•ì´ ì¡´ì¬í•˜ì§€ë§Œ, ìì„¸íˆ ë‹¤ë£¨ì§€ëŠ” ì•Šì„ ê²ƒì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë“  ì–‘ìí™” ê¸°ë²•ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë™í•©ë‹ˆë‹¤:\n",
    "\n",
    "-   1.  ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ëª©í‘œ ì •ë°€ë„ë¡œ ì–‘ìí™”í•©ë‹ˆë‹¤.\n",
    "-   2.  ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ê³ , bfloat16 ì •ë°€ë„ì˜ ì…ë ¥ ë²¡í„° ì‹œí€€ìŠ¤ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "-   3.  ê°€ì¤‘ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ bfloat16ìœ¼ë¡œ ë°˜ëŒ€ë¡œ ì–‘ìí™”(dequantize)í•˜ì—¬ ì…ë ¥ ë²¡í„°ì™€ í•¨ê»˜ bfloat16 ì •ë°€ë„ë¡œ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê°„ë‹¨íˆ ë§í•´ì„œ, *ì…ë ¥-ê°€ì¤‘ì¹˜ í–‰ë ¬* ê³±ì…ˆì€, $ X $ê°€ *ì…ë ¥*, $ W $ê°€ ê°€ì¤‘ì¹˜ í–‰ë ¬, $ Y $ê°€ ì¶œë ¥ì¸ ê²½ìš° ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$ Y = X * W $$\n",
    "\n",
    "ìœ„ ê³µì‹ì´ ë‹¤ìŒê³¼ ê°™ì´ ë³€ê²½ë©ë‹ˆë‹¤\n",
    "\n",
    "$$ Y = X * \\text{dequantize}(W) $$\n",
    "\n",
    "ëª¨ë“  í–‰ë ¬ ê³±ì…ˆì— ëŒ€í•´ ìœ„ì™€ ê°™ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤. ì…ë ¥ì´ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¥¼ í†µê³¼í•˜ë©´ì„œ ëª¨ë“  ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ì—­ì–‘ìí™”(dequantization)ì™€ ì¬ì–‘ìí™”(re-quantization)ê°€ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ, ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•  ë•Œ ì¶”ë¡  ì‹œê°„ì´ ê°ì†Œí•˜ì§€ **ì•Šê³ ** ì˜¤íˆë ¤ ì¦ê°€í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ì œ ì´ë¡ ì€ ì¶©ë¶„í•˜ë‹ˆ ì‹¤ì œë¡œ ì‹œë„í•´ ë´…ì‹œë‹¤! Transformersë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì–‘ìí™”í•˜ë ¤ë©´ [`bitsandbytes`](https://github.com/TimDettmers/bitsandbytes) ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "```bash\n",
    "!pip install bitsandbytes\n",
    "```\n",
    "\n",
    "ê·¸ëŸ° ë‹¤ìŒ `from_pretrained`ì— `load_in_8bit=True` í”Œë˜ê·¸ë¥¼ ì¶”ê°€í•˜ì—¬ 8ë¹„íŠ¸ ì–‘ìí™”ë¡œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/octocoder\", quantization_config=BitsAndBytesConfig(load_in_8bit=True), pad_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì˜ˆì œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ê³  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¸¡ì •í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "result = pipe(prompt, max_new_tokens=60)[0][\"generated_text\"][len(prompt):]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "Here is a Python function that transforms bytes to Giga bytes:\\n\\n```python\\ndef bytes_to_giga_bytes(bytes):\\n    return bytes / 1024 / 1024 / 1024\\n```\\n\\nThis function takes a single\n",
    "```\n",
    "\n",
    "ì¢‹ìŠµë‹ˆë‹¤. ì •í™•ë„ ì†ì‹¤ ì—†ì´ ì´ì „ê³¼ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤! ì´ë²ˆì—ëŠ” ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ ì–‘ì„ í™•ì¸í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_to_giga_bytes(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "15.219234466552734\n",
    "```\n",
    "\n",
    "í›¨ì”¬ ì ë„¤ìš”! ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 15GBë¥¼ ì¡°ê¸ˆ ë„˜ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì¤„ì–´ë“¤ì–´ 4090ê³¼ ê°™ì€ ì†Œë¹„ììš© GPUì—ì„œë„ ì´ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì—ì„œ ë§¤ìš° í° í–¥ìƒì„ ë³´ì´ê³  ìˆìœ¼ë©° ëª¨ë¸ ì¶œë ¥ì˜ í’ˆì§ˆ ì €í•˜ë„ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¶”ë¡  ì¤‘ì— ì•½ê°„ì˜ ì†ë„ ì €í•˜ê°€ ë°œìƒí•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ëª¨ë¸ì„ ì‚­ì œí•˜ê³  ë©”ëª¨ë¦¬ë¥¼ ë‹¤ì‹œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ 4ë¹„íŠ¸ ì–‘ìí™”ê°€ ì œê³µí•˜ëŠ” ìµœëŒ€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•´ ë´…ì‹œë‹¤. 4ë¹„íŠ¸ë¡œ ëª¨ë¸ì„ ì–‘ìí™”í•˜ë ¤ë©´ ì´ì „ê³¼ ë™ì¼í•œ APIë¥¼ ì‚¬ìš©í•˜ë˜ ì´ë²ˆì—ëŠ” `load_in_8bit=True` ëŒ€ì‹  `load_in_4bit=True`ë¥¼ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/octocoder\", quantization_config=BitsAndBytesConfig(load_in_8bit=True), pad_token_id=0)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "result = pipe(prompt, max_new_tokens=60)[0][\"generated_text\"][len(prompt):]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "Here is a Python function that transforms bytes to Giga bytes:\\n\\n```\\ndef bytes_to_gigabytes(bytes):\\n    return bytes / 1024 / 1024 / 1024\\n```\\n\\nThis function takes a single argument\n",
    "```\n",
    "\n",
    "ë°”ë¡œ ì „ ì½”ë“œ ìŠ¤ë‹ˆí«ì—ì„œ `python`ë§Œ ëˆ„ë½ë˜ê³ , ì´ ì „ê³¼ ê±°ì˜ ë™ì¼í•œ ì¶œë ¥ í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ìˆìŠµë‹ˆë‹¤. ì´ì œ ì–¼ë§ˆë‚˜ ë§ì€ ë©”ëª¨ë¦¬ê°€ í•„ìš”í–ˆëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_to_giga_bytes(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "9.543574333190918\n",
    "```\n",
    "\n",
    "9.5GBë°–ì— ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤! 150ì–µ ê°œ ì´ìƒì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ëª¨ë¸ì¸ ê²ƒì„ ê°ì•ˆí•˜ë©´ ë§¤ìš° ì ì€ ì–‘ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì˜ ì •í™•ë„ ì €í•˜ê°€ ê±°ì˜ ì—†ìŒì„ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ, ì‹¤ì œë¡œëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ 8ë¹„íŠ¸ ì–‘ìí™”ë‚˜ `bfloat16`ë¥¼ ì‚¬ìš©í•œ ì¶”ë¡  ê²°ê³¼ì™€ ë¹„êµí•˜ë©´ ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì§ì ‘ ì‹œë„í•´ ë³´ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ 4ë¹„íŠ¸ ì–‘ìí™”ì— ì‚¬ìš©ëœ ë” ê³µê²©ì ì¸ ì–‘ìí™” ë°©ë²•ìœ¼ë¡œ ì¸í•´ ì¶”ë¡  ì‹œ $ \\text{quantize} $ì™€ $ \\text{dequantize} $ ê³¼ì •ì´ ë” ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ì—¬ê¸°ì„œë„ 8ë¹„íŠ¸ ì–‘ìí™”ì™€ ë¹„êµí•˜ì—¬ ì¶”ë¡  ì†ë„ê°€ ì•½ê°„ ëŠë ¤ì¡ŒìŒì„ ìœ ì˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì „ì²´ì ìœ¼ë¡œ OctoCoderë¥¼ 8ë¹„íŠ¸ ì •ë°€ë„ë¡œ ì‹¤í–‰í•˜ë©´ í•„ìš”í•œ GPU VRAMì´ 32GBì—ì„œ 15GBë¡œ ì¤„ì–´ë“¤ì—ˆê³ , 4ë¹„íŠ¸ ì •ë°€ë„ë¡œ ëª¨ë¸ì„ ì‹¤í–‰í•˜ë©´ í•„ìš”í•œ GPU VRAMì´ 9GBë¡œ ë” ì¤„ì–´ë“œëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "4ë¹„íŠ¸ ì–‘ìí™”ëŠ” RTX3090, V100, T4ì™€ ê°™ì€ GPUì—ì„œ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, ì´ëŠ” ëŒ€ë¶€ë¶„ì˜ ì‚¬ëŒë“¤ì´ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” GPUì…ë‹ˆë‹¤.\n",
    "\n",
    "ì–‘ìí™”ì— ëŒ€í•œ ë” ë§ì€ ì •ë³´ë¥¼ í™•ì¸í•˜ê³  4ë¹„íŠ¸ë³´ë‹¤ ë” ì ì€ GPU VRAM ë©”ëª¨ë¦¬ë¡œ ëª¨ë¸ì„ ì–‘ìí™”í•˜ê±°ë‚˜, ë” ë§ì€ ì–‘ìí™” ê´€ë ¨ ì •ë³´ë¥¼ ë³´ë ¤ë©´ [`AutoGPTQ`](https://huggingface.co/docs/transformers/main/en/main_classes/quantization#autogptq-integration%60) êµ¬í˜„ì„ ì°¸ì¡°í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "\n",
    "> ê²°ë¡ ì ìœ¼ë¡œ, ëª¨ë¸ ì–‘ìí™”ëŠ” í–¥ìƒëœ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ëª¨ë¸ ì •í™•ì„± ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ê²ƒì´ë©°, ê²½ìš°ì— ë”°ë¼ ì¶”ë¡  ì‹œê°„ì—ë„ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤ì œ ì‚¬ë¡€ì—ì„œ GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë‹¤ë©´, ì–‘ìí™”ë¥¼ ê³ ë ¤í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë§ì€ GPUëŠ” ì–‘ìí™” ì—†ì´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìœ¼ë©°, ì´ ê²½ìš° 4ë¹„íŠ¸ ë° 8ë¹„íŠ¸ ì–‘ìí™”ê°€ ë§¤ìš° ìœ ìš©í•œ ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš©ê³¼ ê´€ë ¨í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” [íŠ¸ëœìŠ¤í¬ë¨¸ ì–‘ìí™” ë¬¸ì„œ](https://huggingface.co/docs/transformers/main_classes/quantization#general-usage)ë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ì¶”ì²œí•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ë” ë‚˜ì€ ì•Œê³ ë¦¬ì¦˜ê³¼ ê°œì„ ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í”Œë˜ì‹œ ì–´í…ì…˜ [[2-flash-attention]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ëŠ˜ë‚ ì˜ ìµœê³  ì„±ëŠ¥ì„ ìë‘í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ëŒ€ì²´ë¡œ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´(feed-forward layer), í™œì„±í™” ë ˆì´ì–´(activation layer), ë ˆì´ì–´ ì •ê·œí™” ë ˆì´ì–´(layer normalization layer), ê·¸ë¦¬ê³  ê°€ì¥ ì¤‘ìš”í•œ ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´(self-attention layer)ë¡œ êµ¬ì„±ëœ ì•„í‚¤í…ì²˜ë¥¼ ê³µìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ëŠ” ì…ë ¥ í† í° ê°„ì˜ ë¬¸ë§¥ì  ê´€ê³„ë¥¼ ì´í•´í•  ìˆ˜ ìˆê²Œ í•´ ì£¼ê¸° ë•Œë¬¸ì— ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤.\n",
    "í•˜ì§€ë§Œ ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ì˜ ìµœëŒ€ GPU ë©”ëª¨ë¦¬ ì†Œë¹„ëŠ” ì…ë ¥ í† í°ì˜ ìˆ˜(ì´í•˜ $ N $ìœ¼ë¡œ í‘œê¸°)ì™€ í•¨ê»˜ ê³„ì‚° ë° ë©”ëª¨ë¦¬ ë³µì¡ì„±ì´ *2ì°¨ì *ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤. ì…ë ¥ ì‹œí€€ìŠ¤ê°€ ì§§ì€ ê²½ìš°(ìµœëŒ€ 1000ê°œ)ì—ëŠ” í¬ê²Œ ëˆˆì— ë„ì§€ ì•Šì§€ë§Œ, ë” ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤(ì•½ 16000ê°œ)ì—ì„œëŠ” ì‹¬ê°í•œ ë¬¸ì œê°€ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ìì„¸íˆ í•œ ë²ˆ ë“¤ì—¬ë‹¤ ë´…ì‹œë‹¤. ê¸¸ì´ $ N $ì˜ ì…ë ¥ $ \\mathbf{X} $ì— ëŒ€í•œ ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ì˜ ì¶œë ¥ $ \\mathbf{O} $ì„ ê³„ì‚°í•˜ëŠ” ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$ \\textbf{O} = \\text{Attn}(\\mathbf{X}) = \\mathbf{V} \\times \\text{Softmax}(\\mathbf{QK}^T) \\text{ with } \\mathbf{Q} = \\mathbf{W}_q \\mathbf{X}, \\mathbf{V} = \\mathbf{W}_v \\mathbf{X}, \\mathbf{K} = \\mathbf{W}_k \\mathbf{X} $$\n",
    "\n",
    "$ \\mathbf{X} = (\\mathbf{x}1, ... \\mathbf{x}{N}) $ëŠ” ì–´í…ì…˜ ë ˆì´ì–´ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ì…ë‹ˆë‹¤. í”„ë¡œì ì…˜ $ \\mathbf{Q} $ì™€ $ \\mathbf{K} $ëŠ” ê°ê° $ N $ê°œì˜ ë²¡í„°ë¡œ êµ¬ì„±ë˜ë©°, ê·¸ ê²°ê³¼ $ \\mathbf{QK}^T $ì˜ í¬ê¸°ëŠ” $ N^2 $ê°€ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ê°€ì§€ê³  ìˆì–´ ì—¬ëŸ¬ ê°œì˜ ì…€í”„ ì–´í…ì…˜ ê³„ì‚°ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ 40ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ê°€ì§€ê³  bfloat16 ì •ë°€ë„ë¡œ ì‹¤í–‰ëœë‹¤ê³  ê°€ì •í•˜ë©´, $ \\mathbf{QK^T} $ í–‰ë ¬ì„ ì €ì¥í•˜ëŠ” ë° í•„ìš”í•œ ë©”ëª¨ë¦¬ë¥¼ $ 40 * 2 * N^2 $ ë°”ì´íŠ¸ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. $ N=1000 $ì¼ ë•ŒëŠ” ì•½ 50MBì˜ VRAMë§Œ í•„ìš”í•˜ì§€ë§Œ, $ N=16000 $ì¼ ë•ŒëŠ” 19GBì˜ VRAMì´ í•„ìš”í•˜ë©°, $ N=100,000 $ì¼ ë•ŒëŠ” $ \\mathbf{QK^T} $ í–‰ë ¬ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ê±°ì˜ 1TBì˜ VRAMì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ìš”ì•½í•˜ìë©´, ê¸°ë³¸ ì…€í”„ ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ì€ í° ì…ë ¥ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë§¤ìš° ê³¼ë„í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìš”êµ¬í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ì´ ê°œì„ ë˜ë©´ì„œ ì ì  ë” ë³µì¡í•œ ì‘ì—…ì— ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•œë•Œ ëª‡ ë¬¸ì¥ì˜ ë²ˆì—­ì´ë‚˜ ìš”ì•½ì„ ì²˜ë¦¬í•˜ë˜ ëª¨ë¸ì´ ì´ì œëŠ” ì „ì²´ í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•´ì•¼ í•˜ê²Œ ë˜ë©´ì„œ ê´‘ë²”ìœ„í•œ ì…ë ¥ ê¸¸ì´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ìš”êµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì–´ë–»ê²Œ í•˜ë©´ í° ì…ë ¥ ê¸¸ì´ì— ëŒ€í•œ ê³¼ë„í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ë¥¼ ì—†ì•¨ ìˆ˜ ìˆì„ê¹Œìš”? $ QK^T $ í–‰ë ¬ì„ ì œê±°í•˜ëŠ” ìƒˆë¡œìš´ ì…€í”„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤. [Tri Dao et al.](https://huggingface.co/papers/2205.14135)ì€ ë°”ë¡œ ì´ëŸ¬í•œ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•˜ì˜€ê³ , ê·¸ê²ƒì´ **í”Œë˜ì‹œ ì–´í…ì…˜(Flash Attention)**ì…ë‹ˆë‹¤.\n",
    "\n",
    "ê°„ë‹¨íˆ ë§í•´, í”Œë˜ì‹œ ì–´í…ì…˜ì€ $\\mathbf{V} \\times \\text{Softmax}(\\mathbf{QK}^T$) ê³„ì‚°ì„ ë¶„í• í•˜ëŠ”ë°, ì—¬ëŸ¬ ë²ˆì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ê³„ì‚°ì„ ë°˜ë³µí•˜ë©´ì„œ ì‘ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ì¶œë ¥ì„ ê³„ì‚°í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$ \\textbf{O}_i \\leftarrow s^a_{ij} * \\textbf{O}_i + s^b_{ij} * \\mathbf{V}_{j} \\times \\text{Softmax}(\\mathbf{QK}^T_{i,j}) \\text{ for multiple } i, j \\text{ iterations} $$\n",
    "\n",
    "ì—¬ê¸°ì„œ $ s^a_{ij} $ì™€ $ s^b_{ij} $ëŠ” ê° $ i $ì™€ $ j $ì— ëŒ€í•´ ê³„ì‚°ë˜ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ ì •ê·œí™” í†µê³„ëŸ‰ì…ë‹ˆë‹¤.\n",
    "\n",
    "í”Œë˜ì‹œ ì–´í…ì…˜ì˜ ì „ì²´ ì•Œê³ ë¦¬ì¦˜ì€ ë” ë³µì¡í•˜ë©°, ë³¸ ê°€ì´ë“œì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ê¸° ë•Œë¬¸ì— í¬ê²Œ ë‹¨ìˆœí™”í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì€ ì˜ ì‘ì„±ëœ [Flash Attention paper](https://huggingface.co/papers/2205.14135) ë…¼ë¬¸ì„ ì°¸ì¡°í•˜ì—¬ ë” ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ìš”ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "> ì†Œí”„íŠ¸ë§¥ìŠ¤ ì •ê·œí™” í†µê³„ëŸ‰ê³¼ ëª‡ ê°€ì§€ ìŠ¤ë§ˆíŠ¸í•œ ìˆ˜í•™ì  ë°©ë²•ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, í”Œë˜ì‹œ ì–´í…ì…˜ì€ ê¸°ë³¸ ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ì™€ **ìˆ«ìì ìœ¼ë¡œ ë™ì¼í•œ** ì¶œë ¥ì„ ì œê³µí•˜ê³  ë©”ëª¨ë¦¬ ë¹„ìš©ì€ $ N $ì— ë”°ë¼ ì„ í˜•ì ìœ¼ë¡œë§Œ ì¦ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê³µì‹ì„ ë³´ë©´, í”Œë˜ì‹œ ì–´í…ì…˜ì´ ë” ë§ì€ ê³„ì‚°ì„ í•„ìš”ë¡œ í•˜ê¸° ë•Œë¬¸ì— ê¸°ë³¸ ì…€í”„ ì–´í…ì…˜ ê³µì‹ë³´ë‹¤ í›¨ì”¬ ëŠë¦´ ê²ƒì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ í”Œë˜ì‹œ ì–´í…ì…˜ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì •ê·œí™” í†µê³„ëŸ‰ì„ ì§€ì†ì ìœ¼ë¡œ ë‹¤ì‹œ ê³„ì‚°í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì¼ë°˜ ì–´í…ì…˜ë³´ë‹¤ ë” ë§ì€ FLOPì´ í•„ìš”í•©ë‹ˆë‹¤. (ë” ìì„¸í•œ ë‚´ìš©ì€ [ë…¼ë¬¸](https://huggingface.co/papers/2205.14135)ì„ ì°¸ì¡°í•˜ì„¸ìš”)\n",
    "\n",
    "> ê·¸ëŸ¬ë‚˜ í”Œë˜ì‹œ ì–´í…ì…˜ì€ ê¸°ë³¸ ì–´í…ì…˜ë³´ë‹¤ ì¶”ë¡  ì†ë„ê°€ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤. ì´ëŠ” GPUì˜ ëŠë¦¬ê³  ê³ ëŒ€ì—­í­ ë©”ëª¨ë¦¬(VRAM)ì˜ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì´ê³  ëŒ€ì‹  ë¹ ë¥¸ ì˜¨ì¹© ë©”ëª¨ë¦¬(SRAM)ì— ì§‘ì¤‘í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë³¸ì§ˆì ìœ¼ë¡œ, í”Œë˜ì‹œ ì–´í…ì…˜ì˜ ëª¨ë“  ì¤‘ê°„ ë‹¨ê³„ì˜ ì“°ê¸° ë° ì½ê¸° ì‘ì—…ì€ ëŠë¦° VRAM ë©”ëª¨ë¦¬ì— ì ‘ê·¼í•˜ì§€ ì•Šê³  ë¹ ë¥¸ *ì˜¨ì¹©* SRAM ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ ë²¡í„° $ \\mathbf{O} $ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì‹¤ì ìœ¼ë¡œ í”Œë˜ì‹œ ì–´í…ì…˜ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì´ë¥¼ **ì‚¬ìš©í•˜ì§€ ì•Šì„** ì´ìœ ëŠ” ì „í˜€ ì—†ìŠµë‹ˆë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¼í•œ ì¶œë ¥ì„ ì œê³µí•˜ë©°, ë” ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤ì œ ì˜ˆë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì•„í‚¤í…ì²˜ í˜ì‹  [[3-architectural-innovations]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” ê³„ì‚° ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë‹¤ìŒì„ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤:\n",
    "\n",
    "-   ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì€ ì •ë°€ë„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "-   ì…€í”„ ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ì„ ë³´ë‹¤ ë” ë©”ëª¨ë¦¬ ë° ê³„ì‚° íš¨ìœ¨ì ì¸ ë²„ì „ìœ¼ë¡œ êµì²´\n",
    "\n",
    "ì´ì œ ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥ì´ í•„ìš”í•œ ì‘ì—…ì— ê°€ì¥ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¡œ ë³€ê²½í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì‘ì—…ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "-   ê²€ìƒ‰ ì¦ê°• ì§ˆì˜ ì‘ë‹µ\n",
    "-   ìš”ì•½\n",
    "-   ì±„íŒ…\n",
    "\n",
    "*ì±„íŒ…*ì„ ìœ„í•´ì„œëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ ì‚¬ìš©ìì™€ ì–´ì‹œìŠ¤í„´íŠ¸ ê°„ì˜ ëŒ€í™”ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤(ì˜ˆ: ChatGPT).\n",
    "\n",
    "í•œë²ˆ í•™ìŠµëœ í›„ì—ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê¸°ë³¸ ì•„í‚¤í…ì²˜ë¥¼ ë³€ê²½í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì—, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì‘ì—…ì— ëŒ€í•œ ê³ ë ¤ë¥¼ ë¯¸ë¦¬ í•˜ê³  ì´ì— ë”°ë¼ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ë¥¼ ìµœì í™”í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ë©”ëª¨ë¦¬ ë˜ëŠ” ì„±ëŠ¥ì˜ ë³‘ëª© í˜„ìƒì„ ë¹ ë¥´ê²Œ ë°œìƒì‹œí‚¤ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ì˜ ì¤‘ìš”í•œ ë‘ ê°€ì§€ êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "-   ìœ„ì¹˜ ì„ë² ë”©\n",
    "-   í‚¤-ê°’ ìºì‹œ\n",
    "\n",
    "ê° êµ¬ì„± ìš”ì†Œë¥¼ ë” ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ìœ„ì¹˜ ì„ë² ë”© ê°œì„  [[31-improving-positional-embeddings-of-llms]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì…€í”„ ì–´í…ì…˜ì€ ê° í† í°ì„ ì„œë¡œì˜ í† í°ê³¼ ì—°ê´€ì‹œí‚µë‹ˆë‹¤.\n",
    "ì˜ˆë¥¼ ë“¤ì–´, í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œí€€ìŠ¤ *\"Hello\", \"I\", \"love\", \"you\"*ì˜ $ \\text{Softmax}(\\mathbf{QK}^T) $ í–‰ë ¬ì€ ë‹¤ìŒê³¼ ê°™ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "![](https://huggingface.co/docs/transformers/main/ko//blog/assets/163_optimize_llm/self_attn_tokens.png)\n",
    "\n",
    "ê° ë‹¨ì–´ í† í°ì€ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ í† í°ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ëŠ” í™•ë¥  ì§ˆëŸ‰ì„ ë¶€ì—¬ë°›ì•„ ëª¨ë“  ë‹¤ë¥¸ ë‹¨ì–´ í† í°ê³¼ ê´€ê³„ë¥¼ ë§ºê²Œ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ì–´ *\"love\"*ëŠ” ë‹¨ì–´ *\"Hello\"*ì— 5%, *\"I\"*ì— 30%, ê·¸ë¦¬ê³  ìì‹ ì—ê²Œ 65%ì˜ ì£¼ì˜ë¥¼ ê¸°ìš¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì…€í”„ ì–´í…ì…˜ ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ìœ„ì¹˜ ì„ë² ë”©ì´ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ì…ë ¥ì˜ ìœ„ì¹˜ë¥¼ ì´í•´í•˜ëŠ” ë° í° ì–´ë ¤ì›€ì„ ê²ªì„ ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” $ \\mathbf{QK}^T $ì— ì˜í•´ ê³„ì‚°ëœ í™•ë¥  ì ìˆ˜ê°€ ìƒëŒ€ì  ìœ„ì¹˜ ê±°ë¦¬ì— ìƒê´€ì—†ì´ ê° ë‹¨ì–´ í† í°ì„ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ í† í°ê³¼ $ O(1) $ ê³„ì‚°ìœ¼ë¡œ ì—°ê´€ì‹œí‚¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ìœ„ì¹˜ ì„ë² ë”©ì´ ì—†ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ê° í† í°ì´ ë‹¤ë¥¸ ëª¨ë“  í† í°ê³¼ ë™ì¼í•œ ê±°ë¦¬ì— ìˆëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜ê¸° ë•Œë¬¸ì—, *\"Hello I love you\"*ì™€ *\"You love I hello\"*ë¥¼ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ë¬¸ì¥ì˜ ìˆœì„œë¥¼ ì´í•´í•˜ë ¤ë©´ ì¶”ê°€ì ì¸ *ë‹¨ì„œ*ê°€ í•„ìš”í•˜ë©°, ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ *ìœ„ì¹˜ ì¸ì½”ë”©* (ë˜ëŠ” *ìœ„ì¹˜ ì„ë² ë”©*ì´ë¼ê³ ë„ í•¨)ì˜ í˜•íƒœë¡œ ì ìš©ë©ë‹ˆë‹¤. \n",
    "ìœ„ì¹˜ ì¸ì½”ë”©ì€ ê° í† í°ì˜ ìœ„ì¹˜ë¥¼ ìˆ«ì í‘œí˜„ìœ¼ë¡œ ì¸ì½”ë”©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ë¬¸ì¥ì˜ ìˆœì„œë¥¼ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.\n",
    "\n",
    "[*Attention Is All You Need*](https://huggingface.co/papers/1706.03762) ë…¼ë¬¸ì˜ ì €ìë“¤ì€ ì‚¬ì¸ í•¨ìˆ˜ ê¸°ë°˜ì˜ ìœ„ì¹˜ ì„ë² ë”© $ \\mathbf{P} = \\mathbf{p}_1, \\ldots, \\mathbf{p}_N $ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ê° ë²¡í„° $ \\mathbf{p}_i $ëŠ” ìœ„ì¹˜ $ i $ì˜ ì‚¬ì¸ í•¨ìˆ˜ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. ìœ„ì¹˜ ì¸ì½”ë”©ì€ ì…ë ¥ ì‹œí€€ìŠ¤ ë²¡í„°ì— ë‹¨ìˆœíˆ ë”í•´ì ¸ $ \\mathbf{\\hat{X}} = \\mathbf{\\hat{x}}_1, \\ldots, \\mathbf{\\hat{x}}_N $ = $ \\mathbf{x}_1 + \\mathbf{p}_1, \\ldots, \\mathbf{x}_N + \\mathbf{p}_N $ ëª¨ë¸ì´ ë¬¸ì¥ ìˆœì„œë¥¼ ë” ì˜ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê³ ì •ëœ ìœ„ì¹˜ ì„ë² ë”© ëŒ€ì‹  [Devlin et al.](https://huggingface.co/papers/1810.04805)ê³¼ ê°™ì€ ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì€ í•™ìŠµëœ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ìœ„ì¹˜ ì„ë² ë”© $ \\mathbf{P} $ì€ í•™ìŠµ ì¤‘ì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ì¸ í•¨ìˆ˜ ë° í•™ìŠµëœ ìœ„ì¹˜ ì„ë² ë”©ì€ ë¬¸ì¥ ìˆœì„œë¥¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ì¸ì½”ë”©í•˜ëŠ” ì£¼ìš” ë°©ë²•ì´ì—ˆì§€ë§Œ, ì´ëŸ¬í•œ ìœ„ì¹˜ ì¸ì½”ë”©ê³¼ ê´€ë ¨ëœ ëª‡ ê°€ì§€ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "  1. ì‚¬ì¸ í•¨ìˆ˜ì™€ í•™ìŠµëœ ìœ„ì¹˜ ì„ë² ë”©ì€ ëª¨ë‘ ì ˆëŒ€ ìœ„ì¹˜ ì„ë² ë”©ìœ¼ë¡œ, ê° ìœ„ì¹˜ ID $ 0, \\ldots, N $ì— ëŒ€í•´ ê³ ìœ í•œ ì„ë² ë”©ì„ ì¸ì½”ë”©í•©ë‹ˆë‹¤. [Huang et al.](https://huggingface.co/papers/2009.13658) ë° [Su et al.](https://huggingface.co/papers/2104.09864)ì˜ ì—°êµ¬ì— ë”°ë¥´ë©´, ì ˆëŒ€ ìœ„ì¹˜ ì„ë² ë”©ì€ ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥ì— ëŒ€í•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥ì˜ ê²½ìš°, ëª¨ë¸ì´ ì ˆëŒ€ ìœ„ì¹˜ ëŒ€ì‹  ì…ë ¥ í† í° ê°„ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ê±°ë¦¬ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
    "  2. í•™ìŠµëœ ìœ„ì¹˜ ì„ë² ë”©ì„ ì‚¬ìš©í•  ë•Œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ê³ ì •ëœ ì…ë ¥ ê¸¸ì´ $ N $ìœ¼ë¡œ í•™ìŠµë˜ì–´ì•¼ í•˜ë¯€ë¡œ, í•™ìŠµëœ ì…ë ¥ ê¸¸ì´ë³´ë‹¤ ë” ê¸´ ì…ë ¥ ê¸¸ì´ì— ëŒ€í•´ ì¶”ë¡ í•˜ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìµœê·¼ì—ëŠ” ìœ„ì—ì„œ ì–¸ê¸‰í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ìƒëŒ€ì  ìœ„ì¹˜ ì„ë² ë”©ì´ ë” ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ë“¤ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "-   [Rotary Position Embedding (RoPE)](https://huggingface.co/papers/2104.09864)\n",
    "-   [ALiBi](https://huggingface.co/papers/2108.12409)\n",
    "\n",
    "*RoPE*ì™€ *ALiBi*ëŠ” ëª¨ë‘ ì…€í”„ ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ ë‚´ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ë¬¸ì¥ ìˆœì„œë¥¼ ëª¨ë¸ì—ê²Œ ì•Œë ¤ì£¼ëŠ” ê²ƒì´ ìµœì„ ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ì–´ í† í°ì´ ì„œë¡œ ê´€ê³„ë¥¼ ë§ºëŠ” ê³³ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ë¬¸ì¥ ìˆœì„œë¥¼ $ \\mathbf{QK}^T $ ê³„ì‚°ì„ ìˆ˜ì •í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì•Œë ¤ì£¼ì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "ë„ˆë¬´ ë§ì€ ì„¸ë¶€ ì‚¬í•­ì„ ë‹¤ë£¨ì§€ ì•Šê³ , *RoPE*ëŠ” ìœ„ì¹˜ ì •ë³´ë¥¼ ì¿¼ë¦¬-í‚¤ ìŒì— ì¸ì½”ë”©í•  ìˆ˜ ìˆë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê° ë²¡í„° $ \\mathbf{q}_i $ì™€ $ \\mathbf{x}_j $ë¥¼ ê°ê° $ \\theta * i $ì™€ $ \\theta * j $ì˜ ê°ë„ë¡œ íšŒì „ì‹œí‚´ìœ¼ë¡œì¨ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$ \\mathbf{\\hat{q}}_i^T \\mathbf{\\hat{x}}_j = \\mathbf{{q}}_i^T \\mathbf{R}_{\\theta, i -j} \\mathbf{{x}}_j. $$\n",
    "\n",
    "ì—¬ê¸°ì„œ $ \\mathbf{R}_{\\theta, i - j} $ëŠ” íšŒì „ í–‰ë ¬ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. $ \\theta $ëŠ” í›ˆë ¨ ì¤‘ì— *í•™ìŠµë˜ì§€ ì•Šìœ¼ë©°*, ëŒ€ì‹  í•™ìŠµ ì¤‘ ìµœëŒ€ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë”°ë¼ ì‚¬ì „ ì •ì˜ëœ ê°’ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\n",
    "\n",
    "> ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ $ \\mathbf{q}_i $ì™€ $ \\mathbf{q}_j $ ê°„ì˜ í™•ë¥  ì ìˆ˜ëŠ” $ i \\ne j $ì¸ ê²½ìš°ì—ë§Œ ì˜í–¥ì„ ë°›ìœ¼ë©°, ê° ë²¡í„°ì˜ íŠ¹ì • ìœ„ì¹˜ $ i $ì™€ $ j $ì™€ëŠ” ìƒê´€ì—†ì´ ì˜¤ì§ ìƒëŒ€ì  ê±°ë¦¬ $ i - j $ì—ë§Œ ì˜ì¡´í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "*RoPE*ëŠ” í˜„ì¬ ì—¬ëŸ¬ ì¤‘ìš”í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´:\n",
    "\n",
    "-   [**Falcon**](https://huggingface.co/tiiuae/falcon-40b)\n",
    "-   [**Llama**](https://huggingface.co/papers/2302.13971)\n",
    "-   [**PaLM**](https://huggingface.co/papers/2204.02311)\n",
    "\n",
    "ëŒ€ì•ˆìœ¼ë¡œ, *ALiBi*ëŠ” í›¨ì”¬ ë” ê°„ë‹¨í•œ ìƒëŒ€ì  ìœ„ì¹˜ ì¸ì½”ë”© ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì…ë ¥ í† í° ê°„ì˜ ìƒëŒ€ì  ê±°ë¦¬ë¥¼ ìŒìˆ˜ì¸ ì •ìˆ˜ë¡œì„œ ì‚¬ì „ ì •ì˜ëœ ê°’ `m`ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ $ \\mathbf{QK}^T $ í–‰ë ¬ì˜ ê° ì¿¼ë¦¬-í‚¤ í•­ëª©ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ê³„ì‚° ì§ì „ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "![](https://huggingface.co/docs/transformers/main/ko//blog/assets/163_optimize_llm/alibi.png)\n",
    "\n",
    "[ALiBi](https://huggingface.co/papers/2108.12409) ë…¼ë¬¸ì—ì„œ ë³´ì—¬ì£¼ë“¯ì´, ì´ ê°„ë‹¨í•œ ìƒëŒ€ì  ìœ„ì¹˜ ì¸ì½”ë”©ì€ ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œí€€ìŠ¤ì—ì„œë„ ëª¨ë¸ì´ ë†’ì€ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "*ALiBi*ëŠ” í˜„ì¬ ì—¬ëŸ¬ ì¤‘ìš”í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ëª¨ë¸ì´ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´:\n",
    "\n",
    "-   [**MPT**](https://huggingface.co/mosaicml/mpt-30b)\n",
    "-   [**BLOOM**](https://huggingface.co/bigscience/bloom)\n",
    "\n",
    "*RoPE*ì™€ *ALiBi* ìœ„ì¹˜ ì¸ì½”ë”©ì€ ëª¨ë‘ í•™ìŠµ ì¤‘ì— ë³´ì§€ ëª»í•œ ì…ë ¥ ê¸¸ì´ì— ëŒ€í•´ í™•ì¥í•  ìˆ˜ ìˆìœ¼ë©°, *ALiBi*ê°€ *RoPE*ë³´ë‹¤ ë” ì˜ í™•ì¥ë˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. *ALiBi*ì˜ ê²½ìš°, í•˜ì‚¼ê° ìœ„ì¹˜ í–‰ë ¬ì˜ ê°’ì„ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë§ì¶”ì–´ ì¦ê°€ì‹œí‚¤ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. *RoPE*ì˜ ê²½ìš°, í•™ìŠµ ì¤‘ì— ì‚¬ìš©ëœ ë™ì¼í•œ $ \\theta $ë¥¼ ìœ ì§€í•˜ë©´ í•™ìŠµ ì¤‘ì— ë³´ì§€ ëª»í•œ ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ì „ë‹¬í•  ë•Œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤(ì°¸ê³ : [Press et al.](https://huggingface.co/papers/2108.12409)). ê·¸ëŸ¬ë‚˜ ì»¤ë®¤ë‹ˆí‹°ëŠ” $ \\theta $ë¥¼ ì¡°ì •í•˜ëŠ” ëª‡ ê°€ì§€ íš¨ê³¼ì ì¸ íŠ¸ë¦­ì„ ì°¾ì•„ëƒˆìœ¼ë©°, ì´ë¥¼ í†µí•´ *RoPE* ìœ„ì¹˜ ì„ë² ë”©ì´ í™•ì¥ëœ í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œí€€ìŠ¤ì—ì„œë„ ì˜ ì‘ë™í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤(ì°¸ê³ : [here](https://github.com/huggingface/transformers/pull/24653)).\n",
    "\n",
    "> RoPEì™€ ALiBiëŠ” ëª¨ë‘ í›ˆë ¨ ì¤‘ì— *í•™ìŠµë˜ì§€ ì•ŠëŠ”* ìƒëŒ€ì  ìœ„ì¹˜ ì„ë² ë”©ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì§ê´€ì— ê¸°ë°˜í•©ë‹ˆë‹¤:\n",
    " -   í…ìŠ¤íŠ¸ ì…ë ¥ì— ëŒ€í•œ ìœ„ì¹˜ ë‹¨ì„œëŠ” ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ì˜ $ QK^T $ í–‰ë ¬ì— ì§ì ‘ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    " -   ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ì¼ì •í•œ *ìƒëŒ€ì * ê±°ë¦¬ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì„œë¡œ í•™ìŠµí•˜ë„ë¡ ìœ ë„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    " -   í…ìŠ¤íŠ¸ ì…ë ¥ í† í° ê°„ì˜ ê±°ë¦¬ê°€ ë©€ì–´ì§ˆìˆ˜ë¡, ê·¸ë“¤ì˜ ì¿¼ë¦¬-ê°’ í™•ë¥ ì€ ë‚®ì•„ì ¸ì•¼ í•©ë‹ˆë‹¤. RoPEì™€ ALiBiëŠ” ì„œë¡œ ë©€ë¦¬ ë–¨ì–´ì§„ í† í°ì˜ ì¿¼ë¦¬-í‚¤ í™•ë¥ ì„ ë‚®ì¶¥ë‹ˆë‹¤. RoPEëŠ” ì¿¼ë¦¬-í‚¤ ë²¡í„° ê°„ì˜ ê°ë„ë¥¼ ì¦ê°€ì‹œì¼œ ë²¡í„° ê³±ì„ ê°ì†Œì‹œí‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ, ALiBiëŠ” ë²¡í„° ê³±ì— í° ìŒìˆ˜ë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ë¡ ì ìœ¼ë¡œ, í° í…ìŠ¤íŠ¸ ì…ë ¥ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ì‘ì—…ì— ë°°í¬ë  ì˜ˆì •ì¸  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ RoPEì™€ ALiBiì™€ ê°™ì€ ìƒëŒ€ì  ìœ„ì¹˜ ì„ë² ë”©ìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê²ƒì´ ë” ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ RoPEì™€ ALiBië¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ê³ ì • ê¸¸ì´ $ N_1 = 2048 $ì—ì„œë§Œ í›ˆë ¨ë˜ì—ˆë”ë¼ë„ ìœ„ì¹˜ ì„ë² ë”©ì„ ì™¸ì‚½í•˜ì—¬ $ N_1 $ë³´ë‹¤ í›¨ì”¬ í° í…ìŠ¤íŠ¸ ì…ë ¥ $ N_2 = 8192 > N_1 $ë¡œ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ìœ ì˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 í‚¤-ê°’ ìºì‹œ [[32-the-key-value-cache]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì´ìš©í•œ ìê¸°íšŒê·€ í…ìŠ¤íŠ¸ ìƒì„±ì€ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ë„£ê³ , ë‹¤ìŒ í† í°ì„ ìƒ˜í”Œë§í•˜ë©°, ê·¸ ë‹¤ìŒ í† í°ì„ ì…ë ¥ ì‹œí€€ìŠ¤ì— ì¶”ê°€í•˜ê³ , ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ìƒì„±ì„ ì™„ë£Œí–ˆë‹¤ëŠ” í† í°ì„ ìƒì„±í•  ë•Œê¹Œì§€ ì´ë¥¼ ê³„ì† ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n",
    "\n",
    "ìê¸°íšŒê·€ ìƒì„±ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ì— ëŒ€í•œ ì‹œê°ì  ì„¤ëª…ì„ ë³´ë ¤ë©´ [Transformer's Generate Text Tutorial](https://huggingface.co/docs/transformers/llm_tutorial#generate-text)ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "ìê¸°íšŒê·€ ìƒì„±ì´ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ê°„ë‹¨í•œ ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ì‹¤í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `torch.argmax`ë¥¼ í†µí•´ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‹¤ìŒ í† í°ì„ ê°€ì ¸ì˜¬ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "for _ in range(5):\n",
    "  next_logits = model(input_ids)[\"logits\"][:, -1:]\n",
    "  next_token_id = torch.argmax(next_logits,dim=-1)\n",
    "\n",
    "  input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "  print(\"shape of input_ids\", input_ids.shape)\n",
    "\n",
    "generated_text = tokenizer.batch_decode(input_ids[:, -5:])\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "shape of input_ids torch.Size([1, 21])\n",
    "shape of input_ids torch.Size([1, 22])\n",
    "shape of input_ids torch.Size([1, 23])\n",
    "shape of input_ids torch.Size([1, 24])\n",
    "shape of input_ids torch.Size([1, 25])\n",
    "[' Here is a Python function']\n",
    "```\n",
    "\n",
    "ë³´ì‹œë‹¤ì‹œí”¼ ìƒ˜í”Œë§ëœ í† í°ì— ì˜í•´ í…ìŠ¤íŠ¸ ì…ë ¥ í† í°ì„ ë§¤ë²ˆ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "ë§¤ìš° ì˜ˆì™¸ì ì¸ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ , ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ [ì¸ê³¼ì ì¸ ì–¸ì–´ ëª¨ë¸ë§ ëª©í‘œ](https://huggingface.co/docs/transformers/tasks/language_modeling#causal-language-modeling)ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ë¯€ë¡œ ì–´í…ì…˜ ì ìˆ˜ì˜ ìƒì‚¼ê° í–‰ë ¬ì„ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤. ì´ê²ƒì´ ìœ„ì˜ ë‘ ë‹¤ì´ì–´ê·¸ë¨ì—ì„œ ì–´í…ì…˜ ì ìˆ˜ê°€ ë¹„ì–´ ìˆëŠ” ì´ìœ ì…ë‹ˆë‹¤ (ì¦‰, 0 í™•ë¥ ì„ ê°€ì§). ì¸ê³¼ ì–¸ì–´ ëª¨ë¸ë§ì— ëŒ€í•œ ë¹ ë¥¸ ìš”ì•½ì€ [*Illustrated Self Attention ë¸”ë¡œê·¸*](https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention)ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ì ìœ¼ë¡œ, í† í°ì€ *ì ˆëŒ€* ì´ì „ í† í°ì— ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œëŠ” $ \\mathbf{q}_i $ ë²¡í„°ê°€ $ j > i $ì¸ ê²½ìš° ì–´ë–¤ í‚¤, ê°’ ë²¡í„° $ \\mathbf{k}_j, \\mathbf{v}j $ì™€ë„ ì—°ê´€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  $ \\mathbf{q}i $ëŠ” ì´ì „ì˜ í‚¤-ê°’ ë²¡í„° $ \\mathbf{k}{m < i}, \\mathbf{v}{m < i} \\text{ , for } m \\in {0, \\ldots i - 1} $ì—ë§Œ ì£¼ì˜ë¥¼ ê¸°ìš¸ì…ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ê³„ì‚°ì„ ì¤„ì´ê¸° ìœ„í•´ ê° ì¸µì˜ í‚¤-ê°’ ë²¡í„°ë¥¼ ëª¨ë“  ì´ì „ ì‹œê°„ ë‹¨ê³„ì— ëŒ€í•´ ìºì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒìœ¼ë¡œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ê° í¬ì›Œë“œ íŒ¨ìŠ¤ë§ˆë‹¤ í‚¤-ê°’ ìºì‹œë¥¼ ê²€ìƒ‰í•˜ê³  ì „ë‹¬í•˜ì—¬ ì´ë¥¼ í™œìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤. \n",
    "Transformersì—ì„œëŠ” `forward` í˜¸ì¶œì— `use_cache` í”Œë˜ê·¸ë¥¼ ì „ë‹¬í•˜ì—¬ í‚¤-ê°’ ìºì‹œë¥¼ ê²€ìƒ‰í•œ ë‹¤ìŒ í˜„ì¬ í† í°ê³¼ í•¨ê»˜ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values = None # past_key_values ëŠ” í‚¤-ê°’ ìºì‹œë¥¼ ì˜ë¯¸\n",
    "generated_tokens = []\n",
    "next_token_id = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "for _ in range(5):\n",
    "  next_logits, past_key_values = model(next_token_id, past_key_values=past_key_values, use_cache=True).to_tuple()\n",
    "  next_logits = next_logits[:, -1:]\n",
    "  next_token_id = torch.argmax(next_logits, dim=-1)\n",
    "\n",
    "  print(\"shape of input_ids\", next_token_id.shape)\n",
    "  print(\"length of key-value cache\", len(past_key_values[0][0]))  # past_key_values í˜•íƒœ: [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n",
    "  generated_tokens.append(next_token_id.item())\n",
    "\n",
    "generated_text = tokenizer.batch_decode(generated_tokens)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "shape of input_ids torch.Size([1, 1])\n",
    "length of key-value cache 20\n",
    "shape of input_ids torch.Size([1, 1])\n",
    "length of key-value cache 21\n",
    "shape of input_ids torch.Size([1, 1])\n",
    "length of key-value cache 22\n",
    "shape of input_ids torch.Size([1, 1])\n",
    "length of key-value cache 23\n",
    "shape of input_ids torch.Size([1, 1])\n",
    "length of key-value cache 24\n",
    "[' Here', ' is', ' a', ' Python', ' function']\n",
    "```\n",
    "\n",
    "í‚¤-ê°’ ìºì‹œë¥¼ ì‚¬ìš©í•  ë•Œ, í…ìŠ¤íŠ¸ ì…ë ¥ í† í°ì˜ ê¸¸ì´ëŠ” *ì¦ê°€í•˜ì§€ ì•Šê³ * ë‹¨ì¼ ì…ë ¥ ë²¡í„°ë¡œ ìœ ì§€ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ì— í‚¤-ê°’ ìºì‹œì˜ ê¸¸ì´ëŠ” ê° ë””ì½”ë”© ë‹¨ê³„ë§ˆë‹¤ í•˜ë‚˜ì”© ì¦ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "> í‚¤-ê°’ ìºì‹œë¥¼ ì‚¬ìš©í•˜ë©´ $ \\mathbf{QK}^T $ê°€ ë³¸ì§ˆì ìœ¼ë¡œ $ \\mathbf{q}_c\\mathbf{K}^T $ë¡œ ì¤„ì–´ë“œëŠ”ë°, ì—¬ê¸°ì„œ $ \\mathbf{q}_c $ëŠ” í˜„ì¬ ì „ë‹¬ëœ ì…ë ¥ í† í°ì˜ ì¿¼ë¦¬ í”„ë¡œì ì…˜ìœ¼ë¡œ, *í•­ìƒ* ë‹¨ì¼ ë²¡í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "í‚¤-ê°’ ìºì‹œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì—ëŠ” ë‘ ê°€ì§€ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤:\n",
    "-   ì „ì²´ $ \\mathbf{QK}^T $ í–‰ë ¬ì„ ê³„ì‚°í•˜ëŠ” ê²ƒê³¼ ë¹„êµí•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. ì´ëŠ” ì¶”ë¡  ì†ë„ì˜ ì¦ê°€ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.\n",
    "-   ìƒì„±ëœ í† í° ìˆ˜ì— ë”°ë¼ í•„ìš”í•œ ìµœëŒ€ ë©”ëª¨ë¦¬ê°€ ì´ì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ì§€ ì•Šê³ , ì„ í˜•ì ìœ¼ë¡œë§Œ ì¦ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "> ë” ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ë™ì¼í•œ ê²°ê³¼ì™€ í° ì†ë„ í–¥ìƒì„ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— í‚¤-ê°’ ìºì‹œë¥¼ *í•­ìƒ* ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. TransformersëŠ” í…ìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ì´ë‚˜ [`generate` ë©”ì„œë“œ](https://huggingface.co/docs/transformers/main_classes/text_generation)ë¥¼ ì‚¬ìš©í•  ë•Œ ê¸°ë³¸ì ìœ¼ë¡œ í‚¤-ê°’ ìºì‹œë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "<Tip warning={true}>\n",
    "\n",
    "ì°¸ê³ ë¡œ, í‚¤-ê°’ ìºì‹œë¥¼ ì‚¬ìš©í•  ê²ƒì„ ê¶Œì¥í•˜ì§€ë§Œ, ì´ë¥¼ ì‚¬ìš©í•  ë•Œ LLM ì¶œë ¥ì´ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í–‰ë ¬ ê³±ì…ˆ ì»¤ë„ ìì²´ì˜ íŠ¹ì„± ë•Œë¬¸ì…ë‹ˆë‹¤ -- ë” ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://github.com/huggingface/transformers/issues/25420#issuecomment-1775317535)ì—ì„œ ì½ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 ë©€í‹° ë¼ìš´ë“œ ëŒ€í™” [[321-multi-round-conversation]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í‚¤-ê°’ ìºì‹œëŠ” ì—¬ëŸ¬ ë²ˆì˜ ìê¸°íšŒê·€ ë””ì½”ë”©ì´ í•„ìš”í•œ ì±„íŒ…ê³¼ ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì— íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆì œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "User: How many people live in France?\n",
    "Assistant: Roughly 75 million people live in France\n",
    "User: And how many are in Germany?\n",
    "Assistant: Germany has ca. 81 million inhabitants\n",
    "```\n",
    "\n",
    "ì´ ì±„íŒ…ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë‘ ë²ˆì˜ ìê¸°íšŒê·€ ë””ì½”ë”©ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:\n",
    "  1. ì²« ë²ˆì§¸ë¡œ, í‚¤-ê°’ ìºì‹œëŠ” ë¹„ì–´ ìˆê³  ì…ë ¥ í”„ë¡¬í”„íŠ¸ëŠ” `\"User: How many people live in France?\"`ì…ë‹ˆë‹¤. ëª¨ë¸ì€ ìê¸°íšŒê·€ì ìœ¼ë¡œ `\"Roughly 75 million people live in France\"`ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë©° ë””ì½”ë”© ë‹¨ê³„ë§ˆë‹¤ í‚¤-ê°’ ìºì‹œë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
    "  2. ë‘ ë²ˆì§¸ë¡œ, ì…ë ¥ í”„ë¡¬í”„íŠ¸ëŠ” `\"User: How many people live in France? \\n Assistant: Roughly 75 million people live in France \\n User: And how many in Germany?\"`ì…ë‹ˆë‹¤. ìºì‹œ ë•ë¶„ì— ì²« ë²ˆì§¸ ë‘ ë¬¸ì¥ì— ëŒ€í•œ ëª¨ë“  í‚¤-ê°’ ë²¡í„°ëŠ” ì´ë¯¸ ê³„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì…ë ¥ í”„ë¡¬í”„íŠ¸ëŠ” `\"User: And how many in Germany?\"`ë¡œë§Œ êµ¬ì„±ë©ë‹ˆë‹¤. ì¤„ì–´ë“  ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë™ì•ˆ ê³„ì‚°ëœ í‚¤-ê°’ ë²¡í„°ê°€ ì²« ë²ˆì§¸ ë””ì½”ë”©ì˜ í‚¤-ê°’ ìºì‹œì— ì—°ê²°ë©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë‹µë³€ì¸ `\"Germany has ca. 81 million inhabitants\"`ëŠ” `\"User: How many people live in France? \\n Assistant: Roughly 75 million people live in France \\n User: And how many are in Germany?\"`ì˜ ì¸ì½”ë”©ëœ í‚¤-ê°’ ë²¡í„°ë¡œ êµ¬ì„±ëœ í‚¤-ê°’ ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ìê¸°íšŒê·€ì ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œ ë‘ ê°€ì§€ë¥¼ ì£¼ëª©í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "  1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ëŒ€í™”ì˜ ëª¨ë“  ì´ì „ ë¬¸ë§¥ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ëª¨ë“  ë¬¸ë§¥ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì±„íŒ…ì— ë°°í¬ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì—ì„œëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìœ„ì˜ ì˜ˆì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ì‚¬ìš©ìê°€ `\"And how many are in Germany\"`ë¼ê³  ë¬¼ì„ ë•Œ ì¸êµ¬ë¥¼ ì–¸ê¸‰í•˜ê³  ìˆìŒì„ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "  2. í‚¤-ê°’ ìºì‹œëŠ” ì±„íŒ…ì—ì„œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ì¸ì½”ë”©ëœ ì±„íŒ… ê¸°ë¡ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì¸ì½”ë”©í•  í•„ìš” ì—†ì´ ê³„ì†í•´ì„œ í™•ì¥í•  ìˆ˜ ìˆê²Œ í•´ì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤(ì˜ˆ: ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•  ë•Œì™€ ê°™ì€ ê²½ìš°).\n",
    "\n",
    "`transformers`ì—ì„œ `generate` í˜¸ì¶œì€ ê¸°ë³¸ì ìœ¼ë¡œ `use_cache=True`ì™€ í•¨ê»˜ `return_dict_in_generate=True`ë¥¼ ì „ë‹¬í•˜ë©´ `past_key_values`ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ëŠ” ì•„ì§ `pipeline` ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ì„œëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¼ë°˜ì ì¸ ìƒì„±\n",
    "prompt = system_prompt + \"Question: Please write a function in Python that transforms bytes to Giga bytes.\\n\\nAnswer: Here\"\n",
    "model_inputs = tokenizer(prompt, return_tensors='pt')\n",
    "generation_output = model.generate(**model_inputs, max_new_tokens=60, return_dict_in_generate=True)\n",
    "decoded_output = tokenizer.batch_decode(generation_output.sequences)[0]\n",
    "\n",
    "# ë¦¬í„´ëœ `past_key_values`ë¥¼ íŒŒì´í”„ë¼ì¸í™”í•˜ì—¬ ë‹¤ìŒ ëŒ€í™” ë¼ìš´ë“œë¥¼ ê°€ì†í™”\n",
    "prompt = decoded_output + \"\\nQuestion: How can I modify the function above to return Mega bytes instead?\\n\\nAnswer: Here\"\n",
    "model_inputs = tokenizer(prompt, return_tensors='pt')\n",
    "generation_output = model.generate(\n",
    "  **model_inputs,\n",
    "  past_key_values=generation_output.past_key_values,\n",
    "  max_new_tokens=60,\n",
    "  return_dict_in_generate=True\n",
    ")\n",
    "tokenizer.batch_decode(generation_output.sequences)[0][len(prompt):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    " is a modified version of the function that returns Mega bytes instead.\n",
    "\n",
    "def bytes_to_megabytes(bytes):\n",
    "   return bytes / 1024 / 1024\n",
    "\n",
    "Answer: The function takes a number of bytes as input and returns the number of\n",
    "```\n",
    "\n",
    "í›Œë¥­í•©ë‹ˆë‹¤. ì–´í…ì…˜ ì¸µì˜ ë™ì¼í•œ í‚¤ì™€ ê°’ì„ ë‹¤ì‹œ ê³„ì‚°í•˜ëŠ” ë° ì¶”ê°€ ì‹œê°„ì´ ì†Œìš”ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤! ê·¸ëŸ¬ë‚˜ í•œ ê°€ì§€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. $ \\mathbf{QK}^T $ í–‰ë ¬ì— í•„ìš”í•œ ìµœëŒ€ ë©”ëª¨ë¦¬ëŠ” í¬ê²Œ ì¤„ì–´ë“¤ì§€ë§Œ, ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤ë‚˜ ë‹¤íšŒì°¨ ì±„íŒ…ì˜ ê²½ìš° í‚¤-ê°’ ìºì‹œë¥¼ ë©”ëª¨ë¦¬ì— ë³´ê´€í•˜ëŠ” ê²ƒì´ ë§¤ìš° ë©”ëª¨ë¦¬ ì§‘ì•½ì ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‚¤-ê°’ ìºì‹œëŠ” ëª¨ë“  ìê¸° ì–´í…ì…˜ ì¸µê³¼ ëª¨ë“  ì–´í…ì…˜ í—¤ë“œì— ëŒ€í•´ ì´ì „ ì…ë ¥ ë²¡í„° $ \\mathbf{x}_i \\text{, for } i \\in {1, \\ldots, c - 1} $ì˜ í‚¤-ê°’ ë²¡í„°ë¥¼ ì €ì¥í•´ì•¼ í•œë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”.\n",
    "\n",
    "ì´ì „ì— ì‚¬ìš©í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ `bigcode/octocoder`ì— ëŒ€í•´ í‚¤-ê°’ ìºì‹œì— ì €ì¥í•´ì•¼ í•˜ëŠ” ë¶€ë™ ì†Œìˆ˜ì  ê°’ì˜ ìˆ˜ë¥¼ ê³„ì‚°í•´ ë´…ì‹œë‹¤.\n",
    "ë¶€ë™ ì†Œìˆ˜ì  ê°’ì˜ ìˆ˜ëŠ” ì‹œí€€ìŠ¤ ê¸¸ì´ì˜ ë‘ ë°°ì˜ ì–´í…ì…˜ í—¤ë“œ ìˆ˜, ì–´í…ì…˜ í—¤ë“œ ì°¨ì›, ë ˆì´ì–´ ìˆ˜ë¥¼ ê³±í•œ ê°’ì…ë‹ˆë‹¤.\n",
    "ê°€ìƒì˜ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ 16000ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•´ ì´ë¥¼ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.config\n",
    "2 * 16_000 * config.n_layer * config.n_head * config.n_embd // config.n_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì¶œë ¥**:\n",
    "```\n",
    "7864320000\n",
    "```\n",
    "\n",
    "ëŒ€ëµ 80ì–µ ê°œì˜ ë¶€ë™ ì†Œìˆ˜ì  ê°’ì…ë‹ˆë‹¤! `float16` ì •ë°€ë„ë¡œ 80ì–µ ê°œì˜ ë¶€ë™ ì†Œìˆ˜ì  ê°’ì„ ì €ì¥í•˜ëŠ” ë°ëŠ” ì•½ 15GBì˜ RAMì´ í•„ìš”í•˜ë©°, ì´ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ ìì²´ì˜ ì ˆë°˜ ì •ë„ì…ë‹ˆë‹¤.\n",
    "ì—°êµ¬ìë“¤ì€ í‚¤-ê°’ ìºì‹œë¥¼ ì €ì¥í•˜ëŠ” ë° í•„ìš”í•œ ë©”ëª¨ë¦¬ ë¹„ìš©ì„ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë‘ ê°€ì§€ ë°©ë²•ì„ ì œì•ˆí–ˆìœ¼ë©°, ì´ëŠ” ë‹¤ìŒ ì ˆì—ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 ë©€í‹° ì¿¼ë¦¬ ì–´í…ì…˜ (MQA) [[322-multi-query-attention-mqa]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ë©€í‹° ì¿¼ë¦¬ ì–´í…ì…˜ (MQA)](https://huggingface.co/papers/1911.02150)ì€ Noam Shazeerì˜ *Fast Transformer Decoding: One Write-Head is All You Need* ë…¼ë¬¸ì—ì„œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ì œëª©ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, Noamì€ `n_head` í‚¤-ê°’ í”„ë¡œì ì…˜ ê°€ì¤‘ì¹˜ ëŒ€ì‹ , ëª¨ë“  ì–´í…ì…˜ í—¤ë“œì—ì„œ ê³µìœ ë˜ëŠ” ë‹¨ì¼ í—¤ë“œ-ê°’ í”„ë¡œì ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> ë‹¨ì¼ í—¤ë“œ-ê°’ í”„ë¡œì ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, í‚¤-ê°’ ë²¡í„° $ \\mathbf{k}_i, \\mathbf{v}_i $ëŠ” ëª¨ë“  ì–´í…ì…˜ í—¤ë“œì—ì„œ ë™ì¼í•´ì•¼ í•˜ë©°, ì´ëŠ” ìºì‹œì— `n_head` ê°œ ëŒ€ì‹  í•˜ë‚˜ì˜ í‚¤-ê°’ í”„ë¡œì ì…˜ ìŒë§Œ ì €ì¥í•˜ë©´ ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ëŒ€ë¶€ë¶„ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ 20ì—ì„œ 100 ì‚¬ì´ì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, MQAëŠ” í‚¤-ê°’ ìºì‹œì˜ ë©”ëª¨ë¦¬ ì†Œë¹„ë¥¼ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê²½ìš°, ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ 16000ì—ì„œ í•„ìš”í•œ ë©”ëª¨ë¦¬ ì†Œë¹„ë¥¼ 15GBì—ì„œ 400MB ë¯¸ë§Œìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë©”ëª¨ë¦¬ ì ˆê° ì™¸ì—ë„, MQAëŠ” ê³„ì‚° íš¨ìœ¨ì„±ë„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "ìê¸°íšŒê·€ ë””ì½”ë”©ì—ì„œëŠ” í° í‚¤-ê°’ ë²¡í„°ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ê³ , í˜„ì¬ í‚¤-ê°’ ë²¡í„° ìŒê³¼ ì—°ê²°í•œ í›„ $ \\mathbf{q}_c\\mathbf{K}^T $ ê³„ì‚°ì— ë§¤ ë‹¨ê³„ë§ˆë‹¤ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ìê¸°íšŒê·€ ë””ì½”ë”©ì˜ ê²½ìš°, ì§€ì†ì ì¸ ì¬ë¡œë“œì— í•„ìš”í•œ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì´ ì‹¬ê°í•œ ì‹œê°„ ë³‘ëª© í˜„ìƒì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‚¤-ê°’ ë²¡í„°ì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´ ì ‘ê·¼í•´ì•¼ í•˜ëŠ” ë©”ëª¨ë¦¬ ì–‘ì´ ì¤„ì–´ë“¤ì–´ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ë³‘ëª© í˜„ìƒì´ ê°ì†Œí•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [Noamì˜ ë…¼ë¬¸](https://huggingface.co/papers/1911.02150)ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "ì—¬ê¸°ì„œ ì´í•´í•´ì•¼ í•  ì¤‘ìš”í•œ ë¶€ë¶„ì€ í‚¤-ê°’ ì–´í…ì…˜ í—¤ë“œ ìˆ˜ë¥¼ 1ë¡œ ì¤„ì´ëŠ” ê²ƒì´ í‚¤-ê°’ ìºì‹œë¥¼ ì‚¬ìš©í•  ë•Œë§Œ ì˜ë¯¸ê°€ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. í‚¤-ê°’ ìºì‹œ ì—†ì´ ë‹¨ì¼ í¬ì›Œë“œ íŒ¨ìŠ¤ì— ëŒ€í•œ ëª¨ë¸ì˜ ìµœëŒ€ ë©”ëª¨ë¦¬ ì†Œë¹„ëŠ” ë³€ê²½ë˜ì§€ ì•Šìœ¼ë©°, ê° ì–´í…ì…˜ í—¤ë“œëŠ” ì—¬ì „íˆ ê³ ìœ í•œ ì¿¼ë¦¬ ë²¡í„°ë¥¼ ê°€ì§€ë¯€ë¡œ ê° ì–´í…ì…˜ í—¤ë“œëŠ” ì—¬ì „íˆ ë‹¤ë¥¸ $ \\mathbf{QK}^T $ í–‰ë ¬ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "MQAëŠ” ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë„ë¦¬ ì±„íƒë˜ì–´ í˜„ì¬ ê°€ì¥ ì¸ê¸° ìˆëŠ” ë§ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "-   [**Falcon**](https://huggingface.co/tiiuae/falcon-40b)\n",
    "-   [**PaLM**](https://huggingface.co/papers/2204.02311)\n",
    "-   [**MPT**](https://huggingface.co/mosaicml/mpt-30b)\n",
    "-   [**BLOOM**](https://huggingface.co/bigscience/bloom)\n",
    "\n",
    "ë˜í•œ, ì´ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©ëœ ì²´í¬í¬ì¸íŠ¸ `bigcode/octocoder`ëŠ” MQAë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 ê·¸ë£¹ ì¿¼ë¦¬ ì–´í…ì…˜ (GQA) [[323-grouped-query-attention-gqa]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ê·¸ë£¹ ì¿¼ë¦¬ ì–´í…ì…˜ (GQA)](https://huggingface.co/papers/2305.13245)ì€ Googleì˜ Ainslie ë“±ì˜ ì—°êµ¬ì§„ë“¤ì— ì˜í•´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ MQAë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢…ì¢… ì¼ë°˜ì ì¸ ë©€í‹° í‚¤-ê°’ í—¤ë“œ í”„ë¡œì ì…˜ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ í’ˆì§ˆ ì €í•˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ ì¿¼ë¦¬ í—¤ë“œ í”„ë¡œì ì…˜ ê°€ì¤‘ì¹˜ì˜ ìˆ˜ë¥¼ ë„ˆë¬´ ê·¹ë‹¨ì ìœ¼ë¡œ ì¤„ì´ëŠ” ëŒ€ì‹ , ë” ë§ì€ ëª¨ë¸ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ë‹¨ì¼ í‚¤-ê°’ í”„ë¡œì ì…˜ ê°€ì¤‘ì¹˜ ëŒ€ì‹ , `n < n_head` í‚¤-ê°’ í”„ë¡œì ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. `n_head`ë³´ë‹¤ í›¨ì”¬ ì‘ì€ `n`ê°’, ì˜ˆë¥¼ ë“¤ì–´ 2, 4 ë˜ëŠ” 8ì„ ì„ íƒí•˜ë©´, MQAì˜ ê±°ì˜ ëª¨ë“  ë©”ëª¨ë¦¬ ë° ì†ë„ ì´ì ì„ ìœ ì§€í•˜ë©´ì„œ ëª¨ë¸ ìš©ëŸ‰ì„ ëœ í¬ìƒí•˜ê³  ë”°ë¼ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ, GQAì˜ ì €ìë“¤ì€ ê¸°ì¡´ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì›ë˜ ì‚¬ì „ í•™ìŠµ ê³„ì‚°ì˜ 5% ì •ë„ì˜ ì ì€ ì–‘ìœ¼ë¡œ GQA ì•„í‚¤í…ì²˜ë¡œ *ì—…íŠ¸ë ˆì´ë‹*í•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì›ë˜ ì‚¬ì „ í•™ìŠµ ê³„ì‚°ì˜ 5%ê°€ ì—¬ì „íˆ ì—„ì²­ë‚œ ì–‘ì¼ ìˆ˜ ìˆì§€ë§Œ, GQA *ì—…íŠ¸ë ˆì´ë‹*ì€ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ê°€ ë” ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤ì—ì„œë„ ìœ ìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "GQAëŠ” ìµœê·¼ì— ì œì•ˆë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ ë…¸íŠ¸ë¶ì„ ì‘ì„±í•  ë‹¹ì‹œì—ëŠ” ì±„íƒì´ ëœ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "GQAì˜ ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ ì ìš© ì‚¬ë¡€ëŠ” [Llama-v2](https://huggingface.co/meta-llama/Llama-2-70b-hf)ì…ë‹ˆë‹¤.\n",
    "\n",
    "> ê²°ë¡ ì ìœ¼ë¡œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ìê¸°íšŒê·€ ë””ì½”ë”©ìœ¼ë¡œ ë°°í¬ë˜ë©´ì„œ ì±„íŒ…ê³¼ ê°™ì´ í° ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ê°€ì§„ ì‘ì—…ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ê²½ìš° GQA ë˜ëŠ” MQAë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°•ë ¥íˆ ê¶Œì¥ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²°ë¡  [[conclusion]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—°êµ¬ ì»¤ë®¤ë‹ˆí‹°ëŠ” ì ì  ë” í° ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ì‹œê°„ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ê¸°ë°œí•œ ë°©ë²•ë“¤ì„ ëŠì„ì—†ì´ ì°¾ì•„ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [ì¶”ì¸¡ ë””ì½”ë”©](https://huggingface.co/papers/2211.17192)ì´ë¼ëŠ” ìœ ë§í•œ ì—°êµ¬ ë°©í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ \"ì‰¬ìš´ í† í°\"ì€ ë” ì‘ê³  ë¹ ë¥¸ ì–¸ì–´ ëª¨ë¸ì— ì˜í•´ ìƒì„±ë˜ê³ , \"ì–´ë ¤ìš´ í† í°\"ë§Œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ìì²´ì— ì˜í•´ ìƒì„±ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì´ ë…¸íŠ¸ë¶ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ë§Œ, [ë©‹ì§„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸](https://huggingface.co/blog/assisted-generation)ì—ì„œ ì½ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "GPT3/4, Llama-2-70b, Claude, PaLMê³¼ ê°™ì€ ê±°ëŒ€í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ [Hugging Face Chat](https://huggingface.co/chat/) ë˜ëŠ” ChatGPTì™€ ê°™ì€ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì—ì„œ ë¹ ë¥´ê²Œ ì‹¤í–‰ë  ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” ìœ„ì—ì„œ ì–¸ê¸‰í•œ ì •ë°€ë„, ì•Œê³ ë¦¬ì¦˜, ì•„í‚¤í…ì²˜ì˜ ê°œì„  ë•ë¶„ì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ GPU, TPU ë“±ê³¼ ê°™ì€ ê°€ì†ê¸°ëŠ” ì ì  ë” ë¹¨ë¼ì§€ê³  ë” ë§ì€ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê°€ì¥ ì¢‹ì€ ì•Œê³ ë¦¬ì¦˜ê³¼ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœê³ ì˜ íš¨ìœ¨ì„ ì–»ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤ ğŸ¤—"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
