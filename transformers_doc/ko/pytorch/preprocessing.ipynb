{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì „ì²˜ë¦¬[[preprocess]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì„ í›ˆë ¨í•˜ë ¤ë©´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ëª¨ë¸ì— ë§ëŠ” ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë˜ëŠ” ì˜¤ë””ì˜¤ì¸ì§€ ê´€ê³„ì—†ì´ ë°ì´í„°ë¥¼ í…ì„œ ë°°ì¹˜ë¡œ ë³€í™˜í•˜ê³  ì¡°ë¦½í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ğŸ¤— TransformersëŠ” ëª¨ë¸ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì¼ë ¨ì˜ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‹¤ìŒ ë‚´ìš©ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "* í…ìŠ¤íŠ¸ëŠ” [Tokenizer](https://huggingface.co/docs/transformers/main/ko/./main_classes/tokenizer)ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í° ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ê³  í† í°ì˜ ìˆ«ì í‘œí˜„ì„ ë§Œë“  í›„ í…ì„œë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤.\n",
    "* ìŒì„± ë° ì˜¤ë””ì˜¤ëŠ” [Feature extractor](https://huggingface.co/docs/transformers/main/ko/./main_classes/feature_extractor)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒí˜•ì—ì„œ ì‹œí€€ìŠ¤ íŠ¹ì„±ì„ íŒŒì•…í•˜ì—¬ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "* ì´ë¯¸ì§€ ì…ë ¥ì€ [ImageProcessor](https://huggingface.co/docs/transformers/main/ko/./main_classes/image)ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "* ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì€ [Processor](https://huggingface.co/docs/transformers/main/ko/./main_classes/processors)ì„ ì‚¬ìš©í•˜ì—¬ í† í¬ë‚˜ì´ì €ì™€ íŠ¹ì„± ì¶”ì¶œê¸° ë˜ëŠ” ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œë¥¼ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "`AutoProcessor`ëŠ” **ì–¸ì œë‚˜** ì‘ë™í•˜ì—¬ í† í¬ë‚˜ì´ì €, ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ, íŠ¹ì„± ì¶”ì¶œê¸° ë˜ëŠ” í”„ë¡œì„¸ì„œ ë“± ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ì— ë§ëŠ” í´ë˜ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— ğŸ¤— Datasetsë¥¼ ì„¤ì¹˜í•˜ì—¬ ì‹¤í—˜ì— ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "```bash\n",
    "pip install datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìì—°ì–´ì²˜ë¦¬[[natural-language-processing]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Yffk5aydLzg?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Yffk5aydLzg?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ê¸°ë³¸ ë„êµ¬ëŠ” [tokenizer](https://huggingface.co/docs/transformers/main/ko/main_classes/tokenizer)ì…ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ëŠ” ì¼ë ¨ì˜ ê·œì¹™ì— ë”°ë¼ í…ìŠ¤íŠ¸ë¥¼ *í† í°*ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤. í† í°ì€ ìˆ«ìë¡œ ë³€í™˜ë˜ê³  í…ì„œëŠ” ëª¨ë¸ ì…ë ¥ì´ ë©ë‹ˆë‹¤. ëª¨ë¸ì— í•„ìš”í•œ ì¶”ê°€ ì…ë ¥ì€ í† í¬ë‚˜ì´ì €ì— ì˜í•´ ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ì‚¬ì „í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•  ê³„íšì´ë¼ë©´ ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ì „í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í…ìŠ¤íŠ¸ê°€ ì‚¬ì „í›ˆë ¨ ë§ë­‰ì¹˜ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë¶„í• ë˜ê³  ì‚¬ì „í›ˆë ¨ ì¤‘ì— ë™ì¼í•œ í•´ë‹¹ í† í°-ì¸ë±ìŠ¤ ìŒ(ì¼ë°˜ì ìœ¼ë¡œ *vocab*ì´ë¼ê³  í•¨)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì‹œì‘í•˜ë ¤ë©´ `AutoTokenizer.from_pretrained()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”. ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ì „í›ˆë ¨ëœ *vocab*ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ ë‹¤ìŒìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì €ì— ë„£ì–´ì£¼ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102], \n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í† í¬ë‚˜ì´ì €ëŠ” ì„¸ ê°€ì§€ ì¤‘ìš”í•œ í•­ëª©ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:\n",
    "\n",
    "* [input_ids](https://huggingface.co/docs/transformers/main/ko/glossary#input-ids)ëŠ” ë¬¸ì¥ì˜ ê° í† í°ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ì…ë‹ˆë‹¤.\n",
    "* [attention_mask](https://huggingface.co/docs/transformers/main/ko/glossary#attention-mask)ëŠ” í† í°ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "* [token_type_ids](https://huggingface.co/docs/transformers/main/ko/glossary#token-type-ids)ëŠ” ë‘ ê°œ ì´ìƒì˜ ì‹œí€€ìŠ¤ê°€ ìˆì„ ë•Œ í† í°ì´ ì†í•œ ì‹œí€€ìŠ¤ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.\n",
    "\n",
    "`input_ids`ë¥¼ ë””ì½”ë”©í•˜ì—¬ ì…ë ¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í† í¬ë‚˜ì´ì €ê°€ ë‘ ê°œì˜ íŠ¹ìˆ˜í•œ í† í°(ë¶„ë¥˜ í† í° `CLS`ì™€ ë¶„í•  í† í° `SEP`)ì„ ë¬¸ì¥ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\n",
    "ëª¨ë“  ëª¨ë¸ì— íŠ¹ìˆ˜í•œ í† í°ì´ í•„ìš”í•œ ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, í•„ìš”í•˜ë‹¤ë©´ í† í¬ë‚˜ì´ì €ê°€ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì „ì²˜ë¦¬í•  ë¬¸ì¥ì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” ê²½ìš°ì—ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ í† í¬ë‚˜ì´ì €ì— ì „ë‹¬í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102], \n",
       "               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], \n",
       "               [101, 1327, 1164, 5450, 23434, 136, 102]], \n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [0, 0, 0, 0, 0, 0, 0]], \n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], \n",
       "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
       "                    [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒ¨ë”©[[pad]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì…ë ¥ì¸ í…ì„œëŠ” ëª¨ì–‘ì´ ê· ì¼í•´ì•¼ í•˜ì§€ë§Œ, ë¬¸ì¥ì˜ ê¸¸ì´ê°€ í•­ìƒ ê°™ì§€ëŠ” ì•Šê¸° ë•Œë¬¸ì— ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒ¨ë”©ì€ ì§§ì€ ë¬¸ì¥ì— íŠ¹ìˆ˜í•œ *íŒ¨ë”© í† í°*ì„ ì¶”ê°€í•˜ì—¬ í…ì„œë¥¼ ì§ì‚¬ê°í˜• ëª¨ì–‘ì´ ë˜ë„ë¡ í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.\n",
    "\n",
    "`padding` ë§¤ê°œë³€ìˆ˜ë¥¼ `True`ë¡œ ì„¤ì •í•˜ì—¬ ë°°ì¹˜ ë‚´ì˜ ì§§ì€ ì‹œí€€ìŠ¤ë¥¼ ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ì— ë§ì¶° íŒ¨ë”©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0], \n",
       "               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], \n",
       "               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]], \n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
       "                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸¸ì´ê°€ ì§§ì€ ì²« ë¬¸ì¥ê³¼ ì„¸ ë²ˆì§¸ ë¬¸ì¥ì´ ì´ì œ `0`ìœ¼ë¡œ ì±„ì›Œì¡ŒìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜ë¼ë‚´ê¸°[[truncation]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•œí¸, ë•Œë¡œëŠ” ì‹œí€€ìŠ¤ê°€ ëª¨ë¸ì—ì„œ ì²˜ë¦¬í•˜ê¸°ì— ë„ˆë¬´ ê¸¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ì‹œí€€ìŠ¤ë¥¼ ë” ì§§ê²Œ ì¤„ì¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì—ì„œ í—ˆìš©í•˜ëŠ” ìµœëŒ€ ê¸¸ì´ë¡œ ì‹œí€€ìŠ¤ë¥¼ ìë¥´ë ¤ë©´ `truncation` ë§¤ê°œë³€ìˆ˜ë¥¼ `True`ë¡œ ì„¤ì •í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0], \n",
       "               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], \n",
       "               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]], \n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], \n",
       "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
       "                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ë‹¤ì–‘í•œ íŒ¨ë”©ê³¼ ì˜ë¼ë‚´ê¸° ì¸ìˆ˜ì— ëŒ€í•´ ë” ì•Œì•„ë³´ë ¤ë©´ [íŒ¨ë”©ê³¼ ì˜ë¼ë‚´ê¸°](https://huggingface.co/docs/transformers/main/ko/./pad_truncation) ê°œë… ê°€ì´ë“œë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ì„œ ë§Œë“¤ê¸°[[build-tensors]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, í† í¬ë‚˜ì´ì €ê°€ ëª¨ë¸ì— ê³µê¸‰ë˜ëŠ” ì‹¤ì œ í…ì„œë¥¼ ë°˜í™˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "`return_tensors` ë§¤ê°œë³€ìˆ˜ë¥¼ PyTorchì˜ ê²½ìš° `pt`, TensorFlowì˜ ê²½ìš° `tf`ë¡œ ì„¤ì •í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n",
       "                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n",
       "                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]), \n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), \n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì˜¤ë””ì˜¤[[audio]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ë””ì˜¤ ì‘ì—…ì€ ëª¨ë¸ì— ë§ëŠ” ë°ì´í„° ì„¸íŠ¸ë¥¼ ì¤€ë¹„í•˜ê¸° ìœ„í•´ [íŠ¹ì„± ì¶”ì¶œê¸°](https://huggingface.co/docs/transformers/main/ko/main_classes/feature_extractor)ê°€ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì„± ì¶”ì¶œê¸°ëŠ” ì›ì‹œ ì˜¤ë””ì˜¤ ë°ì´í„°ì—ì„œ íŠ¹ì„±ë¥¼ ì¶”ì¶œí•˜ê³  ì´ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì˜¤ë””ì˜¤ ë°ì´í„° ì„¸íŠ¸ì— íŠ¹ì„± ì¶”ì¶œê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ê¸° ìœ„í•´ [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”. (ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì€ ğŸ¤— [ë°ì´í„° ì„¸íŠ¸ íŠœí† ë¦¬ì–¼](https://huggingface.co/docs/datasets/load_hub.html)ì—ì„œ ìì„¸íˆ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`audio` ì—´ì˜ ì²« ë²ˆì§¸ ìš”ì†Œì— ì ‘ê·¼í•˜ì—¬ ì…ë ¥ì„ ì‚´í´ë³´ì„¸ìš”. `audio` ì—´ì„ í˜¸ì¶œí•˜ë©´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê³  ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,\n",
       "         0.        ,  0.        ], dtype=float32),\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n",
       " 'sampling_rate': 8000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë ‡ê²Œ í•˜ë©´ ì„¸ ê°€ì§€ í•­ëª©ì´ ë°˜í™˜ë©ë‹ˆë‹¤:\n",
    "\n",
    "* `array`ëŠ” 1D ë°°ì—´ë¡œ ê°€ì ¸ì™€ì„œ (í•„ìš”í•œ ê²½ìš°) ë¦¬ìƒ˜í”Œë§ëœ ìŒì„± ì‹ í˜¸ì…ë‹ˆë‹¤.\n",
    "* `path`ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê°€ë¦¬í‚µë‹ˆë‹¤.\n",
    "* `sampling_rate`ëŠ” ìŒì„± ì‹ í˜¸ì—ì„œ ì´ˆë‹¹ ì¸¡ì •ë˜ëŠ” ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì¹´ë“œë¥¼ ë³´ë©´ Wav2Vec2ê°€ 16kHz ìƒ˜í”Œë§ëœ ìŒì„± ì˜¤ë””ì˜¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „í›ˆë ¨ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ëª¨ë¸ì„ ì‚¬ì „í›ˆë ¨í•˜ëŠ” ë° ì‚¬ìš©ëœ ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ì™€ ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ê°€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ë°ì´í„°ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ê°€ ë‹¤ë¥´ë©´ ë°ì´í„°ë¥¼ ë¦¬ìƒ˜í”Œë§í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "1. ğŸ¤— Datasetsì˜ `cast_column` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ 16kHzë¡œ ì—…ìƒ˜í”Œë§í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¦¬ìƒ˜í”Œë§í•˜ê¸° ìœ„í•´ `audio` ì—´ì„ ë‹¤ì‹œ í˜¸ì¶œí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,\n",
       "         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ, ì…ë ¥ì„ ì •ê·œí™”í•˜ê³  íŒ¨ë”©í•  íŠ¹ì„± ì¶”ì¶œê¸°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”. í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ê²½ìš°, ë” ì§§ì€ ì‹œí€€ìŠ¤ì— ëŒ€í•´ `0`ì´ ì¶”ê°€ë©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ë°ì´í„°ì—ë„ ê°™ì€ ê°œë…ì´ ì ìš©ë©ë‹ˆë‹¤. \n",
    "íŠ¹ì„± ì¶”ì¶œê¸°ëŠ” ë°°ì—´ì— `0`(ë¬µìŒìœ¼ë¡œ í•´ì„)ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "`AutoFeatureExtractor.from_pretrained()`ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì„± ì¶”ì¶œê¸°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ë””ì˜¤ `array`ë¥¼ íŠ¹ì„± ì¶”ì¶œê¸°ì— ì „ë‹¬í•˜ì„¸ìš”. ë˜í•œ, ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¡°ìš©í•œ ì˜¤ë¥˜(silent errors)ë¥¼ ë” ì˜ ë””ë²„ê¹…í•  ìˆ˜ ìˆë„ë¡ íŠ¹ì„± ì¶”ì¶œê¸°ì— `sampling_rate` ì¸ìˆ˜ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,\n",
       "        5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_input = [dataset[0][\"audio\"][\"array\"]]\n",
    "feature_extractor(audio_input, sampling_rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í† í¬ë‚˜ì´ì €ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë°°ì¹˜ ë‚´ì—ì„œ ê°€ë³€ì ì¸ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ íŒ¨ë”© ë˜ëŠ” ì˜ë¼ë‚´ê¸°ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë‘ ê°œì˜ ì˜¤ë””ì˜¤ ìƒ˜í”Œì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173398,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106496,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ë””ì˜¤ ìƒ˜í”Œì˜ ê¸¸ì´ê°€ ë™ì¼í•˜ë„ë¡ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”. ìµœëŒ€ ìƒ˜í”Œ ê¸¸ì´ë¥¼ ì§€ì •í•˜ë©´ íŠ¹ì„± ì¶”ì¶œê¸°ê°€ í•´ë‹¹ ê¸¸ì´ì— ë§ì¶° ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”©í•˜ê±°ë‚˜ ì˜ë¼ëƒ…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        max_length=100000,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`preprocess_function`ì„ ë°ì´í„° ì„¸íŠ¸ì˜ ì²˜ìŒ ì˜ˆì‹œ ëª‡ ê°œì— ì ìš©í•´ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = preprocess_function(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ìƒ˜í”Œ ê¸¸ì´ê°€ ëª¨ë‘ ê°™ê³  ì§€ì •ëœ ìµœëŒ€ ê¸¸ì´ì— ë§ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë“œë””ì–´ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì„¸íŠ¸ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[\"input_values\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[\"input_values\"][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì»´í“¨í„° ë¹„ì „[[computer-vision]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì»´í“¨í„° ë¹„ì „ ì‘ì—…ì˜ ê²½ìš°, ëª¨ë¸ì— ëŒ€í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì¤€ë¹„í•˜ê¸° ìœ„í•´ [ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ](https://huggingface.co/docs/transformers/main/ko/main_classes/image_processor)ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ëŠ” ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” ì…ë ¥ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. \n",
    "ì´ëŸ¬í•œ ë‹¨ê³„ì—ëŠ” í¬ê¸° ì¡°ì •, ì •ê·œí™”, ìƒ‰ìƒ ì±„ë„ ë³´ì •, ì´ë¯¸ì§€ì˜ í…ì„œ ë³€í™˜ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ëŠ” ì´ë¯¸ì§€ ì¦ê°• ê¸°ë²•ì„ ëª‡ ê°€ì§€ ì ìš©í•œ ë’¤ì— í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ì¦ê°•ì€ ëª¨ë‘ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë³€í˜•í•˜ì§€ë§Œ, ì„œë¡œ ë‹¤ë¥¸ ëª©ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "* ì´ë¯¸ì§€ ì¦ê°•ì€ ê³¼ì í•©(over-fitting)ì„ ë°©ì§€í•˜ê³  ëª¨ë¸ì˜ ê²¬ê³ í•¨(resiliency)ì„ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. \n",
    "ë°ê¸°ì™€ ìƒ‰ìƒ ì¡°ì •, ìë¥´ê¸°, íšŒì „, í¬ê¸° ì¡°ì •, í™•ëŒ€/ì¶•ì†Œ ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¦ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ê·¸ëŸ¬ë‚˜ ì¦ê°•ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ì˜ë¯¸ê°€ ë°”ë€Œì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "* ì´ë¯¸ì§€ ì „ì²˜ë¦¬ëŠ” ì´ë¯¸ì§€ê°€ ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” ì…ë ¥ í˜•ì‹ê³¼ ì¼ì¹˜í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤. \n",
    "ì»´í“¨í„° ë¹„ì „ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ë•Œ ì´ë¯¸ì§€ëŠ” ëª¨ë¸ì´ ì´ˆê¸°ì— í›ˆë ¨ë  ë•Œì™€ ì •í™•íˆ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¯¸ì§€ ì¦ê°•ì—ëŠ” ì›í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¬´ì—‡ì´ë“  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì—ëŠ” ëª¨ë¸ê³¼ ì—°ê²°ëœ `ImageProcessor`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "[food101](https://huggingface.co/datasets/food101) ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ì»´í“¨í„° ë¹„ì „ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œì•„ë³´ì„¸ìš”. \n",
    "ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì€ ğŸ¤— [ë°ì´í„° ì„¸íŠ¸ íŠœí† ë¦¬ì–¼](https://huggingface.co/docs/datasets/load_hub.html)ì„ ì°¸ê³ í•˜ì„¸ìš”.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ë°ì´í„° ì„¸íŠ¸ê°€ ìƒë‹¹íˆ í¬ê¸° ë•Œë¬¸ì— ğŸ¤— Datasetsì˜ `split` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì‘ì€ ìƒ˜í”Œë§Œ ê°€ì ¸ì˜¤ì„¸ìš”!\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"food101\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ, ğŸ¤— Datasetsì˜ [`image`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=image#datasets.Image)ë¡œ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png\"/>\n",
    "</div>\n",
    "\n",
    "`AutoImageProcessor.from_pretrained()`ë¡œ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì € ì´ë¯¸ì§€ ì¦ê°• ë‹¨ê³„ë¥¼ ì¶”ê°€í•´ ë´…ì‹œë‹¤. ì•„ë¬´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë‚˜ ì‚¬ìš©í•´ë„ ê´œì°®ì§€ë§Œ, ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” torchvisionì˜ [`transforms`](https://pytorch.org/vision/stable/transforms.html) ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "ë‹¤ë¥¸ ë°ì´í„° ì¦ê°• ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ë³´ê³  ì‹¶ë‹¤ë©´, [Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb) ë˜ëŠ” [Kornia notebooks](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)ì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. [`Compose`](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)ë¡œ  [`RandomResizedCrop`](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html)ì™€ [`ColorJitter`](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html) ë“± ë³€í™˜ì„ ëª‡ ê°€ì§€ ì—°ê²°í•˜ì„¸ìš”.\n",
    "ì°¸ê³ ë¡œ í¬ê¸° ì¡°ì •ì— í•„ìš”í•œ ì´ë¯¸ì§€ì˜ í¬ê¸° ìš”êµ¬ì‚¬í•­ì€ `image_processor`ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ì¼ë¶€ ëª¨ë¸ì€ ì •í™•í•œ ë†’ì´ì™€ ë„ˆë¹„ë¥¼ ìš”êµ¬í•˜ì§€ë§Œ, ì œì¼ ì§§ì€ ë³€ì˜ ê¸¸ì´(`shortest_edge`)ë§Œ ì •ì˜ëœ ëª¨ë¸ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose\n",
    "\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ëª¨ë¸ì€ ì…ë ¥ìœ¼ë¡œ [`pixel_values`](https://huggingface.co/docs/transformers/main/ko/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderModel.forward.pixel_values)ë¥¼ ë°›ìŠµë‹ˆë‹¤. \n",
    "`ImageProcessor`ëŠ” ì´ë¯¸ì§€ ì •ê·œí™” ë° ì ì ˆí•œ í…ì„œ ìƒì„±ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ë°°ì¹˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì´ë¯¸ì§€ ì¦ê°• ë° ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ê²°í•©í•˜ê³  `pixel_values`ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    images = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    examples[\"pixel_values\"] = image_processor(images, do_resize=False, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ìœ„ì˜ ì˜ˆì—ì„œëŠ” ì´ë¯¸ì§€ ì¦ê°• ì¤‘ì— ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì •í–ˆê¸° ë•Œë¬¸ì— `do_resize=False`ë¡œ ì„¤ì •í•˜ê³ , í•´ë‹¹ `image_processor`ì—ì„œ `size` ì†ì„±ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤. \n",
    "ì´ë¯¸ì§€ ì¦ê°• ì¤‘ì— ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì§€ ì•Šì€ ê²½ìš° ì´ ë§¤ê°œë³€ìˆ˜ë¥¼ ìƒëµí•˜ì„¸ìš”. \n",
    "ê¸°ë³¸ì ìœ¼ë¡œëŠ” `ImageProcessor`ê°€ í¬ê¸° ì¡°ì •ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. \n",
    "\n",
    "ì¦ê°• ë³€í™˜ ê³¼ì •ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì •ê·œí™”í•˜ë ¤ë©´ `image_processor.image_mean` ë° `image_processor.image_std` ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "3. ğŸ¤— Datasetsì˜ [`set_transform`](https://huggingface.co/docs/datasets/process.html#format-transform)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€í™˜ì„ ì ìš©í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ì´ì œ ì´ë¯¸ì§€ì— ì ‘ê·¼í•˜ë©´ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œê°€ `pixel_values`ë¥¼ ì¶”ê°€í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ë“œë””ì–´ ì²˜ë¦¬ëœ ë°ì´í„° ì„¸íŠ¸ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ ë³€í˜•ì´ ì ìš©ëœ í›„ì˜ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ê°€ ë¬´ì‘ìœ„ë¡œ ì˜ë ¤ë‚˜ê°”ê³  ìƒ‰ìƒ ì†ì„±ì´ ë‹¤ë¦…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = dataset[0][\"pixel_values\"]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png\"/>\n",
    "</div>\n",
    "\n",
    "<Tip>\n",
    "\n",
    "`ImageProcessor`ëŠ” ê°ì²´ ê°ì§€, ì‹œë§¨í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜(semantic segmentation), ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜(instance segmentation), íŒŒë†‰í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜(panoptic segmentation)ê³¼ ê°™ì€ ì‘ì—…ì— ëŒ€í•œ í›„ì²˜ë¦¬ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
    "ì´ëŸ¬í•œ ë°©ë²•ì€ ëª¨ë¸ì˜ ì›ì‹œ ì¶œë ¥ì„ ê²½ê³„ ìƒìë‚˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§µê³¼ ê°™ì€ ì˜ë¯¸ ìˆëŠ” ì˜ˆì¸¡ìœ¼ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒ¨ë”©[[pad]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆë¥¼ ë“¤ì–´, [DETR](https://huggingface.co/docs/transformers/main/ko/./model_doc/detr)ì™€ ê°™ì€ ê²½ìš°ì—ëŠ” ëª¨ë¸ì´ í›ˆë ¨í•  ë•Œ í¬ê¸° ì¡°ì • ì¦ê°•ì„ ì ìš©í•©ë‹ˆë‹¤. \n",
    "ì´ë¡œ ì¸í•´ ë°°ì¹˜ ë‚´ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "`DetrImageProcessor`ì˜ `DetrImageProcessor.pad_and_create_pixel_mask()`ë¥¼ ì‚¬ìš©í•˜ê³  ì‚¬ìš©ì ì •ì˜ `collate_fn`ì„ ì •ì˜í•´ì„œ ë°°ì¹˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "    encoding = image_processor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    batch = {}\n",
    "    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "    batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë©€í‹°ëª¨ë‹¬[[multimodal]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì´ í•„ìš”í•œ ì‘ì—…ì˜ ê²½ìš°, ëª¨ë¸ì— ë°ì´í„° ì„¸íŠ¸ë¥¼ ì¤€ë¹„í•˜ê¸° ìœ„í•œ [í”„ë¡œì„¸ì„œ](https://huggingface.co/docs/transformers/main/ko/main_classes/processors)ê°€ í•„ìš”í•©ë‹ˆë‹¤. \n",
    "í”„ë¡œì„¸ì„œëŠ” í† í¬ë‚˜ì´ì €ì™€ íŠ¹ì„± ì¶”ì¶œê¸°ì™€ ê°™ì€ ë‘ ê°€ì§€ ì²˜ë¦¬ ê°ì²´ë¥¼ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "[LJ Speech](https://huggingface.co/datasets/lj_speech) ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ìë™ ìŒì„± ì¸ì‹(ASR)ì„ ìœ„í•œ í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ í™•ì¸í•˜ì„¸ìš”. \n",
    "(ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ğŸ¤— [ë°ì´í„° ì„¸íŠ¸ íŠœí† ë¦¬ì–¼](https://huggingface.co/docs/datasets/load_hub.html)ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "lj_speech = load_dataset(\"lj_speech\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìë™ ìŒì„± ì¸ì‹(ASR)ì—ì„œëŠ” `audio`ì™€ `text`ì—ë§Œ ì§‘ì¤‘í•˜ë©´ ë˜ë¯€ë¡œ, ë‹¤ë¥¸ ì—´ë“¤ì€ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `audio`ì™€ `text`ì—´ì„ ì‚´í´ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,\n",
       "         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',\n",
       " 'sampling_rate': 22050}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_speech[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_speech[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ì¡´ì— ì‚¬ì „í›ˆë ¨ëœ ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„° ì„¸íŠ¸ì™€ ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´ ì˜¤ë””ì˜¤ ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ [ë¦¬ìƒ˜í”Œë§](https://huggingface.co/docs/transformers/main/ko/preprocessing#audio)í•´ì•¼ í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AutoProcessor.from_pretrained()`ë¡œ í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `array`ì— ë“¤ì–´ ìˆëŠ” ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ `input_values`ë¡œ ë³€í™˜í•˜ê³  `text`ë¥¼ í† í°í™”í•˜ì—¬ `labels`ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤. \n",
    "ëª¨ë¸ì˜ ì…ë ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example.update(processor(audio=audio[\"array\"], text=example[\"text\"], sampling_rate=16000))\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ìƒ˜í”Œì„ `prepare_dataset` í•¨ìˆ˜ì— ì ìš©í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset(lj_speech[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ í”„ë¡œì„¸ì„œê°€ `input_values`ì™€ `labels`ë¥¼ ì¶”ê°€í•˜ê³ , ìƒ˜í”Œë§ ë ˆì´íŠ¸ë„ ì˜¬ë°”ë¥´ê²Œ 16kHzë¡œ ë‹¤ìš´ìƒ˜í”Œë§í–ˆìŠµë‹ˆë‹¤. \n",
    "ë“œë””ì–´ ì²˜ë¦¬ëœ ë°ì´í„° ì„¸íŠ¸ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
