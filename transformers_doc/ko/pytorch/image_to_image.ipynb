{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets evaluate accelerate\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-Image ì‘ì—… ê°€ì´ë“œ [[image-to-image-task-guide]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image-to-Image ì‘ì—…ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ë˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì´ë¯¸ì§€ í–¥ìƒ(ì´ˆê³ í•´ìƒë„, ì €ì¡°ë„ í–¥ìƒ, ë¹—ì¤„ê¸° ì œê±° ë“±), ì´ë¯¸ì§€ ë³µì› ë“± ë‹¤ì–‘í•œ í•˜ìœ„ ì‘ì—…ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "- ì´ˆê³ í•´ìƒë„ ì‘ì—…ì„ ìœ„í•œ image-to-image íŒŒì´í”„ë¼ì¸ ì‚¬ìš©,\n",
    "- íŒŒì´í”„ë¼ì¸ ì—†ì´ ë™ì¼í•œ ì‘ì—…ì„ ìœ„í•œ image-to-image ëª¨ë¸ ì‹¤í–‰\n",
    "\n",
    "ì´ ê°€ì´ë“œê°€ ë°œí‘œëœ ì‹œì ì—ì„œëŠ”, `image-to-image` íŒŒì´í”„ë¼ì¸ì€ ì´ˆê³ í•´ìƒë„ ì‘ì—…ë§Œ ì§€ì›í•œë‹¤ëŠ” ì ì„ ìœ ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "```bash\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "ì´ì œ [Swin2SR ëª¨ë¸](https://huggingface.co/caidas/swin2SR-lightweight-x2-64)ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ë¯¸ì§€ì™€ í•¨ê»˜ í˜¸ì¶œí•˜ì—¬ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì´ íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” [Swin2SR ëª¨ë¸](https://huggingface.co/caidas/swin2SR-lightweight-x2-64)ë§Œ ì§€ì›ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pipe = pipeline(task=\"image-to-image\", model=\"caidas/swin2SR-lightweight-x2-64\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì™€ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# (532, 432)\n",
    "```\n",
    "<div class=\"flex justify-center\">\n",
    "     <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg\" alt=\"Photo of a cat\"/>\n",
    "</div>\n",
    "\n",
    "ì´ì œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê³ ì–‘ì´ ì´ë¯¸ì§€ì˜ ì—…ìŠ¤ì¼€ì¼ëœ ë²„ì „ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled = pipe(image)\n",
    "print(upscaled.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# (1072, 880)\n",
    "```\n",
    "\n",
    "íŒŒì´í”„ë¼ì¸ ì—†ì´ ì§ì ‘ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ë ¤ë©´ Transformersì˜ `Swin2SRForImageSuperResolution` ë° `Swin2SRImageProcessor` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë™ì¼í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ì´ˆê¸°í™”í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor \n",
    "\n",
    "model = Swin2SRForImageSuperResolution.from_pretrained(\"caidas/swin2SR-lightweight-x2-64\").to(device)\n",
    "processor = Swin2SRImageProcessor(\"caidas/swin2SR-lightweight-x2-64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline` ìš°ë¦¬ê°€ ì§ì ‘ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” ì „ì²˜ë¦¬ì™€ í›„ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì¶”ìƒí™”í•˜ë¯€ë¡œ, ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ í”„ë¡œì„¸ì„œì— ì „ë‹¬í•œ ë‹¤ìŒ í”½ì…€ê°’ì„ GPUë¡œ ì´ë™ì‹œí‚¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "print(pixel_values.shape)\n",
    "\n",
    "pixel_values = pixel_values.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ í”½ì…€ê°’ì„ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶œë ¥ì€ ì•„ë˜ì™€ ê°™ì€ `ImageSuperResolutionOutput` ìœ í˜•ì˜ ê°ì²´ì…ë‹ˆë‹¤ ğŸ‘‡ \n",
    "\n",
    "```\n",
    "(loss=None, reconstruction=tensor([[[[0.8270, 0.8269, 0.8275,  ..., 0.7463, 0.7446, 0.7453],\n",
    "          [0.8287, 0.8278, 0.8283,  ..., 0.7451, 0.7448, 0.7457],\n",
    "          [0.8280, 0.8273, 0.8269,  ..., 0.7447, 0.7446, 0.7452],\n",
    "          ...,\n",
    "          [0.5923, 0.5933, 0.5924,  ..., 0.0697, 0.0695, 0.0706],\n",
    "          [0.5926, 0.5932, 0.5926,  ..., 0.0673, 0.0687, 0.0705],\n",
    "          [0.5927, 0.5914, 0.5922,  ..., 0.0664, 0.0694, 0.0718]]]],\n",
    "       device='cuda:0'), hidden_states=None, attentions=None)\n",
    "```\n",
    "`reconstruction`ë¥¼ ê°€ì ¸ì™€ ì‹œê°í™”ë¥¼ ìœ„í•´ í›„ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ì‚´í´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.reconstruction.data.shape\n",
    "# torch.Size([1, 3, 880, 1072])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶œë ¥ í…ì„œì˜ ì°¨ì›ì„ ì¶•ì†Œí•˜ê³  0ë²ˆì§¸ ì¶•ì„ ì œê±°í•œ ë‹¤ìŒ, ê°’ì„ í´ë¦¬í•‘í•˜ê³  NumPy ë¶€ë™ì†Œìˆ˜ì  ë°°ì—´ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ [1072, 880] ëª¨ì–‘ì„ ê°–ë„ë¡ ì¶•ì„ ì¬ì •ë ¬í•˜ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶œë ¥ì„ 0ê³¼ 255 ì‚¬ì´ì˜ ê°’ì„ ê°–ë„ë¡ ë˜ëŒë¦½ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# í¬ê¸°ë¥¼ ì¤„ì´ê³ , CPUë¡œ ì´ë™í•˜ê³ , ê°’ì„ í´ë¦¬í•‘\n",
    "output = outputs.reconstruction.data.squeeze().cpu().clamp_(0, 1).numpy()\n",
    "# ì¶•ì„ ì¬ì •ë ¬\n",
    "output = np.moveaxis(output, source=0, destination=-1)\n",
    "# ê°’ì„ í”½ì…€ê°’ ë²”ìœ„ë¡œ ë˜ëŒë¦¬ê¸°\n",
    "output = (output * 255.0).round().astype(np.uint8)\n",
    "Image.fromarray(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "     <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat_upscaled.png\" alt=\"Upscaled photo of a cat\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
