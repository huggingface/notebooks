{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë²ˆì—­[[translation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/1JvfrvZgi6c?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/1JvfrvZgi6c?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë²ˆì—­ì€ í•œ ì–¸ì–´ë¡œ ëœ ì‹œí€€ìŠ¤ë¥¼ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë²ˆì—­ì´ë‚˜ ìš”ì•½ì€ ì…ë ¥ì„ ë°›ì•„ ì¼ë ¨ì˜ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì¸ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤ ë¬¸ì œë¡œ êµ¬ì„±í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. ë²ˆì—­ ì‹œìŠ¤í…œì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ëœ í…ìŠ¤íŠ¸ ê°„ì˜ ë²ˆì—­ì— ì‚¬ìš©ë˜ì§€ë§Œ, ìŒì„± ê°„ì˜ í†µì—­ì´ë‚˜ í…ìŠ¤íŠ¸-ìŒì„± ë˜ëŠ” ìŒì„±-í…ìŠ¤íŠ¸ì™€ ê°™ì€ ì¡°í•©ì—ë„ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œ í•™ìŠµí•  ë‚´ìš©ì€:\n",
    "\n",
    "1. ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ê¸° ìœ„í•´ [T5](https://huggingface.co/t5-small) ëª¨ë¸ì„ OPUS Books ë°ì´í„°ì„¸íŠ¸ì˜ ì˜ì–´-í”„ë‘ìŠ¤ì–´ í•˜ìœ„ ì§‘í•©ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ê³¼\n",
    "2. íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì¶”ë¡ ì— ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "<Tip>\n",
    "ì´ íƒœìŠ¤í¬ ê°€ì´ë“œëŠ” ì•„ë˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ì—ë„ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n",
    "\n",
    "[BART](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/bart), [BigBird-Pegasus](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/bigbird_pegasus), [Blenderbot](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/blenderbot), [BlenderbotSmall](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/blenderbot-small), [Encoder decoder](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/encoder-decoder), [FairSeq Machine-Translation](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/fsmt), [GPTSAN-japanese](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/gptsan-japanese), [LED](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/led), [LongT5](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/longt5), [M2M100](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/m2m_100), [Marian](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/marian), [mBART](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mbart), [MT5](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mt5), [MVP](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mvp), [NLLB](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/nllb), [NLLB-MOE](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/nllb-moe), [Pegasus](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/pegasus), [PEGASUS-X](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/pegasus_x), [PLBart](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/plbart), [ProphetNet](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/prophetnet), [SwitchTransformers](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/switch_transformers), [T5](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/t5), [XLM-ProphetNet](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/xlm-prophetnet)\n",
    "\n",
    "<!--End of the generated tip-->\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:\n",
    "\n",
    "```bash\n",
    "pip install transformers datasets evaluate sacrebleu\n",
    "```\n",
    "\n",
    "ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•  ìˆ˜ ìˆë„ë¡ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì°½ì´ í‘œì‹œë˜ë©´ í† í°ì„ ì…ë ¥í•˜ì—¬ ë¡œê·¸ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPUS Books ë°ì´í„°ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°[[load-opus-books-dataset]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì € ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ [OPUS Books](https://huggingface.co/datasets/opus_books) ë°ì´í„°ì„¸íŠ¸ì˜ ì˜ì–´-í”„ë‘ìŠ¤ì–´ í•˜ìœ„ ì§‘í•©ì„ ê°€ì ¸ì˜¤ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "books = load_dataset(\"opus_books\", \"en-fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì„¸íŠ¸ë¥¼ `train_test_split` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„í• í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ë°ì´í„°ì—ì„œ ì˜ˆì‹œë¥¼ ì‚´í´ë³¼ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '90560',\n",
       " 'translation': {'en': 'But this lofty plateau measured only a few fathoms, and soon we reentered Our Element.',\n",
       "  'fr': 'Mais ce plateau Ã©levÃ© ne mesurait que quelques toises, et bientÃ´t nous fÃ»mes rentrÃ©s dans notre Ã©lÃ©ment.'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ì˜ `translation` í‚¤ê°€ í…ìŠ¤íŠ¸ì˜ ì˜ì–´, í”„ë‘ìŠ¤ì–´ ë²„ì „ì„ í¬í•¨í•˜ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì „ì²˜ë¦¬[[preprocess]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XAR8jnZZuUs?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XAR8jnZZuUs?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ë‹¨ê³„ë¡œ ì˜ì–´-í”„ë‘ìŠ¤ì–´ ìŒì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ T5 í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§Œë“¤ ì „ì²˜ë¦¬ í•¨ìˆ˜ëŠ” ì•„ë˜ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. T5ê°€ ë²ˆì—­ íƒœìŠ¤í¬ì„ì„ ì¸ì§€í•  ìˆ˜ ìˆë„ë¡ ì…ë ¥ ì•ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”. ì—¬ëŸ¬ NLP íƒœìŠ¤í¬ë¥¼ í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ì¤‘ ì¼ë¶€ëŠ” ì´ë ‡ê²Œ íƒœìŠ¤í¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ì¤˜ì•¼í•©ë‹ˆë‹¤.\n",
    "2. ì›ì–´(ì˜ì–´)ê³¼ ë²ˆì—­ì–´(í”„ë‘ìŠ¤ì–´)ë¥¼ ë³„ë„ë¡œ í† í°í™”í•˜ì„¸ìš”. ì˜ì–´ ì–´íœ˜ë¡œ ì‚¬ì „ í•™ìŠµëœ í† í¬ë‚˜ì´ì €ë¡œ í”„ë‘ìŠ¤ì–´ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•  ìˆ˜ëŠ” ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "3. `max_length` ë§¤ê°œë³€ìˆ˜ë¡œ ì„¤ì •í•œ ìµœëŒ€ ê¸¸ì´ë³´ë‹¤ ê¸¸ì§€ ì•Šë„ë¡ ì‹œí€€ìŠ¤ë¥¼ truncateí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "prefix = \"translate English to French: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì „ì²´ ë°ì´í„°ì„¸íŠ¸ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë ¤ë©´ ğŸ¤— Datasetsì˜ `map` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. `map` í•¨ìˆ˜ì˜ ì†ë„ë¥¼ ë†’ì´ë ¤ë©´ `batched=True`ë¥¼ ì„¤ì •í•˜ì—¬ ë°ì´í„°ì„¸íŠ¸ì˜ ì—¬ëŸ¬ ìš”ì†Œë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_books = books.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `DataCollatorForSeq2Seq`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë°ì´í„°ì„¸íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ì „ë¶€ë¥¼ paddingí•˜ëŠ” ëŒ€ì‹ , ë°ì´í„° ì •ë ¬ ì¤‘ ê° ë°°ì¹˜ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ë¬¸ì¥ì„ *ë™ì ìœ¼ë¡œ padding*í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í‰ê°€[[evalulate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ì¤‘ì— ë©”íŠ¸ë¦­ì„ í¬í•¨í•˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ í‰ê°€ ë°©ë²•(evaluation method)ì„ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ íƒœìŠ¤í¬ì— ì í•©í•œ SacreBLEU ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¤ì„¸ìš”. (ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¤ê³  ê³„ì‚°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ ğŸ¤— Evaluate [ë‘˜ëŸ¬ë³´ê¸°](https://huggingface.co/docs/evaluate/a_quick_tour)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ° ë‹¤ìŒ `compute`ì— ì˜ˆì¸¡ê°’ê³¼ ë ˆì´ë¸”ì„ ì „ë‹¬í•˜ì—¬ SacreBLEU ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `compute_metrics` í•¨ìˆ˜ëŠ” ì¤€ë¹„ë˜ì—ˆê³ , í›ˆë ¨ ê³¼ì •ì„ ì„¤ì •í•  ë•Œ ë‹¤ì‹œ ì‚´í´ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í›ˆë ¨[[train]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "`Trainer`ë¡œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ [ì—¬ê¸°](https://huggingface.co/docs/transformers/main/ko/tasks/../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ì¤€ë¹„ê°€ ë˜ì—ˆêµ°ìš”! `AutoModelForSeq2SeqLM`ìœ¼ë¡œ T5ë¥¼ ë¡œë“œí•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì„¸ ë‹¨ê³„ë§Œ ê±°ì¹˜ë©´ ëì…ë‹ˆë‹¤:\n",
    "\n",
    "1. `Seq2SeqTrainingArguments`ì—ì„œ í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ì„¸ìš”. ìœ ì¼í•œ í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ëŠ” ëª¨ë¸ì„ ì €ì¥í•  ìœ„ì¹˜ì¸ `output_dir`ì…ë‹ˆë‹¤. ëª¨ë¸ì„ Hubì— í‘¸ì‹œí•˜ê¸° ìœ„í•´ `push_to_hub=True`ë¡œ ì„¤ì •í•˜ì„¸ìš”. (ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ Hugging Faceì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤.) `Trainer`ëŠ” ì—í­ì´ ëë‚ ë•Œë§ˆë‹¤ SacreBLEU ë©”íŠ¸ë¦­ì„ í‰ê°€í•˜ê³  í›ˆë ¨ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "2. `Seq2SeqTrainer`ì— í›ˆë ¨ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”. ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸, í† í¬ë‚˜ì´ì €, data collator ë° `compute_metrics` í•¨ìˆ˜ë„ ë©ë‹¬ì•„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "3. `train()`ì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "````\n",
       "\n",
       "í•™ìŠµì´ ì™„ë£Œë˜ë©´ `push_to_hub()` ë©”ì„œë“œë¡œ ëª¨ë¸ì„ Hubì— ê³µìœ í•˜ì„¸ìš”. ì´ëŸ¬ë©´ ëˆ„êµ¬ë‚˜ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤:"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_opus_books_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_books[\"train\"],\n",
    "    eval_dataset=tokenized_books[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ë²ˆì—­ì„ ìœ„í•´ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ë³´ë‹¤ ìì„¸í•œ ì˜ˆì œëŠ” í•´ë‹¹ [PyTorch ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb) ë˜ëŠ” [TensorFlow ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ë¡ [[inference]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¢‹ì•„ìš”, ì´ì œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í–ˆìœ¼ë‹ˆ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ë¥¼ ì¨ë³´ì„¸ìš”. T5ì˜ ê²½ìš° ì›í•˜ëŠ” íƒœìŠ¤í¬ë¥¼ ì…ë ¥ì˜ ì ‘ë‘ì‚¬ë¡œ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì˜ì–´ì—ì„œ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²½ìš°, ì•„ë˜ì™€ ê°™ì€ ì ‘ë‘ì‚¬ê°€ ì¶”ê°€ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íŒŒì¸íŠœë‹ëœ ëª¨ë¸ë¡œ ì¶”ë¡ í•˜ê¸°ì— ì œì¼ ê°„ë‹¨í•œ ë°©ë²•ì€ `pipeline()`ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•´ë‹¹ ëª¨ë¸ë¡œ ë²ˆì—­ `pipeline`ì„ ë§Œë“  ë’¤, í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Legumes partagent des ressources avec des bactÃ©ries azotantes.'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"my_awesome_opus_books_model\")\n",
    "translator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì›í•œë‹¤ë©´ `pipeline`ì˜ ê²°ê³¼ë¥¼ ì§ì ‘ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  `input_ids`ë¥¼ PyTorch í…ì„œë¡œ ë°˜í™˜í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"my_awesome_opus_books_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate()` ë©”ì„œë“œë¡œ ë²ˆì—­ì„ ìƒì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„± ì „ëµ ë° ìƒì„±ì„ ì œì–´í•˜ê¸° ìœ„í•œ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [Text Generation](https://huggingface.co/docs/transformers/main/ko/tasks/../main_classes/text_generation) APIë¥¼ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"my_awesome_opus_books_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒì„±ëœ í† í° IDë“¤ì„ ë‹¤ì‹œ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Les lignÃ©es partagent des ressources avec des bactÃ©ries enfixant l'azote.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
