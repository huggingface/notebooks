{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets evaluate accelerate\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‹œê°ì  ì§ˆì˜ì‘ë‹µ (Visual Question Answering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹œê°ì  ì§ˆì˜ì‘ë‹µ(VQA)ì€ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œë°©í˜• ì§ˆë¬¸ì— ëŒ€ì‘í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸ì˜ ì…ë ¥ì€ ëŒ€ë¶€ë¶„ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì˜ ì¡°í•©ì´ë©°, ì¶œë ¥ì€ ìì—°ì–´ë¡œ ëœ ë‹µë³€ì…ë‹ˆë‹¤.\n",
    "\n",
    "VQAì˜ ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "* ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ì ‘ê·¼ì„± ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "* êµìœ¡: ê°•ì˜ë‚˜ êµê³¼ì„œì— ë‚˜ì˜¨ ì‹œê° ìë£Œì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì²´í—˜í˜• ì „ì‹œì™€ ìœ ì  ë“±ì—ì„œë„ VQAë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "* ê³ ê° ì„œë¹„ìŠ¤ ë° ì „ììƒê±°ë˜: VQAëŠ” ì‚¬ìš©ìê°€ ì œí’ˆì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆê²Œ í•¨ìœ¼ë¡œì¨ ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "* ì´ë¯¸ì§€ ê²€ìƒ‰: VQA ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” íŠ¹ì„±ì„ ê°€ì§„ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì‚¬ìš©ìëŠ” \"ê°•ì•„ì§€ê°€ ìˆì–´?\"ë¼ê³  ë¬¼ì–´ë´ì„œ ì£¼ì–´ì§„ ì´ë¯¸ì§€ ë¬¶ìŒì—ì„œ ê°•ì•„ì§€ê°€ ìˆëŠ” ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë°›ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°€ì´ë“œì—ì„œ í•™ìŠµí•  ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- VQA ëª¨ë¸ ì¤‘ í•˜ë‚˜ì¸ [ViLT](https://huggingface.co/docs/transformers/main/ko/tasks/../../en/model_doc/vilt)ë¥¼ [`Graphcore/vqa` ë°ì´í„°ì…‹](https://huggingface.co/datasets/Graphcore/vqa) ì—ì„œ ë¯¸ì„¸ì¡°ì •í•˜ëŠ” ë°©ë²•\n",
    "- ë¯¸ì„¸ì¡°ì •ëœ ViLT ëª¨ë¸ë¡œ ì¶”ë¡ í•˜ëŠ” ë°©ë²•\n",
    "- BLIP-2 ê°™ì€ ìƒì„± ëª¨ë¸ë¡œ ì œë¡œìƒ· VQA ì¶”ë¡ ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViLT ë¯¸ì„¸ ì¡°ì • [[finetuning-vilt]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViLTëŠ” Vision Transformer (ViT) ë‚´ì— í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ í¬í•¨í•˜ì—¬ ë¹„ì „/ìì—°ì–´ ì‚¬ì „í›ˆë ¨(VLP; Vision-and-Language Pretraining)ì„ ìœ„í•œ ê¸°ë³¸ ë””ìì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ViLT ëª¨ë¸ì€ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸(ViT)ì— í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ë„£ì–´ ë¹„ì „/ì–¸ì–´ ì‚¬ì „í›ˆë ¨(VLP; Vision-and-Language Pre-training)ì„ ìœ„í•œ ê¸°ë³¸ì ì¸ ë””ìì¸ì„ ê°–ì·„ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì—¬ëŸ¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. VQA íƒœìŠ¤í¬ì—ì„œëŠ” (`[CLS]` í† í°ì˜ ìµœì¢… ì€ë‹‰ ìƒíƒœ ìœ„ì— ì„ í˜• ë ˆì´ì–´ì¸) ë¶„ë¥˜ í—¤ë”ê°€ ìˆìœ¼ë©° ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.\n",
    "ë”°ë¼ì„œ ì—¬ê¸°ì—ì„œ ì‹œê°ì  ì§ˆì˜ì‘ë‹µì€ **ë¶„ë¥˜ ë¬¸ì œ**ë¡œ ì·¨ê¸‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "ìµœê·¼ì˜ BLIP, BLIP-2, InstructBLIPì™€ ê°™ì€ ëª¨ë¸ë“¤ì€ VQAë¥¼ ìƒì„±í˜• ì‘ì—…ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. ê°€ì´ë“œì˜ í›„ë°˜ë¶€ì—ì„œëŠ” ì´ëŸ° ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì œë¡œìƒ· VQA ì¶”ë¡ ì„ í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "```bash\n",
    "pip install -q transformers datasets\n",
    "```\n",
    "\n",
    "ì»¤ë®¤ë‹ˆí‹°ì— ëª¨ë¸ì„ ê³µìœ í•˜ëŠ” ê²ƒì„ ê¶Œì¥ ë“œë¦½ë‹ˆë‹¤. Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ğŸ¤— Hubì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ë©”ì‹œì§€ê°€ ë‚˜íƒ€ë‚˜ë©´ ë¡œê·¸ì¸í•  í† í°ì„ ì…ë ¥í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"dandelin/vilt-b32-mlm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ê°€ì ¸ì˜¤ê¸° [[load-the-data]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ê°€ì´ë“œì—ì„œëŠ” `Graphcore/vqa` ë°ì´í„°ì„¸íŠ¸ì˜ ì‘ì€ ìƒ˜í”Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ì„¸íŠ¸ëŠ” [ğŸ¤— Hub](https://huggingface.co/datasets/Graphcore/vqa) ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "[`Graphcore/vqa` ë°ì´í„°ì„¸íŠ¸](https://huggingface.co/datasets/Graphcore/vqa) ì˜ ëŒ€ì•ˆìœ¼ë¡œ ê³µì‹ [VQA ë°ì´í„°ì„¸íŠ¸ í˜ì´ì§€](https://visualqa.org/download.html) ì—ì„œ ë™ì¼í•œ ë°ì´í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ì ‘ ê³µìˆ˜í•œ ë°ì´í„°ë¡œ íŠœí† ë¦¬ì–¼ì„ ë”°ë¥´ê³  ì‹¶ë‹¤ë©´ [ì´ë¯¸ì§€ ë°ì´í„°ì„¸íŠ¸ ë§Œë“¤ê¸°](https://huggingface.co/docs/datasets/image_dataset#loading-script) ë¼ëŠ”\n",
    "ğŸ¤— Datasets ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "ê²€ì¦ ë°ì´í„°ì˜ ì²« 200ê°œ í•­ëª©ì„ ë¶ˆëŸ¬ì™€ ë°ì´í„°ì„¸íŠ¸ì˜ íŠ¹ì„±ì„ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_type', 'question_id', 'image_id', 'answer_type', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Graphcore/vqa\", split=\"validation[:200]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì œë¥¼ í•˜ë‚˜ ë½‘ì•„ ë°ì´í„°ì„¸íŠ¸ì˜ íŠ¹ì„±ì„ ì´í•´í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where is he looking?',\n",
       " 'question_type': 'none of the above',\n",
       " 'question_id': 262148000,\n",
       " 'image_id': '/root/.cache/huggingface/datasets/downloads/extracted/ca733e0e000fb2d7a09fbcc94dbfe7b5a30750681d0e965f8e0a23b1c2f98c75/val2014/COCO_val2014_000000262148.jpg',\n",
       " 'answer_type': 'other',\n",
       " 'label': {'ids': ['at table', 'down', 'skateboard', 'table'],\n",
       "  'weights': [0.30000001192092896,\n",
       "   1.0,\n",
       "   0.30000001192092896,\n",
       "   0.30000001192092896]}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì„¸íŠ¸ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
    "* `question`: ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸\n",
    "* `image_id`: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ì˜ ê²½ë¡œ\n",
    "* `label`: ë°ì´í„°ì˜ ë ˆì´ë¸” (annotations)\n",
    "\n",
    "ë‚˜ë¨¸ì§€ íŠ¹ì„±ë“¤ì€ í•„ìš”í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì‚­ì œí•´ë„ ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['question_type', 'question_id', 'answer_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë³´ì‹œë‹¤ì‹œí”¼ `label` íŠ¹ì„±ì€ ê°™ì€ ì§ˆë¬¸ë§ˆë‹¤ ë‹µë³€ì´ ì—¬ëŸ¬ ê°œ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë‘ ë‹¤ë¥¸ ë°ì´í„° ë¼ë²¨ëŸ¬ë“¤ë¡œë¶€í„° ìˆ˜ì§‘ë˜ì—ˆê¸° ë•Œë¬¸ì¸ë°ìš”. ì§ˆë¬¸ì˜ ë‹µë³€ì€ ì£¼ê´€ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ì§ˆë¬¸ì€ \"ê·¸ëŠ” ì–´ë””ë¥¼ ë³´ê³  ìˆë‚˜ìš”?\" ì˜€ì§€ë§Œ, ì–´ë–¤ ì‚¬ëŒë“¤ì€ \"ì•„ë˜\"ë¡œ ë ˆì´ë¸”ì„ ë‹¬ì•˜ê³ , ë‹¤ë¥¸ ì‚¬ëŒë“¤ì€ \"í…Œì´ë¸”\" ë˜ëŠ” \"ìŠ¤ì¼€ì´íŠ¸ë³´ë“œ\" ë“±ìœ¼ë¡œ ì£¼ì„ì„ ë‹¬ì•˜ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì˜ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì–´ë–¤ ë‹µë³€ì„ ì„ íƒí•  ê²ƒì¸ì§€ ìƒê°í•´ ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(dataset[0]['image_id'])\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "     <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/vqa-example.png\" alt=\"VQA Image Example\"/>\n",
    "</div>\n",
    "\n",
    "ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ëª¨í˜¸ì„±ìœ¼ë¡œ ì¸í•´ ì´ëŸ¬í•œ ë°ì´í„°ì„¸íŠ¸ëŠ” ì—¬ëŸ¬ ê°œì˜ ë‹µë³€ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ ë¬¸ì œë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ê²Œë‹¤ê°€, ì›í•«(one-hot) ì¸ì½”ë”© ë²¡í„°ë¥¼ ìƒì„±í•˜ê¸°ë³´ë‹¤ëŠ” ë ˆì´ë¸”ì—ì„œ íŠ¹ì • ë‹µë³€ì´ ë‚˜íƒ€ë‚˜ëŠ” íšŸìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†Œí”„íŠ¸ ì¸ì½”ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ì˜ ì˜ˆì‹œì—ì„œ \"ì•„ë˜\"ë¼ëŠ” ë‹µë³€ì´ ë‹¤ë¥¸ ë‹µë³€ë³´ë‹¤ í›¨ì”¬ ë” ìì£¼ ì„ íƒë˜ì—ˆê¸° ë•Œë¬¸ì— ë°ì´í„°ì„¸íŠ¸ì—ì„œ `weight`ë¼ê³  ë¶ˆë¦¬ëŠ” ì ìˆ˜ë¡œ 1.0ì„ ê°€ì§€ë©°, ë‚˜ë¨¸ì§€ ë‹µë³€ë“¤ì€ 1.0 ë¯¸ë§Œì˜ ì ìˆ˜ë¥¼ ê°€ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ì ì ˆí•œ ë¶„ë¥˜ í—¤ë”ë¡œ ëª¨ë¸ì„ ë‚˜ì¤‘ì— ì¸ìŠ¤í„´ìŠ¤í™”í•˜ê¸° ìœ„í•´ ë ˆì´ë¸”ì„ ì •ìˆ˜ë¡œ ë§¤í•‘í•œ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜, ë°˜ëŒ€ë¡œ ì •ìˆ˜ë¥¼ ë ˆì´ë¸”ë¡œ ë§¤í•‘í•œ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ ì´ 2ê°œì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "labels = [item['ids'] for item in dataset['label']]\n",
    "flattened_labels = list(itertools.chain(*labels))\n",
    "unique_labels = list(set(flattened_labels))\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë§¤í•‘ì´ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ ë‹µë³€ì„ í•´ë‹¹ idë¡œ êµì²´í•˜ê³ , ë°ì´í„°ì„¸íŠ¸ì˜ ë” í¸ë¦¬í•œ í›„ì²˜ë¦¬ë¥¼ ìœ„í•´ í¸í‰í™” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': Value(dtype='string', id=None),\n",
       " 'image_id': Value(dtype='string', id=None),\n",
       " 'label.ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'label.weights': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_ids(inputs):\n",
    "  inputs[\"label\"][\"ids\"] = [label2id[x] for x in inputs[\"label\"][\"ids\"]]\n",
    "  return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(replace_ids)\n",
    "flat_dataset = dataset.flatten()\n",
    "flat_dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì „ì²˜ë¦¬ [[preprocessing-data]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ë‹¨ê³„ëŠ” ëª¨ë¸ì„ ìœ„í•´ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê¸° ìœ„í•´ ViLT í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "`ViltProcessor`ëŠ” BERT í† í¬ë‚˜ì´ì €ì™€ ViLT ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œë¥¼ í¸ë¦¬í•˜ê²Œ í•˜ë‚˜ì˜ í”„ë¡œì„¸ì„œë¡œ ë¬¶ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor\n",
    "\n",
    "processor = ViltProcessor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ë ¤ë©´ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ `ViltProcessor`ë¡œ ì¸ì½”ë”©í•´ì•¼ í•©ë‹ˆë‹¤. í”„ë¡œì„¸ì„œëŠ” [BertTokenizerFast](https://huggingface.co/docs/transformers/main/ko/model_doc/bert#transformers.BertTokenizerFast)ë¡œ í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì¦ˆí•˜ê³  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìœ„í•´ `input_ids`, `attention_mask` ë° `token_type_ids`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "ì´ë¯¸ì§€ëŠ” `ViltImageProcessor`ë¡œ ì´ë¯¸ì§€ë¥¼ í¬ê¸° ì¡°ì •í•˜ê³  ì •ê·œí™”í•˜ë©°, `pixel_values`ì™€ `pixel_mask`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ° ì „ì²˜ë¦¬ ë‹¨ê³„ëŠ” ëª¨ë‘ ë‚´ë¶€ì—ì„œ ì´ë£¨ì–´ì§€ë¯€ë¡œ, `processor`ë¥¼ í˜¸ì¶œí•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ì§ íƒ€ê²Ÿ ë ˆì´ë¸”ì´ ì™„ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íƒ€ê²Ÿì˜ í‘œí˜„ì—ì„œ ê° ìš”ì†ŒëŠ” ê°€ëŠ¥í•œ ë‹µë³€(ë ˆì´ë¸”)ì— í•´ë‹¹í•©ë‹ˆë‹¤. ì •í™•í•œ ë‹µë³€ì˜ ìš”ì†ŒëŠ” í•´ë‹¹ ì ìˆ˜(weight)ë¥¼ ìœ ì§€ì‹œí‚¤ê³  ë‚˜ë¨¸ì§€ ìš”ì†ŒëŠ” 0ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ í•¨ìˆ˜ê°€ ìœ„ì—ì„œ ì„¤ëª…í•œëŒ€ë¡œ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì— `processor`ë¥¼ ì ìš©í•˜ê³  ë ˆì´ë¸”ì„ í˜•ì‹ì— ë§ì¶¥ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    image_paths = examples['image_id']\n",
    "    images = [Image.open(image_path) for image_path in image_paths]\n",
    "    texts = examples['question']\n",
    "\n",
    "    encoding = processor(images, texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    for k, v in encoding.items():\n",
    "          encoding[k] = v.squeeze()\n",
    "\n",
    "    targets = []\n",
    "\n",
    "    for labels, scores in zip(examples['label.ids'], examples['label.weights']):\n",
    "        target = torch.zeros(len(id2label))\n",
    "\n",
    "        for label, score in zip(labels, scores):\n",
    "            target[label] = score\n",
    "\n",
    "        targets.append(target)\n",
    "\n",
    "    encoding[\"labels\"] = targets\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì „ì²´ ë°ì´í„°ì„¸íŠ¸ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë ¤ë©´ ğŸ¤— Datasetsì˜ `map` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. `batched=True`ë¥¼ ì„¤ì •í•˜ì—¬ ë°ì´í„°ì„¸íŠ¸ì˜ ì—¬ëŸ¬ ìš”ì†Œë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ `map`ì„ ë” ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì‹œì ì—ì„œ í•„ìš”í•˜ì§€ ì•Šì€ ì—´ì€ ì œê±°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'pixel_values', 'pixel_mask', 'labels'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = flat_dataset.map(preprocess_data, batched=True, remove_columns=['question','question_type',  'question_id', 'image_id', 'answer_type', 'label.ids', 'label.weights'])\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ ë‹¨ê³„ë¡œ, [DefaultDataCollator](https://huggingface.co/docs/transformers/main/ko/main_classes/data_collator#transformers.DefaultDataCollator)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œë¡œ ì“¸ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í›ˆë ¨ [[train-the-model]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! `ViltForQuestionAnswering`ìœ¼ë¡œ ViLTë¥¼ ê°€ì ¸ì˜¬ ì°¨ë¡€ì…ë‹ˆë‹¤. ë ˆì´ë¸”ì˜ ìˆ˜ì™€ ë ˆì´ë¸” ë§¤í•‘ì„ ì§€ì •í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltForQuestionAnswering\n",
    "\n",
    "model = ViltForQuestionAnswering.from_pretrained(model_checkpoint, num_labels=len(id2label), id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ì‹œì ì—ì„œëŠ” ë‹¤ìŒ ì„¸ ë‹¨ê³„ë§Œ ë‚¨ì•˜ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. [TrainingArguments](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.TrainingArguments)ì—ì„œ í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "repo_id = \"MariaK/vilt_finetuned_200\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_id,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=20,\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    learning_rate=5e-5,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ëª¨ë¸, ë°ì´í„°ì„¸íŠ¸, í”„ë¡œì„¸ì„œ, ë°ì´í„° ì½œë ˆì´í„°ì™€ í•¨ê»˜ í›ˆë ¨ ì¸ìˆ˜ë¥¼ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ì— ì „ë‹¬í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=processed_dataset,\n",
    "    processing_class=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [train()](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer.train)ì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ì´ ì™„ë£Œë˜ë©´, [push_to_hub()](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer.push_to_hub) ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ğŸ¤— Hubì— ëª¨ë¸ì„ ê³µìœ í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ë¡  [[inference]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViLT ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³  ğŸ¤— Hubì— ì—…ë¡œë“œí–ˆë‹¤ë©´ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì¶”ë¡ ì— ì‚¬ìš©í•´ë³´ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ `Pipeline`ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"visual-question-answering\", model=\"MariaK/vilt_finetuned_200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ê°€ì´ë“œì˜ ëª¨ë¸ì€ 200ê°œì˜ ì˜ˆì œì—ì„œë§Œ í›ˆë ¨ë˜ì—ˆìœ¼ë¯€ë¡œ ê·¸ë‹¤ì§€ ë§ì€ ê²ƒì„ ê¸°ëŒ€í•  ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì„¸íŠ¸ì˜ ì²« ë²ˆì§¸ ì˜ˆì œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ê²°ê³¼ë¥¼ ì„¤ëª…í•´ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Where is he looking?\"\n",
       "[{'score': 0.5498199462890625, 'answer': 'down'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[0]\n",
    "image = Image.open(example['image_id'])\n",
    "question = example['question']\n",
    "print(question)\n",
    "pipe(image, question, top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¹„ë¡ í™•ì‹ ì€ ë³„ë¡œ ì—†ì§€ë§Œ, ëª¨ë¸ì€ ì‹¤ì œë¡œ ë¬´ì–¸ê°€ë¥¼ ë°°ì› ìŠµë‹ˆë‹¤. ë” ë§ì€ ì˜ˆì œì™€ ë” ê¸´ í›ˆë ¨ ê¸°ê°„ì´ ì£¼ì–´ì§„ë‹¤ë©´ ë¶„ëª… ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤!\n",
    "\n",
    "ì›í•œë‹¤ë©´ íŒŒì´í”„ë¼ì¸ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n",
    "1. ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ê°€ì ¸ì™€ì„œ í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "2. ì „ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "3. ë¡œì§“ì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„± ìˆëŠ” ë‹µë³€ì˜ idë¥¼ ê°€ì ¸ì™€ì„œ `id2label`ì—ì„œ ì‹¤ì œ ë‹µë³€ì„ ì°¾ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted answer: down"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = ViltProcessor.from_pretrained(\"MariaK/vilt_finetuned_200\")\n",
    "\n",
    "image = Image.open(example['image_id'])\n",
    "question = example['question']\n",
    "\n",
    "# prepare inputs\n",
    "inputs = processor(image, question, return_tensors=\"pt\")\n",
    "\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"MariaK/vilt_finetuned_200\")\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "print(\"Predicted answer:\", model.config.id2label[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì œë¡œìƒ· VQA [[zeroshot-vqa]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì „ ëª¨ë¸ì€ VQAë¥¼ ë¶„ë¥˜ ë¬¸ì œë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. BLIP, BLIP-2 ë° InstructBLIPì™€ ê°™ì€ ìµœê·¼ì˜ ëª¨ë¸ì€ VQAë¥¼ ìƒì„± ì‘ì—…ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤. [BLIP-2](https://huggingface.co/docs/transformers/main/ko/tasks/../../en/model_doc/blip-2)ë¥¼ ì˜ˆë¡œ ë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì‚¬ì „í›ˆë ¨ëœ ë¹„ì „ ì¸ì½”ë”ì™€ LLMì˜ ëª¨ë“  ì¡°í•©ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë¹„ì „-ìì—°ì–´ ì‚¬ì „ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ([BLIP-2 ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸](https://huggingface.co/blog/blip-2)ë¥¼ í†µí•´ ë” ìì„¸íˆ ì•Œì•„ë³¼ ìˆ˜ ìˆì–´ìš”)\n",
    "ì´ë¥¼ í†µí•´ ì‹œê°ì  ì§ˆì˜ì‘ë‹µì„ í¬í•¨í•œ ì—¬ëŸ¬ ë¹„ì „-ìì—°ì–´ ì‘ì—…ì—ì„œ SOTAë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ëª¨ë¸ì„ ì–´ë–»ê²Œ VQAì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ ë³´ê² ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ ê°€ì ¸ì™€ ë³´ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ëª¨ë¸ì„ ëª…ì‹œì ìœ¼ë¡œ GPUë¡œ ì „ì†¡í•  ê²ƒì…ë‹ˆë‹¤. ì´ì „ì—ëŠ” í›ˆë ¨í•  ë•Œ ì“°ì§€ ì•Šì€ ì´ìœ ëŠ” [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ê°€ ì´ ë¶€ë¶„ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìœ¼ë¯€ë¡œ, VQA ë°ì´í„°ì„¸íŠ¸ì˜ ì²« ë²ˆì§¸ ì˜ˆì œì—ì„œì™€ ë™ì¼í•œ ì´ë¯¸ì§€/ì§ˆë¬¸ ìŒì„ ì‚¬ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[0]\n",
    "image = Image.open(example['image_id'])\n",
    "question = example['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLIP-2ë¥¼ ì‹œê°ì  ì§ˆì˜ì‘ë‹µ ì‘ì—…ì— ì‚¬ìš©í•˜ë ¤ë©´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ê°€ `Question: {} Answer:` í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Question: {question} Answer:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì˜ í”„ë¡œì„¸ì„œë¡œ ì´ë¯¸ì§€/í”„ë¡¬í”„íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³ , ì²˜ë¦¬ëœ ì…ë ¥ì„ ëª¨ë¸ì„ í†µí•´ ì „ë‹¬í•˜ê³ , ì¶œë ¥ì„ ë””ì½”ë“œí•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He is looking at the crowd\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë³´ì‹œë‹¤ì‹œí”¼ ëª¨ë¸ì€ êµ°ì¤‘ì„ ì¸ì‹í•˜ê³ , ì–¼êµ´ì˜ ë°©í–¥(ì•„ë˜ìª½ì„ ë³´ê³  ìˆìŒ)ì„ ì¸ì‹í–ˆì§€ë§Œ, êµ°ì¤‘ì´ ìŠ¤ì¼€ì´í„° ë’¤ì— ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ë†“ì³¤ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‚¬ëŒì´ ì§ì ‘ ë¼ë²¨ë§í•œ ë°ì´í„°ì…‹ì„ ì–»ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—, ì´ ì ‘ê·¼ë²•ì€ ë¹ ë¥´ê²Œ ìœ ìš©í•œ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
