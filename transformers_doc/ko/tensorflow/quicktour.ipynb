{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets evaluate accelerate\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‘˜ëŸ¬ë³´ê¸° [[quick-tour]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤— Transformersë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”! ê°œë°œí•´ë³¸ ì ì´ ì—†ë”ë¼ë„ ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆë„ë¡ ì“°ì¸ ì´ ê¸€ì€ [`pipeline`](https://huggingface.co/docs/transformers/main/ko/./main_classes/pipelines)ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ í•˜ê³ , ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë¥¼ [AutoClass](https://huggingface.co/docs/transformers/main/ko/./model_doc/auto)ë¡œ ë¡œë“œí•˜ê³ , PyTorch ë˜ëŠ” TensorFlowë¡œ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì„ ì†Œê°œí•´ ë“œë¦´ ê²ƒì…ë‹ˆë‹¤. ë³¸ ê°€ì´ë“œì—ì„œ ì†Œê°œë˜ëŠ” ê°œë…ì„ (íŠ¹íˆ ì´ˆë³´ìì˜ ê´€ì ìœ¼ë¡œ) ë” ì¹œì ˆí•˜ê²Œ ì ‘í•˜ê³  ì‹¶ë‹¤ë©´, íŠœí† ë¦¬ì–¼ì´ë‚˜ [ì½”ìŠ¤](https://huggingface.co/course/chapter1/1)ë¥¼ ì°¸ì¡°í•˜ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:\n",
    "\n",
    "```bash\n",
    "!pip install transformers datasets evaluate accelerate\n",
    "```\n",
    "\n",
    "ë˜í•œ ì„ í˜¸í•˜ëŠ” ë¨¸ì‹  ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## íŒŒì´í”„ë¼ì¸ [[pipeline]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tiZFewofSLM?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tiZFewofSLM?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`pipeline`](https://huggingface.co/docs/transformers/main/ko/./main_classes/pipelines)ì€ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì¶”ë¡ í•˜ê¸°ì— ê°€ì¥ ì‰½ê³  ë¹ ë¥¸ ë°©ë²•ì…ë‹ˆë‹¤. `pipeline()`ì€ ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ì—ì„œ ë‹¤ì–‘í•œ ê³¼ì—…ì„ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ì•„ë˜ í‘œì— í‘œì‹œëœ ëª‡ ê°€ì§€ ê³¼ì—…ì„ ê¸°ë³¸ì ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤:\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ì‘ì—…ì˜ ì „ì²´ ëª©ë¡ì€ [Pipelines API ì°¸ì¡°](https://huggingface.co/docs/transformers/main/ko/./main_classes/pipelines)ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "| **íƒœìŠ¤í¬**      | **ì„¤ëª…**                                                             | **ëª¨ë‹¬ë¦¬í‹°**     | **íŒŒì´í”„ë¼ì¸ ID**                             |\n",
    "|-----------------|----------------------------------------------------------------------|------------------|-----------------------------------------------|\n",
    "| í…ìŠ¤íŠ¸ ë¶„ë¥˜      | í…ìŠ¤íŠ¸ì— ì•Œë§ì€ ë ˆì´ë¸” ë¶™ì´ê¸°                                         | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"sentiment-analysis\")           |\n",
    "| í…ìŠ¤íŠ¸ ìƒì„±      | ì£¼ì–´ì§„ ë¬¸ìì—´ ì…ë ¥ê³¼ ì´ì–´ì§€ëŠ” í…ìŠ¤íŠ¸ ìƒì„±í•˜ê¸°                       | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"text-generation\")              |\n",
    "| ê°œì²´ëª… ì¸ì‹      | ë¬¸ìì—´ì˜ ê° í† í°ë§ˆë‹¤ ì•Œë§ì€ ë ˆì´ë¸” ë¶™ì´ê¸° (ì¸ë¬¼, ì¡°ì§, ì¥ì†Œ ë“±ë“±)     | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"ner\")                          |\n",
    "| ì§ˆì˜ì‘ë‹µ         | ì£¼ì–´ì§„ ë¬¸ë§¥ê³¼ ì§ˆë¬¸ì— ë”°ë¼ ì˜¬ë°”ë¥¸ ëŒ€ë‹µí•˜ê¸°                           | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"question-answering\")           |\n",
    "| ë¹ˆì¹¸ ì±„ìš°ê¸°      | ë¬¸ìì—´ì˜ ë¹ˆì¹¸ì— ì•Œë§ì€ í† í° ë§ì¶”ê¸°                                  | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"fill-mask\")                    |\n",
    "| ìš”ì•½             | í…ìŠ¤íŠ¸ë‚˜ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê¸°                                            | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"summarization\")                |\n",
    "| ë²ˆì—­             | í…ìŠ¤íŠ¸ë¥¼ í•œ ì–¸ì–´ì—ì„œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ê¸°                           | ìì—°ì–´ ì²˜ë¦¬(NLP) | pipeline(task=\"translation\")                  |\n",
    "| ì´ë¯¸ì§€ ë¶„ë¥˜      | ì´ë¯¸ì§€ì— ì•Œë§ì€ ë ˆì´ë¸” ë¶™ì´ê¸°                                         | ì»´í“¨í„° ë¹„ì „(CV)  | pipeline(task=\"image-classification\")         |\n",
    "| ì´ë¯¸ì§€ ë¶„í•       | ì´ë¯¸ì§€ì˜ í”½ì…€ë§ˆë‹¤ ë ˆì´ë¸” ë¶™ì´ê¸°(ì‹œë§¨í‹±, íŒŒë†‰í‹± ë° ì¸ìŠ¤í„´ìŠ¤ ë¶„í•  í¬í•¨) | ì»´í“¨í„° ë¹„ì „(CV)  | pipeline(task=\"image-segmentation\")           |\n",
    "| ê°ì²´ íƒì§€        | ì´ë¯¸ì§€ ì† ê°ì²´ì˜ ê²½ê³„ ìƒìë¥¼ ê·¸ë¦¬ê³  í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ê¸°               | ì»´í“¨í„° ë¹„ì „(CV)  | pipeline(task=\"object-detection\")             |\n",
    "| ì˜¤ë””ì˜¤ ë¶„ë¥˜      | ì˜¤ë””ì˜¤ íŒŒì¼ì— ì•Œë§ì€ ë ˆì´ë¸” ë¶™ì´ê¸°                                    | ì˜¤ë””ì˜¤           | pipeline(task=\"audio-classification\")         |\n",
    "| ìë™ ìŒì„± ì¸ì‹   | ì˜¤ë””ì˜¤ íŒŒì¼ ì† ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë°”ê¾¸ê¸°                               | ì˜¤ë””ì˜¤           | pipeline(task=\"automatic-speech-recognition\") |\n",
    "| ì‹œê° ì§ˆì˜ì‘ë‹µ    | ì£¼ì–´ì§„ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì— ëŒ€í•´ ì˜¬ë°”ë¥´ê²Œ ëŒ€ë‹µí•˜ê¸°                       | ë©€í‹°ëª¨ë‹¬         | pipeline(task=\"vqa\")                          |\n",
    "| ë¬¸ì„œ ì§ˆì˜ì‘ë‹µ    | ì£¼ì–´ì§„ ë¬¸ì„œì™€ ì§ˆë¬¸ì— ëŒ€í•´ ì˜¬ë°”ë¥´ê²Œ ëŒ€ë‹µí•˜ê¸°                         | ë©€í‹°ëª¨ë‹¬         | pipeline(task=\"document-question-answering\")  |\n",
    "| ì´ë¯¸ì§€ ìº¡ì…˜ ë‹¬ê¸° | ì£¼ì–´ì§„ ì´ë¯¸ì§€ì˜ ìº¡ì…˜ ìƒì„±í•˜ê¸°                                       | ë©€í‹°ëª¨ë‹¬         | pipeline(task=\"image-to-text\")                |\n",
    "\n",
    "ë¨¼ì € `pipeline()`ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì‚¬ìš©í•  ì‘ì—…ì„ ì§€ì •í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” ê°ì • ë¶„ì„ì„ ìœ„í•´ `pipeline()`ì„ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline()`ì€ ê°ì • ë¶„ì„ì„ ìœ„í•œ [ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤. ì´ì œ `classifier`ë¥¼ ëŒ€ìƒ í…ìŠ¤íŠ¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the ğŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§Œì•½ ì…ë ¥ì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” ê²½ìš°, ì…ë ¥ì„ ë¦¬ìŠ¤íŠ¸ë¡œ `pipeline()`ì— ì „ë‹¬í•˜ì—¬, ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label: POSITIVE, with score: 0.9998\n",
       "label: NEGATIVE, with score: 0.5309"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline()`ì€ ì£¼ì–´ì§„ ê³¼ì—…ì— ê´€ê³„ì—†ì´ ë°ì´í„°ì…‹ ì „ë¶€ë¥¼ ìˆœíšŒí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ìë™ ìŒì„± ì¸ì‹ì„ ê³¼ì—…ìœ¼ë¡œ ì„ íƒí•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ì„ ë¡œë“œí•  ì°¨ë¡€ì…ë‹ˆë‹¤. (ìì„¸í•œ ë‚´ìš©ì€ ğŸ¤— Datasets [ì‹œì‘í•˜ê¸°](https://huggingface.co/docs/datasets/quickstart#audio)ì„ ì°¸ì¡°í•˜ì„¸ìš”) ì—¬ê¸°ì—ì„œëŠ” [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ê°€ ê¸°ì¡´ ëª¨ë¸ì¸ [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h)ì˜ í›ˆë ¨ ë‹¹ì‹œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\"audio\"` ì—´ì„ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì ¸ì™€ì„œ ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤. ì²« 4ê°œ ìƒ˜í”Œì—ì„œ ì›ì‹œ ì›¨ì´ë¸Œí¼ ë°°ì—´ì„ ì¶”ì¶œí•˜ê³  íŒŒì´í”„ë¼ì¸ì— ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìŒì„±ì´ë‚˜ ë¹„ì „ê³¼ ê°™ì´ ì…ë ¥ì´ í° ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì˜ ê²½ìš°, ëª¨ë“  ì…ë ¥ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ë ¤ë©´ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ì œë„ˆë ˆì´í„° í˜•íƒœë¡œ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [Pipelines API ì°¸ì¡°](https://huggingface.co/docs/transformers/main/ko/./main_classes/pipelines)ë¥¼ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒŒì´í”„ë¼ì¸ì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì‚¬ìš©í•˜ê¸° [[use-another-model-and-tokenizer-in-the-pipeline]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline()`ì€ [Hub](https://huggingface.co/models)ì˜ ëª¨ë“  ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, `pipeline()`ì„ ë‹¤ë¥¸ ìš©ë„ì— ë§ê²Œ ì‰½ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í”„ë‘ìŠ¤ì–´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  Hubì˜ íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ëª¨ë¸ì„ í•„í„°ë§í•˜ë©´ ë©ë‹ˆë‹¤. í•„í„°ë§ëœ ê²°ê³¼ì˜ ìƒìœ„ í•­ëª©ìœ¼ë¡œëŠ” í”„ë‘ìŠ¤ì–´ í…ìŠ¤íŠ¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤êµ­ì–´ [BERT ëª¨ë¸](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)ì´ ë°˜í™˜ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TFAutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.TFAutoModelForSequenceClassification)ê³¼ [AutoTokenizer](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoTokenizer)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ê´€ë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ì„¸ìš” (ë‹¤ìŒ ì„¹ì…˜ì—ì„œ `TFAutoClass`ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline()`ì—ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì§€ì •í•˜ë©´, ì´ì œ `classifier`ë¥¼ í”„ë‘ìŠ¤ì–´ í…ìŠ¤íŠ¸ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7273}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆë•…í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ë¯¸ì„¸ì¡°ì • ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ë¯¸ì„¸ì¡°ì • íŠœí† ë¦¬ì–¼](https://huggingface.co/docs/transformers/main/ko/./training)ì„ ì°¸ì¡°í•˜ì„¸ìš”. ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•œ í›„ì—ëŠ” ëª¨ë¸ì„ Hubì˜ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ë¯¼ì£¼í™”ì— ê¸°ì—¬í•´ì£¼ì„¸ìš”! ğŸ¤—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoClass [[autoclass]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhChOFRegn4?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhChOFRegn4?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoModelForSequenceClassification)ê³¼ [AutoTokenizer](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoTokenizer) í´ë˜ìŠ¤ëŠ” ìœ„ì—ì„œ ë‹¤ë£¬ `pipeline()`ì˜ ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. [AutoClass](https://huggingface.co/docs/transformers/main/ko/./model_doc/auto)ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì´ë¦„ì´ë‚˜ ê²½ë¡œì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” 'ë°”ë¡œê°€ê¸°'ì…ë‹ˆë‹¤. ê³¼ì—…ì— ì í•©í•œ `AutoClass`ë¥¼ ì„ íƒí•˜ê³  í•´ë‹¹ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ ì„ íƒí•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ì „ ì„¹ì…˜ì˜ ì˜ˆì œë¡œ ëŒì•„ê°€ì„œ `pipeline()`ì˜ ê²°ê³¼ë¥¼ `AutoClass`ë¥¼ í™œìš©í•´ ë³µì œí•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoTokenizer [[autotokenizer]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ìˆ«ì ë°°ì—´ í˜•íƒœë¡œ ì „ì²˜ë¦¬í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. í† í°í™” ê³¼ì •ì—ëŠ” ë‹¨ì–´ë¥¼ ì–´ë””ì—ì„œ ëŠì„ì§€, ì–´ëŠ ìˆ˜ì¤€ê¹Œì§€ ë‚˜ëˆŒì§€ì™€ ê°™ì€ ì—¬ëŸ¬ ê·œì¹™ë“¤ì´ ìˆìŠµë‹ˆë‹¤ (í† í°í™”ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [í† í¬ë‚˜ì´ì € ìš”ì•½](https://huggingface.co/docs/transformers/main/ko/./tokenizer_summary)ì„ ì°¸ì¡°í•˜ì„¸ìš”). ê°€ì¥ ì¤‘ìš”í•œ ì ì€ ëª¨ë¸ì´ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ë™ì¼í•œ í† í°í™” ê·œì¹™ì„ ì‚¬ìš©í•˜ë„ë¡ ë™ì¼í•œ ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ í† í¬ë‚˜ì´ì €ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "[AutoTokenizer](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoTokenizer)ë¡œ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì €ì— ì „ë‹¬í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the ğŸ¤— Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í† í¬ë‚˜ì´ì €ëŠ” ë‹¤ìŒì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:\n",
    "\n",
    "* [input_ids](https://huggingface.co/docs/transformers/main/ko/./glossary#input-ids): í† í°ì˜ ìˆ«ì í‘œí˜„.\n",
    "* [attention_mask](https://huggingface.co/docs/transformers/main/ko/.glossary#attention-mask): ì–´ë–¤ í† í°ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì—¬ì•¼ í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "í† í¬ë‚˜ì´ì €ëŠ” ì…ë ¥ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œë„ ë°›ì„ ìˆ˜ ìˆìœ¼ë©°, í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”©í•˜ê³  ì˜ë¼ë‚´ì–´ ì¼ì •í•œ ê¸¸ì´ì˜ ë¬¶ìŒì„ ë°˜í™˜í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "[ì „ì²˜ë¦¬](https://huggingface.co/docs/transformers/main/ko/./preprocessing) íŠœí† ë¦¬ì–¼ì„ ì°¸ì¡°í•˜ì‹œë©´ í† í°í™”ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ì™€ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì„ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•œ [AutoImageProcessor](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoImageProcessor)ì™€ [AutoFeatureExtractor](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoFeatureExtractor), [AutoProcessor](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoProcessor)ì˜ ì‚¬ìš©ë°©ë²•ë„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoModel [[automodel]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤— TransformersëŠ” ì‚¬ì „ í›ˆë ¨ëœ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°„ë‹¨í•˜ê³  í†µí•©ëœ ë°©ë²•ìœ¼ë¡œ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, [AutoTokenizer](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoTokenizer)ì²˜ëŸ¼ [TFAutoModel](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.TFAutoModel)ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ ì¼í•œ ì°¨ì´ì ì€ ê³¼ì—…ì— ì•Œë§ì€ [TFAutoModel](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.TFAutoModel)ì„ ì„ íƒí•´ì•¼ í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ (ë˜ëŠ” ì‹œí€€ìŠ¤) ë¶„ë¥˜ì˜ ê²½ìš° [TFAutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.TFAutoModelForSequenceClassification)ì„ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "[AutoModel](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoModel) í´ë˜ìŠ¤ì—ì„œ ì§€ì›í•˜ëŠ” ê³¼ì—…ì— ëŒ€í•´ì„œëŠ” [ê³¼ì—… ìš”ì•½](https://huggingface.co/docs/transformers/main/ko/./task_summary)ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì´ì œ ì „ì²˜ë¦¬ëœ ì…ë ¥ ë¬¶ìŒì„ ì§ì ‘ ëª¨ë¸ì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ì•„ë˜ì²˜ëŸ¼ ê·¸ëŒ€ë¡œ í…ì„œë¥¼ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_outputs = tf_model(tf_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì˜ ìµœì¢… í™œì„±í™” í•¨ìˆ˜ ì¶œë ¥ì€ `logits` ì†ì„±ì— ë‹´ê²¨ìˆìŠµë‹ˆë‹¤. `logits`ì— softmax í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í™•ë¥ ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n",
    "tf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ëª¨ë“  ğŸ¤— Transformers ëª¨ë¸(PyTorch ë˜ëŠ” TensorFlow)ì€ (softmaxì™€ ê°™ì€) ìµœì¢… í™œì„±í™” í•¨ìˆ˜ *ì´ì „ì—* í…ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ìµœì¢… í™œì„±í™” í•¨ìˆ˜ì˜ ì¶œë ¥ì€ ì¢…ì¢… ì†ì‹¤ í•¨ìˆ˜ ì¶œë ¥ê³¼ ê²°í•©ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ëª¨ë¸ ì¶œë ¥ì€ íŠ¹ìˆ˜í•œ ë°ì´í„° í´ë˜ìŠ¤ì´ë¯€ë¡œ IDEì—ì„œ ìë™ ì™„ì„±ë©ë‹ˆë‹¤. ëª¨ë¸ ì¶œë ¥ì€ íŠœí”Œì´ë‚˜ ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ ë™ì‘í•˜ë©° (ì •ìˆ˜, ìŠ¬ë¼ì´ìŠ¤ ë˜ëŠ” ë¬¸ìì—´ë¡œ ì¸ë±ì‹± ê°€ëŠ¥), Noneì¸ ì†ì„±ì€ ë¬´ì‹œë©ë‹ˆë‹¤.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì €ì¥í•˜ê¸° [[save-a-model]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ì„ í† í¬ë‚˜ì´ì €ì™€ í•¨ê»˜ ì €ì¥í•˜ë ¤ë©´ [TFPreTrainedModel.save_pretrained()](https://huggingface.co/docs/transformers/main/ko/main_classes/model#transformers.TFPreTrainedModel.save_pretrained)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_save_directory = \"./tf_save_pretrained\"\n",
    "tokenizer.save_pretrained(tf_save_directory)\n",
    "tf_model.save_pretrained(tf_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì„ ë‹¤ì‹œ ì‚¬ìš©í•˜ë ¤ë©´ [TFPreTrainedModel.from_pretrained()](https://huggingface.co/docs/transformers/main/ko/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤— Transformersì˜ ë©‹ì§„ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” ëª¨ë¸ì„ PyTorch ë˜ëŠ” TensorFlow ëª¨ë¸ë¡œ ì €ì¥í•´ë’€ë‹¤ê°€ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ë¡œ ë‹¤ì‹œ ë¡œë“œí•  ìˆ˜ ìˆëŠ” ì ì…ë‹ˆë‹¤. `from_pt` ë˜ëŠ” `from_tf` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•œ í”„ë ˆì„ì›Œí¬ì—ì„œ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì»¤ìŠ¤í…€ ëª¨ë¸ êµ¬ì¶•í•˜ê¸° [[custom-model-builds]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì˜ êµ¬ì„± í´ë˜ìŠ¤ë¥¼ ìˆ˜ì •í•˜ì—¬ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì€ë‹‰ì¸µì´ë‚˜ ì–´í…ì…˜ í—¤ë“œì˜ ìˆ˜ì™€ ê°™ì€) ëª¨ë¸ì˜ ì†ì„±ì€ êµ¬ì„±ì—ì„œ ì§€ì •ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì»¤ìŠ¤í…€ êµ¬ì„± í´ë˜ìŠ¤ë¡œ ëª¨ë¸ì„ ë§Œë“¤ë©´ ì²˜ìŒë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë¸ ì†ì„±ì€ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ë˜ë¯€ë¡œ ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € [AutoConfig](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoConfig)ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆ˜ì •í•˜ê³  ì‹¶ì€ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”. [AutoConfig.from_pretrained()](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoConfig.from_pretrained) ë‚´ë¶€ì—ì„œ (ì–´í…ì…˜ í—¤ë“œ ìˆ˜ì™€ ê°™ì´) ë³€ê²½í•˜ë ¤ëŠ” ì†ì„±ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TFAutoModel.from_config()](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoModel.from_config)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°”ê¾¼ êµ¬ì„±ëŒ€ë¡œ ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "my_model = TFAutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì»¤ìŠ¤í…€ êµ¬ì„±ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì»¤ìŠ¤í…€ ì•„í‚¤í…ì²˜ ë§Œë“¤ê¸°](https://huggingface.co/docs/transformers/main/ko/./create_a_model) ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer - PyTorchì— ìµœì í™”ëœ í›ˆë ¨ ë£¨í”„ [[trainer-a-pytorch-optimized-training-loop]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  ëª¨ë¸ì€ [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)ì´ë¯€ë¡œ ì¼ë°˜ì ì¸ í›ˆë ¨ ë£¨í”„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ì ‘ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•  ìˆ˜ë„ ìˆì§€ë§Œ, ğŸ¤— TransformersëŠ” PyTorchë¥¼ ìœ„í•œ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer) í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ í´ë˜ìŠ¤ì—ëŠ” ê¸°ë³¸ í›ˆë ¨ ë£¨í”„ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©° ë¶„ì‚° í›ˆë ¨, í˜¼í•© ì •ë°€ë„ ë“±ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì¶”ê°€ë¡œ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ê³¼ì—…ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ì— ë‹¤ìŒ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. [PreTrainedModel](https://huggingface.co/docs/transformers/main/ko/main_classes/model#transformers.PreTrainedModel) ë˜ëŠ” [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)ë¡œ ì‹œì‘í•©ë‹ˆë‹¤:\n",
    "\n",
    "   ```py\n",
    "   >>> from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "   >>> model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "   ```\n",
    "\n",
    "2. [TrainingArguments](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.TrainingArguments)ëŠ” í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, í›ˆë ¨í•  ì—í¬í¬ ìˆ˜ì™€ ê°™ì€ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. í›ˆë ¨ ì¸ìë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì´ ì‚¬ìš©ë©ë‹ˆë‹¤:\n",
    "\n",
    "   ```py\n",
    "   >>> from transformers import TrainingArguments\n",
    "\n",
    "   >>> training_args = TrainingArguments(\n",
    "   ...     output_dir=\"path/to/save/folder/\",\n",
    "   ...     learning_rate=2e-5,\n",
    "   ...     per_device_train_batch_size=8,\n",
    "   ...     per_device_eval_batch_size=8,\n",
    "   ...     num_train_epochs=2,\n",
    "   ... )\n",
    "   ```\n",
    "\n",
    "3. í† í¬ë‚˜ì´ì €, ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ, íŠ¹ì§• ì¶”ì¶œê¸°(feature extractor) ë˜ëŠ” í”„ë¡œì„¸ì„œì™€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ ë¡œë“œí•˜ì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> from transformers import AutoTokenizer\n",
    "\n",
    "   >>> tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "   ```\n",
    "\n",
    "4. ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> from datasets import load_dataset\n",
    "\n",
    "   >>> dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT\n",
    "   ```\n",
    "\n",
    "5. ë°ì´í„°ì…‹ì„ í† í°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•˜ì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> def tokenize_dataset(dataset):\n",
    "   ...     return tokenizer(dataset[\"text\"])\n",
    "   ```\n",
    "\n",
    "   ê·¸ë¦¬ê³  `map`ë¡œ ë°ì´í„°ì…‹ ì „ì²´ì— ì ìš©í•˜ì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> dataset = dataset.map(tokenize_dataset, batched=True)\n",
    "   ```\n",
    "\n",
    "6. [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/ko/main_classes/data_collator#transformers.DataCollatorWithPadding)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì˜ í‘œë³¸ ë¬¶ìŒì„ ë§Œë“œì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> from transformers import DataCollatorWithPadding\n",
    "\n",
    "   >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "   ```\n",
    "\n",
    "ì´ì œ ìœ„ì˜ ëª¨ë“  í´ë˜ìŠ¤ë¥¼ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ë¡œ ëª¨ìœ¼ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¤€ë¹„ê°€ ë˜ì—ˆìœ¼ë©´ [train()](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer.train)ì„ í˜¸ì¶œí•˜ì—¬ í›ˆë ¨ì„ ì‹œì‘í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ë²ˆì—­ì´ë‚˜ ìš”ì•½ê³¼ ê°™ì´ ì‹œí€€ìŠ¤-ì‹œí€€ìŠ¤ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê³¼ì—…ì—ëŠ” [Seq2SeqTrainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Seq2SeqTrainer) ë° [Seq2SeqTrainingArguments](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Seq2SeqTrainingArguments) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "[Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer) ë‚´ì˜ ë©”ì„œë“œë¥¼ ì„œë¸Œí´ë˜ìŠ¤í™”í•˜ì—¬ í›ˆë ¨ ë£¨í”„ë¥¼ ë°”ê¿€ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬ë©´ ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ê°™ì€ ê¸°ëŠ¥ ë˜í•œ ë°”ê¿€ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ë³€ê²½ ê°€ëŠ¥í•œ ë©”ì†Œë“œì— ëŒ€í•´ì„œëŠ” [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer) ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
    "\n",
    "í›ˆë ¨ ë£¨í”„ë¥¼ ìˆ˜ì •í•˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ì€ [Callbacks](https://huggingface.co/docs/transformers/main/ko/./main_classes/callback)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Callbacksë¡œ ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í†µí•©í•˜ê³ , í›ˆë ¨ ë£¨í”„ë¥¼ ì²´í¬í•˜ì—¬ ì§„í–‰ ìƒí™©ì„ ë³´ê³ ë°›ê±°ë‚˜, í›ˆë ¨ì„ ì¡°ê¸°ì— ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Callbacksì€ í›ˆë ¨ ë£¨í”„ ìì²´ë¥¼ ë°”ê¾¸ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ì†ì‹¤ í•¨ìˆ˜ì™€ ê°™ì€ ê²ƒì„ ë°”ê¾¸ë ¤ë©´ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ë¥¼ ì„œë¸Œí´ë˜ìŠ¤í™”í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlowë¡œ í›ˆë ¨ì‹œí‚¤ê¸° [[train-with-tensorflow]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  ëª¨ë¸ì€ [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)ì´ë¯€ë¡œ [Keras](https://keras.io/) APIë¥¼ í†µí•´ TensorFlowì—ì„œ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ¤— TransformersëŠ” ë°ì´í„°ì…‹ì„ ì‰½ê²Œ `tf.data.Dataset` í˜•íƒœë¡œ ì‰½ê²Œ ë¡œë“œí•  ìˆ˜ ìˆëŠ” [prepare_tf_dataset()](https://huggingface.co/docs/transformers/main/ko/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) ë©”ì†Œë“œë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì—, Kerasì˜ [`compile`](https://keras.io/api/models/model_training_apis/#compile-method) ë° [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) ë©”ì†Œë“œë¡œ ë°”ë¡œ í›ˆë ¨ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. [TFPreTrainedModel](https://huggingface.co/docs/transformers/main/ko/main_classes/model#transformers.TFPreTrainedModel) ë˜ëŠ” [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)ë¡œ ì‹œì‘í•©ë‹ˆë‹¤:\n",
    "\n",
    "   ```py\n",
    "   >>> from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "   >>> model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "   ```\n",
    "\n",
    "2. í† í¬ë‚˜ì´ì €, ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ, íŠ¹ì§• ì¶”ì¶œê¸°(feature extractor) ë˜ëŠ” í”„ë¡œì„¸ì„œì™€ ê°™ì€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ ë¡œë“œí•˜ì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> from transformers import AutoTokenizer\n",
    "\n",
    "   >>> tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "   ```\n",
    "\n",
    "3. ë°ì´í„°ì…‹ì„ í† í°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•˜ì„¸ìš”:\n",
    "\n",
    "   ```py\n",
    "   >>> def tokenize_dataset(dataset):\n",
    "   ...     return tokenizer(dataset[\"text\"])  # doctest: +SKIP\n",
    "   ```\n",
    "\n",
    "4. `map`ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ì— í† í°í™” í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê³ , ë°ì´í„°ì…‹ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ [prepare_tf_dataset()](https://huggingface.co/docs/transformers/main/ko/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)ì— ì „ë‹¬í•˜ì„¸ìš”. ë°°ì¹˜ í¬ê¸°ë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ë°ì´í„°ì…‹ì„ ì„ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "   ```py\n",
    "   >>> dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP\n",
    "   >>> tf_dataset = model.prepare_tf_dataset(\n",
    "   ...     dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer\n",
    "   ... )  # doctest: +SKIP\n",
    "   ```\n",
    "\n",
    "5. ì¤€ë¹„ë˜ì—ˆìœ¼ë©´ `compile` ë° `fit`ë¥¼ í˜¸ì¶œí•˜ì—¬ í›ˆë ¨ì„ ì‹œì‘í•˜ì„¸ìš”. ğŸ¤— Transformersì˜ ëª¨ë“  ëª¨ë¸ì€ ê³¼ì—…ê³¼ ê´€ë ¨ëœ ê¸°ë³¸ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤:\n",
    "\n",
    "   ```py\n",
    "   >>> from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "   >>> model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "   >>> model.fit(tf_dataset)  # doctest: +SKIP\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”? [[whats-next]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤— Transformers ë‘˜ëŸ¬ë³´ê¸°ë¥¼ ëª¨ë‘ ì½ìœ¼ì…¨ë‹¤ë©´, ê°€ì´ë“œë¥¼ ì‚´í´ë³´ê³  ë” êµ¬ì²´ì ì¸ ê²ƒì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”. ì´ë¥¼í…Œë©´ ì»¤ìŠ¤í…€ ëª¨ë¸ êµ¬ì¶•í•˜ëŠ” ë°©ë²•, ê³¼ì—…ì— ì•Œë§ê²Œ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•˜ëŠ” ë°©ë²•, ìŠ¤í¬ë¦½íŠ¸ë¡œ ëª¨ë¸ í›ˆë ¨í•˜ëŠ” ë°©ë²• ë“±ì´ ìˆìŠµë‹ˆë‹¤. ğŸ¤— Transformers í•µì‹¬ ê°œë…ì— ëŒ€í•´ ë” ì•Œì•„ë³´ë ¤ë©´ ì»¤í”¼ í•œ ì” ë“¤ê³  ê°œë… ê°€ì´ë“œë¥¼ ì‚´í´ë³´ì„¸ìš”!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
