{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
    "! pip install transformers datasets evaluate accelerate\n",
    "# ë§ˆì§€ë§‰ ë¦´ë¦¬ìŠ¤ ëŒ€ì‹  ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•˜ë ¤ë©´, ìœ„ ëª…ë ¹ì„ ì£¼ì„ìœ¼ë¡œ ë°”ê¾¸ê³  ì•„ë˜ ëª…ë ¹ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì˜¤ë””ì˜¤ ë¶„ë¥˜[[audio_classification]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KWwzcmG98Ds?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KWwzcmG98Ds?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ë””ì˜¤ ë¶„ë¥˜ëŠ” í…ìŠ¤íŠ¸ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì…ë ¥ ë°ì´í„°ì— í´ë˜ìŠ¤ ë ˆì´ë¸” ì¶œë ¥ì„ í• ë‹¹í•©ë‹ˆë‹¤. ìœ ì¼í•œ ì°¨ì´ì ì€ í…ìŠ¤íŠ¸ ì…ë ¥ ëŒ€ì‹  ì›ì‹œ ì˜¤ë””ì˜¤ íŒŒí˜•ì´ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ë¶„ë¥˜ì˜ ì‹¤ì œ ì ìš© ë¶„ì•¼ì—ëŠ” í™”ìì˜ ì˜ë„ íŒŒì•…, ì–¸ì–´ ë¶„ë¥˜, ì†Œë¦¬ë¡œ ë™ë¬¼ ì¢…ì„ ì‹ë³„í•˜ëŠ” ê²ƒ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë¬¸ì„œì—ì„œ ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ë°ì´í„° ì„¸íŠ¸ë¥¼ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ í™”ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "2. ì¶”ë¡ ì— ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ì´ ì‘ì—…ê³¼ í˜¸í™˜ë˜ëŠ” ëª¨ë“  ì•„í‚¤í…ì²˜ì™€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³´ë ¤ë©´ [ì‘ì—… í˜ì´ì§€](https://huggingface.co/tasks/audio-classification)ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:\n",
    "\n",
    "```bash\n",
    "pip install transformers datasets evaluate\n",
    "```\n",
    "\n",
    "ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•  ìˆ˜ ìˆë„ë¡ í—ˆê¹…í˜ì´ìŠ¤ ê³„ì •ì— ë¡œê·¸ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë©´ í† í°ì„ ì…ë ¥í•˜ì—¬ ë¡œê·¸ì¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MInDS-14 ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°[[load_minds_14_dataset]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì € ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ MinDS-14 ë°ì´í„° ì„¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì„¸íŠ¸ì˜ `train` ë¶„í• ì„ `train_test_split` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì‘ì€ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì§‘í•©ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì— ë” ë§ì€ ì‹œê°„ì„ ì†Œë¹„í•˜ê¸° ì „ì— ëª¨ë“  ê²ƒì´ ì‘ë™í•˜ëŠ”ì§€ ì‹¤í—˜í•˜ê³  í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë°ì´í„° ì§‘í•©ì„ ì‚´í´ë³¼ê²Œìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì„¸íŠ¸ì—ëŠ” `lang_id` ë° `english_transcription`ê³¼ ê°™ì€ ìœ ìš©í•œ ì •ë³´ê°€ ë§ì´ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ ì´ ê°€ì´ë“œì—ì„œëŠ” `audio` ë° `intent_class`ì— ì¤‘ì ì„ ë‘˜ ê²ƒì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì€ `remove_columns` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œê±°í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì‹œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,\n",
       "         -0.00024414, -0.00024414], dtype=float32),\n",
       "  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n",
       "  'sampling_rate': 8000},\n",
       " 'intent_class': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‘ ê°œì˜ í•„ë“œê°€ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- `audio`: ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì ¸ì˜¤ê³  ë¦¬ìƒ˜í”Œë§í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” ìŒì„± ì‹ í˜¸ì˜ 1ì°¨ì› `ë°°ì—´`ì…ë‹ˆë‹¤.\n",
    "- `intent_class`: í™”ìì˜ ì˜ë„ì— ëŒ€í•œ í´ë˜ìŠ¤ IDë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì´ ë ˆì´ë¸” IDì—ì„œ ë ˆì´ë¸” ì´ë¦„ì„ ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ ë ˆì´ë¸” ì´ë¦„ì„ ì •ìˆ˜ë¡œ ë§¤í•‘í•˜ëŠ” ì‚¬ì „ì„ ë§Œë“¤ê±°ë‚˜ ê·¸ ë°˜ëŒ€ë¡œ ë§¤í•‘í•˜ëŠ” ì‚¬ì „ì„ ë§Œë“­ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = minds[\"train\"].features[\"intent_class\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë ˆì´ë¸” IDë¥¼ ë ˆì´ë¸” ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app_error'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label[str(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì „ì²˜ë¦¬[[preprocess]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ë‹¨ê³„ëŠ” ì˜¤ë””ì˜¤ ì‹ í˜¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ Wav2Vec2 íŠ¹ì§• ì¶”ì¶œê¸°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ì†ë„ëŠ” 8khzì´ë¯€ë¡œ(ì´ ì •ë³´ëŠ” [ë°ì´í„°ì„¸íŠ¸ ì¹´ë“œ](https://huggingface.co/datasets/PolyAI/minds14)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤), ì‚¬ì „ í›ˆë ¨ëœ Wav2Vec2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë°ì´í„° ì„¸íŠ¸ë¥¼ 16kHzë¡œ ë¦¬ìƒ˜í”Œë§í•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,\n",
       "         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),\n",
       "  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n",
       "  'sampling_rate': 16000},\n",
       " 'intent_class': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤:\n",
    "\n",
    "1. ê°€ì ¸ì˜¬ `ì˜¤ë””ì˜¤` ì—´ì„ í˜¸ì¶œí•˜ê³  í•„ìš”í•œ ê²½ìš° ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤.\n",
    "2. ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ìƒ˜í”Œë§ ì†ë„ê°€ ëª¨ë¸ì— ì‚¬ì „ í›ˆë ¨ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ìƒ˜í”Œë§ ì†ë„ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì´ ì •ë³´ëŠ” Wav2Vec2 [ëª¨ë¸ ì¹´ë“œ](https://huggingface.co/facebook/wav2vec2-base)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "3. ê¸´ ì…ë ¥ì´ ì˜ë¦¬ì§€ ì•Šê³  ì¼ê´„ ì²˜ë¦¬ë˜ë„ë¡ ìµœëŒ€ ì…ë ¥ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì— ì „ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì ìš©í•˜ë ¤ë©´ ğŸ¤— Datasets `map` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. `batched=True`ë¥¼ ì„¤ì •í•˜ì—¬ ë°ì´í„° ì§‘í•©ì˜ ì—¬ëŸ¬ ìš”ì†Œë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë©´ `map`ì˜ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ì§€ ì•Šì€ ì—´ì„ ì œê±°í•˜ê³  `intent_class`ì˜ ì´ë¦„ì„ ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” ì´ë¦„ì¸ `label`ë¡œ ë³€ê²½í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
    "encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í‰ê°€í•˜ê¸°[[evaluate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ì¤‘ì— ë©”íŠ¸ë¦­ì„ í¬í•¨í•˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ ë°©ë²•ì„ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì—ì„œëŠ” [accuracy(ì •í™•ë„)](https://huggingface.co/spaces/evaluate-metric/accuracy) ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜µë‹ˆë‹¤(ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¤ê³  ê³„ì‚°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ğŸ¤— Evalutate [ë¹ ë¥¸ ë‘˜ëŸ¬ë³´ê¸°](https://huggingface.co/docs/evaluate/a_quick_tour) ì°¸ì¡°í•˜ì„¸ìš”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ° ë‹¤ìŒ ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì„ `compute`ì— ì „ë‹¬í•˜ì—¬ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ `compute_metrics` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìœ¼ë©°, íŠ¸ë ˆì´ë‹ì„ ì„¤ì •í•  ë•Œ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í›ˆë ¨[[train]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "[Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë° ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ [ì—¬ê¸°](https://huggingface.co/docs/transformers/main/ko/tasks/../training#train-with-pytorch-trainer)ì„ ì‚´í´ë³´ì„¸ìš”!\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ì´ì œ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤! [AutoModelForAudioClassification](https://huggingface.co/docs/transformers/main/ko/model_doc/auto#transformers.AutoModelForAudioClassification)ì„ ì´ìš©í•´ì„œ Wav2Vec2ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì˜ˆìƒë˜ëŠ” ë ˆì´ë¸” ìˆ˜ì™€ ë ˆì´ë¸” ë§¤í•‘ì„ ì§€ì •í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì„¸ ë‹¨ê³„ë§Œ ë‚¨ì•˜ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ [TrainingArguments](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.TrainingArguments)ì— ì •ì˜í•©ë‹ˆë‹¤. ìœ ì¼í•œ í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ëŠ” ëª¨ë¸ì„ ì €ì¥í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ëŠ” `output_dir`ì…ë‹ˆë‹¤. `push_to_hub = True`ë¥¼ ì„¤ì •í•˜ì—¬ ì´ ëª¨ë¸ì„ í—ˆë¸Œë¡œ í‘¸ì‹œí•©ë‹ˆë‹¤(ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ í—ˆê¹… í˜ì´ìŠ¤ì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤). ê° ì—í­ì´ ëë‚  ë•Œë§ˆë‹¤ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ê°€ ì •í™•ë„ë¥¼ í‰ê°€í•˜ê³  í›ˆë ¨ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "2. ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸, í† í¬ë‚˜ì´ì €, ë°ì´í„° ì½œë ˆì´í„°, `compute_metrics` í•¨ìˆ˜ì™€ í•¨ê»˜ í›ˆë ¨ ì¸ìë¥¼ [Trainer](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer)ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "3. [train()](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer.train)ì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_mind_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    warmup_steps=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_minds[\"train\"],\n",
    "    eval_dataset=encoded_minds[\"test\"],\n",
    "    processing_class=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ëª¨ë“  ì‚¬ëŒì´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ [push_to_hub()](https://huggingface.co/docs/transformers/main/ko/main_classes/trainer#transformers.Trainer.push_to_hub) ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í—ˆë¸Œì— ê³µìœ í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "For a more in-depth example of how to finetune a model for audio classification, take a look at the corresponding [PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb).\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¶”ë¡ [[inference]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í–ˆìœ¼ë‹ˆ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì¶”ë¡ ì„ ì‹¤í–‰í•  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ìƒ˜í”Œë§ ì†ë„ë¥¼ ëª¨ë¸ì˜ ìƒ˜í”Œë§ ì†ë„ì™€ ì¼ì¹˜í•˜ë„ë¡ ë¦¬ìƒ˜í”Œë§í•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "audio_file = dataset[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸ì„ ì‹œí—˜í•´ ë³´ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ `pipeline()`ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ `pipeline`ì„ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ê³  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ë‹¬í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "    {'score': 0.09766869246959686, 'label': 'cash_deposit'},\n",
       "    {'score': 0.07998877018690109, 'label': 'app_error'},\n",
       "    {'score': 0.0781070664525032, 'label': 'joint_account'},\n",
       "    {'score': 0.07667109370231628, 'label': 'pay_bill'},\n",
       "    {'score': 0.0755252093076706, 'label': 'balance'}\n",
       "]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"audio-classification\", model=\"stevhliu/my_awesome_minds_model\")\n",
    "classifier(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì›í•˜ëŠ” ê²½ìš° `pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "íŠ¹ì§• ì¶”ì¶œê¸°ë¥¼ ê°€ì ¸ì™€ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ì²˜ë¦¬í•˜ê³  `ì…ë ¥`ì„ PyTorch í…ì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì— ì…ë ¥ì„ ì „ë‹¬í•˜ê³  ë¡œì§“ì„ ë°˜í™˜í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í™•ë¥ ì´ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜¨ ë‹¤ìŒ ëª¨ë¸ì˜ `id2label` ë§¤í•‘ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ë ˆì´ë¸”ë¡œ ë³€í™˜í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cash_deposit'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits).item()\n",
    "predicted_label = model.config.id2label[predicted_class_ids]\n",
    "predicted_label"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
