{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç”¨äº TensorFlow æ¨¡å‹çš„ XLA é›†æˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ é€Ÿçº¿æ€§ä»£æ•°ï¼Œä¹Ÿç§°ä¸ºXLAï¼Œæ˜¯ä¸€ä¸ªç”¨äºåŠ é€ŸTensorFlowæ¨¡å‹è¿è¡Œæ—¶é—´çš„ç¼–è¯‘å™¨ã€‚ä»[å®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/xla)ä¸­å¯ä»¥çœ‹åˆ°ï¼š\n",
    "\n",
    "XLAï¼ˆåŠ é€Ÿçº¿æ€§ä»£æ•°ï¼‰æ˜¯ä¸€ç§é’ˆå¯¹çº¿æ€§ä»£æ•°çš„ç‰¹å®šé¢†åŸŸç¼–è¯‘å™¨ï¼Œå¯ä»¥åœ¨å¯èƒ½ä¸éœ€è¦æ›´æ”¹æºä»£ç çš„æƒ…å†µä¸‹åŠ é€ŸTensorFlowæ¨¡å‹ã€‚\n",
    "\n",
    "åœ¨TensorFlowä¸­ä½¿ç”¨XLAéå¸¸ç®€å•â€”â€”å®ƒåŒ…å«åœ¨`tensorflow`åº“ä¸­ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨ä»»ä½•å›¾åˆ›å»ºå‡½æ•°ä¸­çš„`jit_compile`å‚æ•°æ¥è§¦å‘ï¼Œä¾‹å¦‚[`tf.function`](https://www.tensorflow.org/guide/intro_to_graphs)ã€‚åœ¨ä½¿ç”¨Kerasæ–¹æ³•å¦‚`fit()`å’Œ`predict()`æ—¶ï¼Œåªéœ€å°†`jit_compile`å‚æ•°ä¼ é€’ç»™`model.compile()`å³å¯å¯ç”¨XLAã€‚ç„¶è€Œï¼ŒXLAä¸ä»…é™äºè¿™äº›æ–¹æ³• - å®ƒè¿˜å¯ä»¥ç”¨äºåŠ é€Ÿä»»ä½•ä»»æ„çš„`tf.function`ã€‚\n",
    "\n",
    "åœ¨ğŸ¤— Transformersä¸­ï¼Œå‡ ä¸ªTensorFlowæ–¹æ³•å·²ç»è¢«é‡å†™ä¸ºä¸XLAå…¼å®¹ï¼ŒåŒ…æ‹¬[GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)ã€[T5](https://huggingface.co/docs/transformers/model_doc/t5)å’Œ[OPT](https://huggingface.co/docs/transformers/model_doc/opt)ç­‰æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œä»¥åŠ[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)ç­‰è¯­éŸ³å¤„ç†æ¨¡å‹ã€‚\n",
    "\n",
    "è™½ç„¶ç¡®åˆ‡çš„åŠ é€Ÿå€æ•°å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ¨¡å‹ï¼Œä½†å¯¹äºğŸ¤— Transformersä¸­çš„TensorFlowæ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°é€Ÿåº¦æé«˜äº†çº¦100å€ã€‚æœ¬æ–‡æ¡£å°†è§£é‡Šå¦‚ä½•åœ¨è¿™äº›æ¨¡å‹ä¸Šä½¿ç”¨XLAè·å¾—æœ€å¤§çš„æ€§èƒ½ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šå…³äºåŸºå‡†æµ‹è¯•å’Œæˆ‘ä»¬åœ¨XLAé›†æˆèƒŒåçš„è®¾è®¡å“²å­¦çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬è¿˜å°†æä¾›é¢å¤–çš„èµ„æºé“¾æ¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ XLA è¿è¡Œ TensorFlow å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬è€ƒè™‘ä»¥ä¸‹TensorFlow ä¸­çš„æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [tf.keras.layers.Dense(10, input_shape=(10,), activation=\"relu\"), tf.keras.layers.Dense(5, activation=\"softmax\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šè¿°æ¨¡å‹æ¥å—ç»´åº¦ä¸º `(10,)` çš„è¾“å…¥ã€‚æˆ‘ä»¬å¯ä»¥åƒä¸‹é¢è¿™æ ·ä½¿ç”¨æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random inputs for the model.\n",
    "batch_size = 16\n",
    "input_vector_dim = 10\n",
    "random_inputs = tf.random.normal((batch_size, input_vector_dim))\n",
    "\n",
    "# Run a forward pass.\n",
    "_ = model(random_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ä½¿ç”¨ XLA ç¼–è¯‘çš„å‡½æ•°è¿è¡Œå‰å‘ä¼ æ’­ï¼Œæˆ‘ä»¬éœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xla_fn = tf.function(model, jit_compile=True)\n",
    "_ = xla_fn(random_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model`çš„é»˜è®¤`call()`å‡½æ•°ç”¨äºç¼–è¯‘XLAå›¾ã€‚ä½†å¦‚æœä½ æƒ³å°†å…¶ä»–æ¨¡å‹å‡½æ•°ç¼–è¯‘æˆXLAï¼Œä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_xla_fn = tf.function(model.my_xla_fn, jit_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨ğŸ¤— Transformersåº“ä¸­ä½¿ç”¨XLAè¿è¡ŒTensorFlowæ–‡æœ¬ç”Ÿæˆæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦åœ¨ğŸ¤— Transformersä¸­å¯ç”¨XLAåŠ é€Ÿç”Ÿæˆï¼Œæ‚¨éœ€è¦å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„`transformers`ã€‚æ‚¨å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å®‰è£…å®ƒï¼š\n",
    "\n",
    "```bash\n",
    "pip install transformers --upgrade\n",
    "```\n",
    "\n",
    "ç„¶åæ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed.\n",
    "from transformers.utils import check_min_version\n",
    "\n",
    "check_min_version(\"4.21.0\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", padding_side=\"left\", pad_token=\"</s>\")\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "input_string = [\"TensorFlow is\"]\n",
    "\n",
    "# One line to create an XLA generation function\n",
    "xla_generate = tf.function(model.generate, jit_compile=True)\n",
    "\n",
    "tokenized_input = tokenizer(input_string, return_tensors=\"tf\")\n",
    "generated_tokens = xla_generate(**tokenized_input, num_beams=2)\n",
    "\n",
    "decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "print(f\"Generated -- {decoded_text}\")\n",
    "# Generated -- TensorFlow is an open-source, open-source, distributed-source application # framework for the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­£å¦‚æ‚¨æ‰€æ³¨æ„åˆ°çš„ï¼Œåœ¨`generate()`ä¸Šå¯ç”¨XLAåªéœ€è¦ä¸€è¡Œä»£ç ã€‚å…¶ä½™éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜ã€‚ç„¶è€Œï¼Œä¸Šé¢çš„ä»£ç ç‰‡æ®µä¸­æœ‰ä¸€äº›ä¸XLAç›¸å…³çš„æ³¨æ„äº‹é¡¹ã€‚æ‚¨éœ€è¦äº†è§£è¿™äº›æ³¨æ„äº‹é¡¹ï¼Œä»¥å……åˆ†åˆ©ç”¨XLAå¯èƒ½å¸¦æ¥çš„æ€§èƒ½æå‡ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢çš„éƒ¨åˆ†è®¨è®ºè¿™äº›å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## éœ€è¦å…³æ³¨çš„æ³¨æ„äº‹é¡¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“æ‚¨é¦–æ¬¡æ‰§è¡Œå¯ç”¨XLAçš„å‡½æ•°ï¼ˆå¦‚ä¸Šé¢çš„`xla_generate()`ï¼‰æ—¶ï¼Œå®ƒå°†åœ¨å†…éƒ¨å°è¯•æ¨æ–­è®¡ç®—å›¾ï¼Œè¿™æ˜¯ä¸€ä¸ªè€—æ—¶çš„è¿‡ç¨‹ã€‚è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸º[â€œtracingâ€](https://www.tensorflow.org/guide/intro_to_graphs#when_is_a_function_tracing)ã€‚\n",
    "\n",
    "æ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°ç”Ÿæˆæ—¶é—´å¹¶ä¸å¿«ã€‚è¿ç»­è°ƒç”¨`xla_generate()`ï¼ˆæˆ–ä»»ä½•å…¶ä»–å¯ç”¨äº†XLAçš„å‡½æ•°ï¼‰ä¸éœ€è¦å†æ¬¡æ¨æ–­è®¡ç®—å›¾ï¼Œåªè¦å‡½æ•°çš„è¾“å…¥ä¸æœ€åˆæ„å»ºè®¡ç®—å›¾æ—¶çš„å½¢çŠ¶ç›¸åŒ¹é…ã€‚å¯¹äºå…·æœ‰å›ºå®šè¾“å…¥å½¢çŠ¶çš„æ¨¡æ€ï¼ˆä¾‹å¦‚å›¾åƒï¼‰ï¼Œè¿™ä¸æ˜¯é—®é¢˜ï¼Œä½†å¦‚æœæ‚¨æ­£åœ¨å¤„ç†å…·æœ‰å¯å˜è¾“å…¥å½¢çŠ¶çš„æ¨¡æ€ï¼ˆä¾‹å¦‚æ–‡æœ¬ï¼‰ï¼Œåˆ™å¿…é¡»æ³¨æ„ã€‚\n",
    "\n",
    "ä¸ºäº†ç¡®ä¿`xla_generate()`å§‹ç»ˆä½¿ç”¨ç›¸åŒçš„è¾“å…¥å½¢çŠ¶ï¼Œæ‚¨å¯ä»¥åœ¨è°ƒç”¨`tokenizer`æ—¶æŒ‡å®š`padding`å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", padding_side=\"left\", pad_token=\"</s>\")\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "input_string = [\"TensorFlow is\"]\n",
    "\n",
    "xla_generate = tf.function(model.generate, jit_compile=True)\n",
    "\n",
    "# Here, we call the tokenizer with padding options.\n",
    "tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "generated_tokens = xla_generate(**tokenized_input, num_beams=2)\n",
    "decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "print(f\"Generated -- {decoded_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ‚¨å¯ä»¥ç¡®ä¿`xla_generate()`çš„è¾“å…¥å§‹ç»ˆå…·æœ‰å®ƒè·Ÿè¸ªçš„å½¢çŠ¶ï¼Œä»è€ŒåŠ é€Ÿç”Ÿæˆæ—¶é—´ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç æ¥éªŒè¯è¿™ä¸€ç‚¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", padding_side=\"left\", pad_token=\"</s>\")\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "xla_generate = tf.function(model.generate, jit_compile=True)\n",
    "\n",
    "for input_string in [\"TensorFlow is\", \"TensorFlow is a\", \"TFLite is a\"]:\n",
    "    tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors=\"tf\")\n",
    "    start = time.time_ns()\n",
    "    generated_tokens = xla_generate(**tokenized_input, num_beams=2)\n",
    "    end = time.time_ns()\n",
    "    print(f\"Execution time -- {(end - start) / 1e6:.1f} ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨Tesla T4 GPUä¸Šï¼Œæ‚¨å¯ä»¥æœŸæœ›å¦‚ä¸‹çš„è¾“å‡ºï¼š\n",
    "\n",
    "```bash\n",
    "Execution time -- 30819.6 ms\n",
    "\n",
    "Execution time -- 79.0 ms\n",
    "\n",
    "Execution time -- 78.9 ms\n",
    "```\n",
    "\n",
    "ç¬¬ä¸€æ¬¡è°ƒç”¨`xla_generate()`ä¼šå› ä¸º`tracing`è€Œè€—æ—¶ï¼Œä½†åç»­çš„è°ƒç”¨ä¼šå¿«å¾—å¤šã€‚è¯·æ³¨æ„ï¼Œä»»ä½•æ—¶å€™å¯¹ç”Ÿæˆé€‰é¡¹çš„æ›´æ”¹éƒ½ä¼šè§¦å‘é‡æ–°`tracing`ï¼Œä»è€Œå¯¼è‡´ç”Ÿæˆæ—¶é—´å‡æ…¢ã€‚\n",
    "\n",
    "åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰æ¶µç›–ğŸ¤— Transformersæä¾›çš„æ‰€æœ‰æ–‡æœ¬ç”Ÿæˆé€‰é¡¹ã€‚æˆ‘ä»¬é¼“åŠ±æ‚¨é˜…è¯»æ–‡æ¡£ä»¥äº†è§£é«˜çº§ç”¨ä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é™„åŠ èµ„æº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹æ˜¯ä¸€äº›é™„åŠ èµ„æºï¼Œå¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£åœ¨ğŸ¤— Transformerså’Œå…¶ä»–åº“ä¸‹ä½¿ç”¨XLAï¼š\n",
    "\n",
    "* [è¿™ä¸ªColab Notebook](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/91_tf_xla_generate.ipynb) æä¾›äº†ä¸€ä¸ªäº’åŠ¨æ¼”ç¤ºï¼Œè®©æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨XLAå…¼å®¹çš„ç¼–ç å™¨-è§£ç å™¨ï¼ˆä¾‹å¦‚[T5](https://huggingface.co/docs/transformers/model_doc/t5)ï¼‰å’Œä»…è§£ç å™¨ï¼ˆä¾‹å¦‚[GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)ï¼‰æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚\n",
    "\n",
    "* [è¿™ç¯‡åšå®¢æ–‡ç« ](https://huggingface.co/blog/tf-xla-generate) æä¾›äº†XLAå…¼å®¹æ¨¡å‹çš„æ¯”è¾ƒåŸºå‡†æ¦‚è¿°ï¼Œä»¥åŠå…³äºåœ¨TensorFlowä¸­ä½¿ç”¨XLAçš„å‹å¥½ä»‹ç»ã€‚\n",
    "\n",
    "* [è¿™ç¯‡åšå®¢æ–‡ç« ](https://blog.tensorflow.org/2022/11/how-hugging-face-improved-text-generation-performance-with-xla.html) è®¨è®ºäº†æˆ‘ä»¬åœ¨ğŸ¤— Transformersä¸­ä¸ºTensorFlowæ¨¡å‹æ·»åŠ XLAæ”¯æŒçš„è®¾è®¡ç†å¿µã€‚\n",
    "\n",
    "* æ¨èç”¨äºæ›´å¤šå­¦ä¹ XLAå’ŒTensorFlowå›¾çš„èµ„æºï¼š\n",
    "    * [XLAï¼šé¢å‘æœºå™¨å­¦ä¹ çš„ä¼˜åŒ–ç¼–è¯‘å™¨](https://www.tensorflow.org/xla)\n",
    "    * [å›¾å’Œtf.functionç®€ä»‹](https://www.tensorflow.org/guide/intro_to_graphs)\n",
    "    * [ä½¿ç”¨tf.functionè·å¾—æ›´å¥½çš„æ€§èƒ½](https://www.tensorflow.org/guide/function)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
