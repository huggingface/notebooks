{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å‰ã«ã€ãã‚Œã‚’ãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã™ã‚‹å…¥åŠ›å½¢å¼ã«å‰å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ãŒãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€ã¾ãŸã¯ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã§ã‚ã‚‹ã‹ã©ã†ã‹ã«ã‹ã‹ã‚ã‚‰ãšã€ãã‚Œã‚‰ã¯ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒãƒƒãƒã«å¤‰æ›ã—ã¦çµ„ã¿ç«‹ã¦ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ğŸ¤— Transformersã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«ç”¨ã«æº–å‚™ã™ã‚‹ã®ã«å½¹ç«‹ã¤å‰å‡¦ç†ã‚¯ãƒ©ã‚¹ã®ã‚»ãƒƒãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\n",
    "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€æ¬¡ã®ã“ã¨ã‚’å­¦ã³ã¾ã™ï¼š\n",
    "\n",
    "* ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã€[Tokenizer](https://huggingface.co/docs/transformers/main/ja/./main_classes/tokenizer)ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¤‰æ›ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æ•°å€¤è¡¨ç¾ã‚’ä½œæˆã—ã€ãã‚Œã‚‰ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«çµ„ã¿ç«‹ã¦ã‚‹æ–¹æ³•ã€‚\n",
    "* éŸ³å£°ã¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®å ´åˆã€[Feature extractor](https://huggingface.co/docs/transformers/main/ja/./main_classes/feature_extractor)ã‚’ä½¿ç”¨ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ³¢å½¢ã‹ã‚‰é€£ç¶šçš„ãªç‰¹å¾´ã‚’æŠ½å‡ºã—ã€ãã‚Œã‚‰ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã™ã‚‹æ–¹æ³•ã€‚\n",
    "* ç”»åƒå…¥åŠ›ã®å ´åˆã€[ImageProcessor](https://huggingface.co/docs/transformers/main/ja/./main_classes/image)ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã™ã‚‹æ–¹æ³•ã€‚\n",
    "* ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®å ´åˆã€[Processor](https://huggingface.co/docs/transformers/main/ja/./main_classes/processors)ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¨ç‰¹å¾´æŠ½å‡ºå™¨ã¾ãŸã¯ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã€‚\n",
    "\n",
    "<Tip>\n",
    "\n",
    "`AutoProcessor`ã¯å¸¸ã«å‹•ä½œã—ã€ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«é©åˆ‡ãªã‚¯ãƒ©ã‚¹ã‚’è‡ªå‹•çš„ã«é¸æŠã—ã¾ã™ã€‚\n",
    "ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã€ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã€ç‰¹å¾´æŠ½å‡ºå™¨ã€ã¾ãŸã¯ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ã«ã‹ã‹ã‚ã‚‰ãšã€å‹•ä½œã—ã¾ã™ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "å§‹ã‚ã‚‹å‰ã«ã€ğŸ¤— Datasetsã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã€ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è©¦ã™ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "```bash\n",
    "pip install datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Yffk5aydLzg?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Yffk5aydLzg?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«ä½¿ç”¨ã™ã‚‹ä¸»è¦ãªãƒ„ãƒ¼ãƒ«ã¯ã€[ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶](https://huggingface.co/docs/transformers/main/ja/main_classes/tokenizer)ã§ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯ã€ä¸€é€£ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’*ãƒˆãƒ¼ã‚¯ãƒ³*ã«åˆ†å‰²ã—ã¾ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã¯æ•°å€¤ã«å¤‰æ›ã•ã‚Œã€ãã®å¾Œãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨ãªã‚Šã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã¨ã™ã‚‹è¿½åŠ ã®å…¥åŠ›ã¯ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã«ã‚ˆã£ã¦è¿½åŠ ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "<Tip>\n",
    "\n",
    "äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹äºˆå®šã®å ´åˆã€é–¢é€£ã™ã‚‹äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆãŒäº‹å‰å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã¨åŒã˜æ–¹æ³•ã§åˆ†å‰²ã•ã‚Œã€äº‹å‰å­¦ç¿’ä¸­ã«é€šå¸¸*ãƒœã‚­ãƒ£ãƒ–*ã¨ã—ã¦å‚ç…§ã•ã‚Œã‚‹å¯¾å¿œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "[AutoTokenizer.from_pretrained()](https://huggingface.co/docs/transformers/main/ja/model_doc/auto#transformers.AutoTokenizer.from_pretrained)ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€é–‹å§‹ã—ã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒäº‹å‰å­¦ç¿’ã•ã‚ŒãŸ*ãƒœã‚­ãƒ£ãƒ–*ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã«æ¸¡ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯ã€é‡è¦ãª3ã¤ã®é …ç›®ã‚’æŒã¤è¾æ›¸ã‚’è¿”ã—ã¾ã™ï¼š\n",
    "\n",
    "* [input_ids](https://huggingface.co/docs/transformers/main/ja/glossary#input-ids) ã¯æ–‡ä¸­ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã™ã€‚\n",
    "* [attention_mask](https://huggingface.co/docs/transformers/main/ja/glossary#attention-mask) ã¯ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’å—ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "* [token_type_ids](https://huggingface.co/docs/transformers/main/ja/glossary#token-type-ids) ã¯è¤‡æ•°ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒã‚ã‚‹å ´åˆã€ãƒˆãƒ¼ã‚¯ãƒ³ãŒã©ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å±ã—ã¦ã„ã‚‹ã‹ã‚’è­˜åˆ¥ã—ã¾ã™ã€‚\n",
    "\n",
    "`input_ids` ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦å…¥åŠ›ã‚’è¿”ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] é­”æ³•ä½¿ã„ã®äº‹ã«å¹²æ¸‰ã™ã‚‹ãªã€å½¼ã‚‰ã¯å¾®å¦™ã§æ€’ã‚Šã£ã½ã„ã€‚ [SEP]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚ä½•ã«ãŠåˆ†ã‹ã‚Šã„ãŸã ã‘ã‚‹ã‹ã¨æ€ã„ã¾ã™ãŒã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯ã“ã®æ–‡ç« ã«2ã¤ã®ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³ã€`CLS`ï¼ˆã‚¯ãƒ©ã‚·ãƒ•ã‚¡ã‚¤ã‚¢ï¼‰ã¨`SEP`ï¼ˆã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ï¼‰ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚\n",
    "ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¿…è¦ã¨ã™ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€å¿…è¦ãªå ´åˆã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯è‡ªå‹•çš„ã«ãã‚Œã‚‰ã‚’è¿½åŠ ã—ã¾ã™ã€‚\n",
    "\n",
    "è¤‡æ•°ã®æ–‡ç« ã‚’å‰å‡¦ç†ã™ã‚‹å ´åˆã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã«ãƒªã‚¹ãƒˆã¨ã—ã¦æ¸¡ã—ã¦ãã ã•ã„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],\n",
       "               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n",
       "               [101, 1327, 1164, 5450, 23434, 136, 102]],\n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [0, 0, 0, 0, 0, 0, 0]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                    [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–‡ç« ã¯å¸¸ã«åŒã˜é•·ã•ã§ã¯ãªã„ã“ã¨ãŒã‚ã‚Šã€ã“ã‚Œã¯ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ï¼‰ãŒå‡ä¸€ãªå½¢çŠ¶ã‚’æŒã¤å¿…è¦ãŒã‚ã‚‹ãŸã‚å•é¡Œã¨ãªã‚Šã¾ã™ã€‚\n",
    "ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¯ã€çŸ­ã„æ–‡ã«ç‰¹åˆ¥ãªã€Œãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã€ã‚’è¿½åŠ ã—ã¦ã€ãƒ†ãƒ³ã‚½ãƒ«ã‚’é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆã‚ã›ã‚‹ãŸã‚ã®æˆ¦ç•¥ã§ã™ã€‚\n",
    "\n",
    "ãƒãƒƒãƒå†…ã®çŸ­ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æœ€é•·ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆã‚ã›ã‚‹ãŸã‚ã«ã€`padding`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’`True`ã«è¨­å®šã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n",
       "               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n",
       "               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ç•ªç›®ã¨3ç•ªç›®ã®æ–‡ã¯ã€çŸ­ã„ãŸã‚ã«`0`ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€†ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ã§ã¯ã€æ™‚æŠ˜ã€ãƒ¢ãƒ‡ãƒ«ãŒå‡¦ç†ã™ã‚‹ã®ã«é•·ã™ãã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã“ã®å ´åˆã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’çŸ­ç¸®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ãŒå—ã‘å…¥ã‚Œã‚‹æœ€å¤§ã®é•·ã•ã«ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ã«ã¯ã€`truncation`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’`True`ã«è¨­å®šã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n",
       "               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n",
       "               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ç•°ãªã‚‹ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¨åˆ‡ã‚Šè©°ã‚ã®å¼•æ•°ã«ã¤ã„ã¦è©³ã—ãã¯ã€[ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¨åˆ‡ã‚Šè©°ã‚](https://huggingface.co/docs/transformers/main/ja/./pad_truncation)ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚¬ã‚¤ãƒ‰ã‚’ã”è¦§ãã ã•ã„ã€‚\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãŒãƒ¢ãƒ‡ãƒ«ã«ä¾›çµ¦ã•ã‚Œã‚‹å®Ÿéš›ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã™ã‚ˆã†ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "\n",
    "`return_tensors`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’`pt`ï¼ˆPyTorchç”¨ï¼‰ã¾ãŸã¯`tf`ï¼ˆTensorFlowç”¨ï¼‰ã«è¨­å®šã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n",
       "                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n",
       "                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
       "array([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n",
       "       [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)>,\n",
       " 'token_type_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n",
       " 'attention_mask': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¿ã‚¹ã‚¯ã®å ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ç”¨ã«æº–å‚™ã™ã‚‹ãŸã‚ã«[ç‰¹å¾´æŠ½å‡ºå™¨](https://huggingface.co/docs/transformers/main/ja/main_classes/feature_extractor)ãŒå¿…è¦ã§ã™ã€‚\n",
    "ç‰¹å¾´æŠ½å‡ºå™¨ã¯ç”Ÿã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´ã‚’æŠ½å‡ºã—ã€ãã‚Œã‚‰ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "[PolyAI/minds14](https://huggingface.co/datasets/PolyAI/minds14)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ğŸ¤— [Datasetsãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/datasets/load_hub)ã‚’å‚ç…§ï¼‰ã€\n",
    "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ã©ã®ã‚ˆã†ã«ä½¿ç”¨ã§ãã‚‹ã‹ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦`audio`åˆ—ã®æœ€åˆã®è¦ç´ ã‚’ç¢ºèªã—ã¾ã™ã€‚`audio`åˆ—ã‚’å‘¼ã³å‡ºã™ã¨ã€è‡ªå‹•çš„ã«ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã€ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,\n",
       "         0.        ,  0.        ], dtype=float32),\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n",
       " 'sampling_rate': 8000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã«ã‚ˆã‚Šã€3ã¤ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒè¿”ã•ã‚Œã¾ã™ï¼š\n",
    "\n",
    "* `array` ã¯èª­ã¿è¾¼ã¾ã‚ŒãŸéŸ³å£°ä¿¡å·ã§ã€1Dã®é…åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚\n",
    "* `path` ã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã‚’æŒ‡ã—ã¾ã™ã€‚\n",
    "* `sampling_rate` ã¯éŸ³å£°ä¿¡å·å†…ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒ1ç§’é–“ã«ã„ãã¤æ¸¬å®šã•ã‚Œã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€[Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚’ç¢ºèªã™ã‚‹ã¨ã€Wav2Vec2ãŒ16kHzã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸéŸ³å£°ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã§äº‹å‰å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨ã€ã‚ãªãŸã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãŒä¸€è‡´ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãŒç•°ãªã‚‹å ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "1. ğŸ¤— Datasetsã® `cast_column` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã‚’16kHzã«ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. å†ã³ `audio` åˆ—ã‚’å‘¼ã³å‡ºã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚µãƒ³ãƒ—ãƒ«ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,\n",
       "         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€å…¥åŠ›ã‚’æ­£è¦åŒ–ã—ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹å ´åˆã€çŸ­ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«ã¯ `0` ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚åŒã˜è€ƒãˆæ–¹ãŒã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã«ã‚‚é©ç”¨ã•ã‚Œã¾ã™ã€‚ç‰¹å¾´æŠ½å‡ºå™¨ã¯ `array` ã« `0` ã‚’è¿½åŠ ã—ã¾ã™ï¼ˆã“ã‚Œã¯ç„¡éŸ³ã¨ã—ã¦è§£é‡ˆã•ã‚Œã¾ã™ï¼‰ã€‚\n",
    "\n",
    "[AutoFeatureExtractor.from_pretrained()](https://huggingface.co/docs/transformers/main/ja/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained)ã‚’ä½¿ç”¨ã—ã¦ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª `array` ã‚’ç‰¹å¾´æŠ½å‡ºå™¨ã«æ¸¡ã—ã¾ã™ã€‚ç‰¹å¾´æŠ½å‡ºå™¨ã§ç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ç„¡éŸ³ã‚¨ãƒ©ãƒ¼ã‚’ã‚ˆã‚Šè‰¯ããƒ‡ãƒãƒƒã‚°ã™ã‚‹ãŸã‚ã«ã€ç‰¹å¾´æŠ½å‡ºå™¨ã« `sampling_rate` å¼•æ•°ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,\n",
       "        5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_input = [dataset[0][\"audio\"][\"array\"]]\n",
    "feature_extractor(audio_input, sampling_rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŒæ§˜ã«ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¨åŒæ§˜ã«ã€ãƒãƒƒãƒå†…ã®å¯å¤‰ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯åˆ‡ã‚Šè©°ã‚ã‚’é©ç”¨ã§ãã¾ã™ã€‚æ¬¡ã«ã€ã“ã‚Œã‚‰ã®2ã¤ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚µãƒ³ãƒ—ãƒ«ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173398,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106496,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®é–¢æ•°ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å‰å‡¦ç†ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚µãƒ³ãƒ—ãƒ«ã®é•·ã•ã‚’åŒã˜ã«ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«é•·ã‚’æŒ‡å®šã—ã€ç‰¹å¾´æŠ½å‡ºå™¨ã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãã‚Œã«åˆã‚ã›ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯åˆ‡ã‚Šè©°ã‚ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        max_length=100000,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`preprocess_function`ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æœ€åˆã®æ•°ä¾‹ã«é©ç”¨ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = preprocess_function(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚µãƒ³ãƒ—ãƒ«ã®é•·ã•ã¯ç¾åœ¨åŒã˜ã§ã€æŒ‡å®šã•ã‚ŒãŸæœ€å¤§é•·ã¨ä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã§å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[\"input_values\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[\"input_values\"][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ãŸã‚ã®[ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µ](https://huggingface.co/docs/transformers/main/ja/main_classes/image_processor)ãŒå¿…è¦ã§ã™ã€‚\n",
    "ç”»åƒã®å‰å‡¦ç†ã«ã¯ã€ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹å…¥åŠ›å½¢å¼ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã„ãã¤ã‹ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã¯ã€ãƒªã‚µã‚¤ã‚ºã€æ­£è¦åŒ–ã€ã‚«ãƒ©ãƒ¼ãƒãƒ£ãƒãƒ«ã®è£œæ­£ã€ãŠã‚ˆã³ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã™ã‚‹ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ç”»åƒã®å‰å‡¦ç†ã¯ã€é€šå¸¸ã€ç”»åƒã®å¢—å¼·ã®å½¢å¼ã«å¾“ã„ã¾ã™ã€‚ç”»åƒã®å‰å‡¦ç†ã¨ç”»åƒã®å¢—å¼·ã®ä¸¡æ–¹ã¯ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã—ã¾ã™ãŒã€ç•°ãªã‚‹ç›®çš„ãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "* ç”»åƒã®å¢—å¼·ã¯ã€éå­¦ç¿’ã‚’é˜²ãã€ãƒ¢ãƒ‡ãƒ«ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã®ã«å½¹ç«‹ã¤æ–¹æ³•ã§ç”»åƒã‚’å¤‰æ›´ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å¢—å¼·ã™ã‚‹æ–¹æ³•ã¯ç„¡é™ã§ã€æ˜ã‚‹ã•ã‚„è‰²ã®èª¿æ•´ã€ã‚¯ãƒ­ãƒƒãƒ—ã€å›è»¢ã€ãƒªã‚µã‚¤ã‚ºã€ã‚ºãƒ¼ãƒ ãªã©ã€æ§˜ã€…ãªæ–¹æ³•ãŒã‚ã‚Šã¾ã™ã€‚ãŸã ã—ã€å¢—å¼·æ“ä½œã«ã‚ˆã£ã¦ç”»åƒã®æ„å‘³ãŒå¤‰ã‚ã‚‰ãªã„ã‚ˆã†ã«æ³¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "* ç”»åƒã®å‰å‡¦ç†ã¯ã€ç”»åƒãŒãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã™ã‚‹å…¥åŠ›å½¢å¼ã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆã€ç”»åƒã¯ãƒ¢ãƒ‡ãƒ«ãŒæœ€åˆã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸã¨ãã¨ã¾ã£ãŸãåŒã˜æ–¹æ³•ã§å‰å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ç”»åƒã®å¢—å¼·ã«ã¯ä»»æ„ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ç”»åƒã®å‰å‡¦ç†ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«é–¢é€£ä»˜ã‘ã‚‰ã‚ŒãŸ`ImageProcessor`ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ãŸã‚ã«ã€[food101](https://huggingface.co/datasets/food101)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ğŸ¤—[Datasetsãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/datasets/load_hub)ã‚’å‚ç…§ï¼‰ï¼š\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‹ãªã‚Šå¤§ãã„ãŸã‚ã€ğŸ¤— Datasetsã®`split`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"food101\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ğŸ¤— Datasetsã® [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image) æ©Ÿèƒ½ã§ç”»åƒã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png\"/>\n",
    "</div>\n",
    "\n",
    "AutoImageProcessorã‚’[AutoImageProcessor.from_pretrained()](https://huggingface.co/docs/transformers/main/ja/model_doc/auto#transformers.AutoImageProcessor.from_pretrained)ã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ã¾ãšã€ç”»åƒã®æ‹¡å¼µã‚’è¿½åŠ ã—ã¾ã—ã‚‡ã†ã€‚å¥½ããªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã§ãã¾ã™ãŒã€ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯torchvisionã®[`transforms`](https://pytorch.org/vision/stable/transforms.html)ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚åˆ¥ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€[Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)ã¾ãŸã¯[Kornia notebooks](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)ã§è©³ç´°ã‚’å­¦ã¶ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "   ã“ã“ã§ã¯ã€[`Compose`](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)ã‚’ä½¿ç”¨ã—ã¦ã„ãã¤ã‹ã®å¤‰æ›ã‚’é€£é–ã•ã›ã¾ã™ - [`RandomResizedCrop`](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html)ã¨[`ColorJitter`](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html)ã€‚\n",
    "   ã‚µã‚¤ã‚ºã®å¤‰æ›´ã«é–¢ã—ã¦ã¯ã€`image_processor`ã‹ã‚‰ç”»åƒã‚µã‚¤ã‚ºã®è¦ä»¶ã‚’å–å¾—ã§ãã¾ã™ã€‚\n",
    "   ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€æ­£ç¢ºãªé«˜ã•ã¨å¹…ãŒå¿…è¦ã§ã™ãŒã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯`shortest_edge`ã®ã¿ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose\n",
    "\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ãƒ¢ãƒ‡ãƒ«ã¯[`pixel_values`](https://huggingface.co/docs/transformers/main/ja/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderModel.forward.pixel_values)ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚\n",
    "`ImageProcessor`ã¯ç”»åƒã®æ­£è¦åŒ–ã¨é©åˆ‡ãªãƒ†ãƒ³ã‚½ãƒ«ã®ç”Ÿæˆã‚’å‡¦ç†ã§ãã¾ã™ã€‚\n",
    "ä¸€é€£ã®ç”»åƒã«å¯¾ã™ã‚‹ç”»åƒæ‹¡å¼µã¨ç”»åƒå‰å‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ã€`pixel_values`ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    images = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    examples[\"pixel_values\"] = image_processor(images, do_resize=False, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ç”»åƒã®ã‚µã‚¤ã‚ºå¤‰æ›´ã‚’æ—¢ã«ç”»åƒå¢—å¼·å¤‰æ›ã§è¡Œã£ã¦ã„ã‚‹ãŸã‚ã€`do_resize=False`ã‚’è¨­å®šã—ã¾ã—ãŸã€‚\n",
    "é©åˆ‡ãª `image_processor` ã‹ã‚‰ã® `size` å±æ€§ã‚’æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚ç”»åƒå¢—å¼·ä¸­ã«ç”»åƒã®ã‚µã‚¤ã‚ºå¤‰æ›´ã‚’è¡Œã‚ãªã„å ´åˆã¯ã€ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’çœç•¥ã—ã¦ãã ã•ã„ã€‚\n",
    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€`ImageProcessor` ãŒã‚µã‚¤ã‚ºå¤‰æ›´ã‚’å‡¦ç†ã—ã¾ã™ã€‚\n",
    "\n",
    "ç”»åƒã‚’å¢—å¼·å¤‰æ›ã®ä¸€éƒ¨ã¨ã—ã¦æ­£è¦åŒ–ã—ãŸã„å ´åˆã¯ã€`image_processor.image_mean` ã¨ `image_processor.image_std` ã®å€¤ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n",
    "</Tip>\n",
    "\n",
    "3. æ¬¡ã«ã€ğŸ¤— Datasetsã®[`set_transform`](https://huggingface.co/docs/datasets/process#format-transform)ã‚’ä½¿ç”¨ã—ã¦ã€å¤‰æ›ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§é©ç”¨ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ç”»åƒã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µãŒ `pixel_values` ã‚’è¿½åŠ ã—ãŸã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã§å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹ã¯ã€å¤‰æ›ãŒé©ç”¨ã•ã‚ŒãŸå¾Œã®ç”»åƒã®å¤–è¦³ã§ã™ã€‚ ç”»åƒã¯ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ‡ã‚ŠæŠœã‹ã‚Œã€ãã®è‰²ã®ç‰¹æ€§ã‚‚ç•°ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = dataset[0][\"pixel_values\"]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png\"/>\n",
    "</div>\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã€æ„å‘³ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãŠã‚ˆã³ãƒ‘ãƒãƒ—ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®ã‚¿ã‚¹ã‚¯ã®å ´åˆã€`ImageProcessor`ã¯\n",
    "ãƒã‚¹ãƒˆå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿã®å‡ºåŠ›ã‚’å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ—ãªã©ã®æ„å‘³ã®ã‚ã‚‹äºˆæ¸¬ã«å¤‰æ›ã—ã¾ã™ã€‚\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€éƒ¨ã®å ´åˆã€ãŸã¨ãˆã°ã€[DETR](https://huggingface.co/docs/transformers/main/ja/./model_doc/detr)ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã«ã‚¹ã‚±ãƒ¼ãƒ«ã®å¤‰æ›´ã‚’é©ç”¨ã—ã¾ã™ã€‚\n",
    "ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒƒãƒå†…ã®ç”»åƒã®ã‚µã‚¤ã‚ºãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚[DetrImageProcessor](https://huggingface.co/docs/transformers/main/ja/model_doc/detr#transformers.DetrImageProcessor)ã‹ã‚‰`DetrImageProcessor.pad()`ã‚’ä½¿ç”¨ã—ã€\n",
    "ã‚«ã‚¹ã‚¿ãƒ ã®`collate_fn`ã‚’å®šç¾©ã—ã¦ç”»åƒã‚’ä¸€ç·’ã«ãƒãƒƒãƒå‡¦ç†ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    batch = {}\n",
    "    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "    batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã‚’ä½¿ç”¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ãŸã‚ã®[ãƒ—ãƒ­ã‚»ãƒƒã‚µ](https://huggingface.co/docs/transformers/main/ja/main_classes/processors)ãŒå¿…è¦ã§ã™ã€‚ãƒ—ãƒ­ã‚»ãƒƒã‚µã¯ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚„ç‰¹å¾´é‡æŠ½å‡ºå™¨ãªã©ã®2ã¤ã®å‡¦ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’çµåˆã—ã¾ã™ã€‚\n",
    "\n",
    "è‡ªå‹•éŸ³å£°èªè­˜ï¼ˆASRï¼‰ã®ãŸã‚ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ä½¿ç”¨æ–¹æ³•ã‚’ç¤ºã™ãŸã‚ã«ã€[LJ Speech](https://huggingface.co/datasets/lj_speech)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ğŸ¤— [Datasets ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/datasets/load_hub)ã‚’å‚ç…§ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "lj_speech = load_dataset(\"lj_speech\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASRï¼ˆè‡ªå‹•éŸ³å£°èªè­˜ï¼‰ã®å ´åˆã€ä¸»ã« `audio` ã¨ `text` ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ãŸã‚ã€ä»–ã®åˆ—ã‚’å‰Šé™¤ã§ãã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€`audio`ã¨`text`ã®åˆ—ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,\n",
       "         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',\n",
       " 'sampling_rate': 22050}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_speech[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_speech[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¸¸ã«ã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã‚’ã€ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨ä¸€è‡´ã•ã›ã‚‹ã‚ˆã†ã«[ãƒªã‚µãƒ³ãƒ—ãƒ«](https://huggingface.co/docs/transformers/main/ja/preprocessing#audio)ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ [AutoProcessor.from_pretrained()](https://huggingface.co/docs/transformers/main/ja/model_doc/auto#transformers.AutoProcessor.from_pretrained) ã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `array`å†…ã«å«ã¾ã‚Œã‚‹ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’`input_values`ã«å‡¦ç†ã—ã€`text`ã‚’`labels`ã«ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example.update(processor(audio=audio[\"array\"], text=example[\"text\"], sampling_rate=16000))\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ã‚µãƒ³ãƒ—ãƒ«ã«`prepare_dataset`é–¢æ•°ã‚’é©ç”¨ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset(lj_speech[0])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
