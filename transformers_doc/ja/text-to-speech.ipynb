{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ (TTS) ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è‡ªç„¶ãªéŸ³å£°ã‚’ä½œæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚éŸ³å£°ã¯è¤‡æ•°ã®å½¢å¼ã§ç”Ÿæˆã§ãã¾ã™ã€‚\n",
    "è¨€èªã¨è¤‡æ•°ã®è©±è€…å‘ã‘ã€‚ç¾åœ¨ã€ã„ãã¤ã‹ã®ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ãƒ¢ãƒ‡ãƒ«ãŒ ğŸ¤— Transformers ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n",
    "[Bark](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/bark)ã€[MMS](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/mms)ã€[VITS](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/vits)ã€ãŠã‚ˆã³ [SpeechT5](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/speecht5)ã€‚\n",
    "\n",
    "`text-to-audio`ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (ã¾ãŸã¯ãã®åˆ¥å - `text-to-speech`) ã‚’ä½¿ç”¨ã—ã¦ã€éŸ³å£°ã‚’ç°¡å˜ã«ç”Ÿæˆã§ãã¾ã™ã€‚ Bark ãªã©ã®ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€\n",
    "ç¬‘ã„ã€ãŸã‚æ¯ã€æ³£ããªã©ã®éè¨€èªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ãŸã‚Šã€éŸ³æ¥½ã‚’è¿½åŠ ã—ãŸã‚Šã™ã‚‹ã‚ˆã†ã«æ¡ä»¶ä»˜ã‘ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
    "Bark ã§`text-to-speech`ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã®ä¾‹ã‚’æ¬¡ã«ç¤ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
    "text = \"[clears throat] This is a test ... and I just took a long pause.\"\n",
    "output = pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§çµæœã®éŸ³å£°ã‚’èããŸã‚ã«ä½¿ç”¨ã§ãã‚‹ã‚³ãƒ¼ãƒ‰ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æ¬¡ã«ç¤ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bark ãŠã‚ˆã³ãã®ä»–ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ TTS ãƒ¢ãƒ‡ãƒ«ãŒã§ãã‚‹ã“ã¨ã®è©³ç´°ãªä¾‹ã«ã¤ã„ã¦ã¯ã€æ¬¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "[éŸ³å£°ã‚³ãƒ¼ã‚¹](https://huggingface.co/learn/audio-course/chapter6/pre-trained_models)ã€‚\n",
    "\n",
    "TTS ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹å ´åˆã€ç¾åœ¨å¾®èª¿æ•´ã§ãã‚‹ã®ã¯ SpeechT5 ã®ã¿ã§ã™ã€‚ SpeechT5 ã¯ã€æ¬¡ã®çµ„ã¿åˆã‚ã›ã§äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã¸ã®ãƒ‡ãƒ¼ã‚¿ã€‚ä¸¡æ–¹ã®ãƒ†ã‚­ã‚¹ãƒˆã«å…±æœ‰ã•ã‚Œã‚‹éš ã•ã‚ŒãŸè¡¨ç¾ã®çµ±ä¸€ã•ã‚ŒãŸç©ºé–“ã‚’å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n",
    "ãã—ã¦ã‚¹ãƒ”ãƒ¼ãƒã€‚ã“ã‚Œã¯ã€åŒã˜äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã«åˆã‚ã›ã¦å¾®èª¿æ•´ã§ãã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€SpeechT5\n",
    "X ãƒ™ã‚¯ãƒˆãƒ« ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã‚’é€šã˜ã¦è¤‡æ•°ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã®æ®‹ã‚Šã®éƒ¨åˆ†ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚\n",
    "\n",
    "1. [VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) ã®ã‚ªãƒ©ãƒ³ãƒ€èª (`nl`) è¨€èªã‚µãƒ–ã‚»ãƒƒãƒˆä¸Šã®è‹±èªéŸ³å£°ã§å…ƒã€…ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ [SpeechT5](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/speecht5) ã‚’å¾®èª¿æ•´ã—ã¾ã™ã€‚ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚\n",
    "2. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹ã‹ç›´æ¥ä½¿ç”¨ã™ã‚‹ã‹ã® 2 ã¤ã®æ–¹æ³•ã®ã„ãšã‚Œã‹ã§ã€æ´—ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "å§‹ã‚ã‚‹å‰ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install datasets soundfile speechbrain accelerate\n",
    "```\n",
    "\n",
    "SpeechT5 ã®ã™ã¹ã¦ã®æ©Ÿèƒ½ãŒã¾ã æ­£å¼ãƒªãƒªãƒ¼ã‚¹ã«ãƒãƒ¼ã‚¸ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚½ãƒ¼ã‚¹ã‹ã‚‰ ğŸ¤—Transformers ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/huggingface/transformers.git\n",
    "```\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã«å¾“ã†ã«ã¯ã€GPU ãŒå¿…è¦ã§ã™ã€‚ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½œæ¥­ã—ã¦ã„ã‚‹å ´åˆã¯ã€æ¬¡ã®è¡Œã‚’å®Ÿè¡Œã—ã¦ GPU ãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚\n",
    "\n",
    "```bash\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</Tip>\n",
    "\n",
    "Hugging Face ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) ã¯ã€ä»¥ä¸‹ã§æ§‹æˆã•ã‚Œã‚‹å¤§è¦æ¨¡ãªå¤šè¨€èªéŸ³å£°ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ã¯ 2009 å¹´ã‹ã‚‰ 2020 å¹´ã®æ¬§å·è­°ä¼šã®ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²ã‚’ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ã„ã¾ã™ã€‚ 15 ä»¶åˆ†ã®ãƒ©ãƒ™ãƒ«ä»˜ãéŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®è¨€èªã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã‚ªãƒ©ãƒ³ãƒ€èªã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€è‡ªç”±ã«åˆ¥ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "VoxPopuli ã¾ãŸã¯ãã®ä»–ã®è‡ªå‹•éŸ³å£°èªè­˜ (ASR) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯æœ€é©ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n",
    "TTS ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‚éå‰°ãªãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒã‚¤ã‚ºãªã©ã€ASR ã«ã¨ã£ã¦æœ‰ç›Šã¨ãªã‚‹æ©Ÿèƒ½ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚\n",
    "é€šå¸¸ã€TTS ã§ã¯æœ›ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ãŸã ã—ã€æœ€é«˜å“è³ªã€å¤šè¨€èªã€ãƒãƒ«ãƒã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã® TTS ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¦‹ã¤ã‘ã‚‹ã®ã¯éå¸¸ã«å›°é›£ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚\n",
    "æŒ‘æˆ¦çš„ã€‚\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20968"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"facebook/voxpopuli\", \"nl\", split=\"train\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¾®èª¿æ•´ã«ã¯ 20968 å€‹ã®ä¾‹ã§ååˆ†ã§ã™ã€‚ SpeechT5 ã¯ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆãŒ 16 kHz ã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã‚‹ãŸã‚ã€\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ä¾‹ãŒã“ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©ã—ã€é©åˆ‡ãªãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor\n",
    "\n",
    "checkpoint = \"microsoft/speecht5_tts\"\n",
    "processor = SpeechT5Processor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text cleanup for SpeechT5 tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ãšã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹ã«ã¯ã€ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼éƒ¨åˆ†ãŒå¿…è¦ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¾‹ã«ã¯ã€`raw_text`æ©Ÿèƒ½ã¨ `normalized_text`æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨ã—ã¦ã©ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã‚’æ±ºã‚ã‚‹ã¨ãã¯ã€\n",
    "SpeechT5 ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã«ã¯æ•°å€¤ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„ã“ã¨ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚ `normalized_text`ã«ã¯æ•°å­—ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™\n",
    "ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€ã“ã‚Œã¯ã‚ˆã‚Šé©åˆ‡ã§ã‚ã‚Šã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ `normalized_text` ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n",
    "\n",
    "SpeechT5 ã¯è‹±èªã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã‚ªãƒ©ãƒ³ãƒ€èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ç‰¹å®šã®æ–‡å­—ã‚’èªè­˜ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—\n",
    "æ®‹ã£ã¦ã„ã‚‹ã‚ˆã†ã«ã€ã“ã‚Œã‚‰ã®æ–‡å­—ã¯ `<unk>`ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚ãŸã ã—ã€ã‚ªãƒ©ãƒ³ãƒ€èªã§ã¯ã€`Ã `ãªã©ã®ç‰¹å®šã®æ–‡å­—ã¯\n",
    "éŸ³ç¯€ã‚’å¼·èª¿ã™ã‚‹ã“ã¨ã«æ…£ã‚Œã¦ã„ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ã€ã“ã®æ–‡å­—ã‚’é€šå¸¸ã®`a`ã«ç½®ãæ›ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è­˜åˆ¥ã™ã‚‹ã«ã¯ã€`SpeechT5Tokenizer`ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ã™ã¹ã¦ã®ä¸€æ„ã®æ–‡å­—ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\n",
    "æ–‡å­—ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚ã“ã‚Œã‚’è¡Œã†ã«ã¯ã€ä»¥ä¸‹ã‚’é€£çµã™ã‚‹ `extract_all_chars` ãƒãƒƒãƒ”ãƒ³ã‚°é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "ã™ã¹ã¦ã®ä¾‹ã‹ã‚‰ã®è»¢å†™ã‚’ 1 ã¤ã®æ–‡å­—åˆ—ã«ã¾ã¨ã‚ã€ãã‚Œã‚’æ–‡å­—ã‚»ãƒƒãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚\n",
    "ã™ã¹ã¦ã®æ–‡å­—èµ·ã“ã—ãŒä¸€åº¦ã«åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã€`dataset.map()`ã§`bâ€‹â€‹atched=True`ã¨`batch_size=-1`ã‚’å¿…ãšè¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
    "ãƒãƒƒãƒ”ãƒ³ã‚°æ©Ÿèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"normalized_text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§ã€2 ã¤ã®æ–‡å­—ã‚»ãƒƒãƒˆãŒã§ãã¾ã—ãŸã€‚1 ã¤ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èªå½™ã‚’æŒã¡ã€ã‚‚ã† 1 ã¤ã¯ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èªå½™ã‚’æŒã¡ã¾ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„æ–‡å­—ã‚’ç‰¹å®šã™ã‚‹ã«ã¯ã€ã“ã‚Œã‚‰ 2 ã¤ã®ã‚»ãƒƒãƒˆã®å·®åˆ†ã‚’å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚çµæœã¨ã—ã¦\n",
    "set ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ã‚ã‚‹ãŒãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã«ã¯å«ã¾ã‚Œã¦ã„ãªã„æ–‡å­—ãŒå«ã¾ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', 'Ã ', 'Ã§', 'Ã¨', 'Ã«', 'Ã­', 'Ã¯', 'Ã¶', 'Ã¼'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vocab - tokenizer_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‰ã®æ‰‹é †ã§ç‰¹å®šã•ã‚ŒãŸã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„æ–‡å­—ã‚’å‡¦ç†ã™ã‚‹ã«ã¯ã€ã“ã‚Œã‚‰ã®æ–‡å­—ã‚’\n",
    "æœ‰åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³ã€‚ã‚¹ãƒšãƒ¼ã‚¹ã¯ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§ã™ã§ã« `â–` ã«ç½®ãæ›ãˆã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€å€‹åˆ¥ã«å‡¦ç†ã™ã‚‹å¿…è¦ãŒãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    (\"Ã \", \"a\"),\n",
    "    (\"Ã§\", \"c\"),\n",
    "    (\"Ã¨\", \"e\"),\n",
    "    (\"Ã«\", \"e\"),\n",
    "    (\"Ã­\", \"i\"),\n",
    "    (\"Ã¯\", \"i\"),\n",
    "    (\"Ã¶\", \"o\"),\n",
    "    (\"Ã¼\", \"u\"),\n",
    "]\n",
    "\n",
    "\n",
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(cleanup_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ç‰¹æ®Šæ–‡å­—ã‚’æ‰±ã£ãŸã®ã§ã€ä»Šåº¦ã¯éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«ç„¦ç‚¹ã‚’ç§»ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoxPopuli ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯è¤‡æ•°ã®è©±è€…ã®éŸ³å£°ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ä½•äººã®è©±è€…ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã—ã‚‡ã†ã‹?ã«\n",
    "ã“ã‚Œã‚’æ±ºå®šã™ã‚‹ã¨ã€ä¸€æ„ã®è©±è€…ã®æ•°ã¨ã€å„è©±è€…ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯„ä¸ã™ã‚‹ä¾‹ã®æ•°ã‚’æ•°ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯åˆè¨ˆ 20,968 å€‹ã®ä¾‹ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®æƒ…å ±ã«ã‚ˆã‚Šã€åˆ†å¸ƒã‚’ã‚ˆã‚Šæ·±ãç†è§£ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n",
    "è¬›æ¼”è€…ã¨ãƒ‡ãƒ¼ã‚¿å†…ã®ä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "speaker_counts = defaultdict(int)\n",
    "\n",
    "for speaker_id in dataset[\"speaker_id\"]:\n",
    "    speaker_counts[speaker_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã¨ã€å„è©±è€…ã«ã©ã‚Œã ã‘ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ã‚’æŠŠæ¡ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(speaker_counts.values(), bins=20)\n",
    "plt.ylabel(\"Speakers\")\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_speakers_histogram.png\" alt=\"Speakers histogram\"/>\n",
    "</div>\n",
    "\n",
    "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‹ã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®è©±è€…ã®ç´„ 3 åˆ†ã® 1 ã®ä¾‹ãŒ 100 æœªæº€ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚\n",
    "ç´„ 10 äººã®è¬›æ¼”è€…ãŒ 500 ä»¥ä¸Šã®ä¾‹ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã“ã¨ã‚’åˆ¶é™ã§ãã¾ã™ã€‚\n",
    "100 ï½ 400 å€‹ã®ä¾‹ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’è¬›æ¼”è€…ã«æä¾›ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_speaker(speaker_id):\n",
    "    return 100 <= speaker_counts[speaker_id] <= 400\n",
    "\n",
    "\n",
    "dataset = dataset.filter(select_speaker, input_columns=[\"speaker_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ®‹ã‚Šã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®æ•°ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset[\"speaker_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ®‹ã‚Šã®ä¾‹ãŒã„ãã¤ã‚ã‚‹ã‹è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9973"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç´„ 40 äººã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¬›æ¼”è€…ã‹ã‚‰ã® 10,000 å¼±ã®ä¾‹ãŒæ®‹ã‚Šã¾ã™ãŒã€ã“ã‚Œã§ååˆ†ã§ã™ã€‚\n",
    "\n",
    "ä¾‹ãŒå°‘ãªã„ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®ä¸­ã«ã¯ã€ä¾‹ãŒé•·ã„å ´åˆã€å®Ÿéš›ã«ã¯ã‚ˆã‚Šå¤šãã®éŸ³å£°ãŒåˆ©ç”¨ã§ãã‚‹å ´åˆãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã—ã‹ã—ã€\n",
    "å„è©±è€…ã®éŸ³å£°ã®åˆè¨ˆé‡ã‚’æ±ºå®šã™ã‚‹ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "å„ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’ä¼´ã†æ™‚é–“ã®ã‹ã‹ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã€‚ãã®ãŸã‚ã€ã“ã“ã§ã¯ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTS ãƒ¢ãƒ‡ãƒ«ãŒè¤‡æ•°ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã«ã¯ã€ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã¯ã€ç‰¹å®šã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®éŸ³å£°ç‰¹æ€§ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¸ã®è¿½åŠ å…¥åŠ›ã§ã™ã€‚\n",
    "ã“ã‚Œã‚‰ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ [spkrec-xvect-voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "SpeechBrain ã®ãƒ¢ãƒ‡ãƒ«ã€‚\n",
    "\n",
    "å…¥åŠ›ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ³¢å½¢ã‚’å—ã‘å–ã‚Šã€512 è¦ç´ ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’å‡ºåŠ›ã™ã‚‹é–¢æ•° `create_speaker_embedding()` ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "å¯¾å¿œã™ã‚‹ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ãŒå«ã¾ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name,\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
    ")\n",
    "\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`speechbrain/spkrec-xvect-voxceleb`ãƒ¢ãƒ‡ãƒ«ã¯ã€VoxCeleb ã‹ã‚‰ã®è‹±èªéŸ³å£°ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸã“ã¨ã«æ³¨æ„ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ãŒã€ã“ã®ã‚¬ã‚¤ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã¯ã‚ªãƒ©ãƒ³ãƒ€èªã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ä»Šå¾Œã‚‚ç”Ÿæˆã•ã‚Œã‚‹ã¨ä¿¡ã˜ã¦ã„ã¾ã™ãŒã€\n",
    "ã‚ªãƒ©ãƒ³ãƒ€èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©åˆ‡ãªè©±è€…åŸ‹ã‚è¾¼ã¿ã‚’è¡Œã£ã¦ã‚‚ã€ã“ã®ä»®å®šã¯ã™ã¹ã¦ã®å ´åˆã«å½“ã¦ã¯ã¾ã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "æœ€é©ãªçµæœã‚’å¾—ã‚‹ã«ã¯ã€æœ€åˆã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã§ X ãƒ™ã‚¯ãƒˆãƒ« ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒç¢ºå®Ÿã«\n",
    "ã‚ªãƒ©ãƒ³ãƒ€èªã«å­˜åœ¨ã™ã‚‹ç‹¬ç‰¹ã®éŸ³å£°ç‰¹å¾´ã‚’ã‚ˆã‚Šã‚ˆãæ‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«ã€ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã—ã‚‡ã†ã€‚ã‚’å–ã‚Šè¾¼ã‚€ `prepare_dataset` é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "ã“ã‚Œã¯ 1 ã¤ã®ä¾‹ã§ã‚ã‚Šã€`SpeechT5Processor` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ãƒ­ã‚°ãƒ¡ãƒ« ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "ã¾ãŸã€è¿½åŠ ã®å…¥åŠ›ã¨ã—ã¦ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã‚‚è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example = processor(\n",
    "        text=example[\"normalized_text\"],\n",
    "        audio_target=audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_attention_mask=False,\n",
    "    )\n",
    "\n",
    "    # strip off the batch dimension\n",
    "    example[\"labels\"] = example[\"labels\"][0]\n",
    "\n",
    "    # use SpeechBrain to obtain x-vector\n",
    "    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å˜ä¸€ã®ä¾‹ã‚’è¦‹ã¦ã€å‡¦ç†ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'labels', 'stop_labels', 'speaker_embeddings']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_example = prepare_dataset(dataset[0])\n",
    "list(processed_example.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¯ 512 è¦ç´ ã®ãƒ™ã‚¯ãƒˆãƒ«ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_example[\"speaker_embeddings\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ©ãƒ™ãƒ«ã¯ã€80 ãƒ¡ãƒ« ãƒ“ãƒ³ã‚’å«ã‚€ãƒ­ã‚°ãƒ¡ãƒ« ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(processed_example[\"labels\"].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_logmelspectrogram_1.png\" alt=\"Log-mel spectrogram with 80 mel bins\"/>\n",
    "</div>\n",
    "\n",
    "è£œè¶³: ã“ã®ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ãŒã‚ã‹ã‚Šã«ãã„ã¨æ„Ÿã˜ã‚‹å ´åˆã¯ã€ä½å‘¨æ³¢ã‚’é…ç½®ã™ã‚‹è¦å‰‡ã«æ…£ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåŸå› ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ãƒ—ãƒ­ãƒƒãƒˆã®ä¸‹éƒ¨ã«é«˜å‘¨æ³¢ã€ä¸Šéƒ¨ã«é«˜å‘¨æ³¢ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ãŸã ã—ã€matplotlib ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ç”»åƒã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹å ´åˆã€\n",
    "Y è»¸ãŒåè»¢ã•ã‚Œã€ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ãŒä¸Šä¸‹é€†ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "æ¬¡ã«ã€å‡¦ç†é–¢æ•°ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«é©ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã¯ 5 ï½ 10 åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ä¸€éƒ¨ã®ä¾‹ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒå‡¦ç†ã§ãã‚‹æœ€å¤§å…¥åŠ›é•· (600 ãƒˆãƒ¼ã‚¯ãƒ³) ã‚’è¶…ãˆã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n",
    "ãã‚Œã‚‰ã®ä¾‹ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰å‰Šé™¤ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã•ã‚‰ã«é€²ã‚“ã§ã€ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒ ã‚µã‚¤ã‚ºã‚’å¯èƒ½ã«ã™ã‚‹ãŸã‚ã«ã€200 ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã‚‹ã‚‚ã®ã¯ã™ã¹ã¦å‰Šé™¤ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8259"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_not_too_long(input_ids):\n",
    "    input_length = len(input_ids)\n",
    "    return input_length < 200\n",
    "\n",
    "\n",
    "dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€åŸºæœ¬çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/ãƒ†ã‚¹ãƒˆåˆ†å‰²ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¤‡æ•°ã®ä¾‹ã‚’ 1 ã¤ã®ãƒãƒƒãƒã«çµåˆã™ã‚‹ã«ã¯ã€ã‚«ã‚¹ã‚¿ãƒ  ãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ã€çŸ­ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã§åŸ‹ã‚è¾¼ã¿ã¾ã™ã€‚\n",
    "ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€ã™ã¹ã¦ã®ä¾‹ãŒåŒã˜é•·ã•ã«ãªã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  ãƒ©ãƒ™ãƒ«ã®å ´åˆã€åŸ‹ã‚è¾¼ã¾ã‚ŒãŸéƒ¨åˆ†ã¯ç‰¹åˆ¥ãªå€¤ `-100` ã«ç½®ãæ›ãˆã‚‰ã‚Œã¾ã™ã€‚ã“ã®ç‰¹åˆ¥ãªä¾¡å€¤ã¯\n",
    "ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ æå¤±ã‚’è¨ˆç®—ã™ã‚‹ã¨ãã«ã€ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®ãã®éƒ¨åˆ†ã‚’ç„¡è¦–ã™ã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã«æŒ‡ç¤ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TTSDataCollatorWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: list[dict[str, Union[list[int], torch.Tensor]]]) -> dict[str, torch.Tensor]:\n",
    "        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n",
    "        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n",
    "        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n",
    "\n",
    "        # collate the inputs and targets into a batch\n",
    "        batch = processor.pad(input_ids=input_ids, labels=label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        batch[\"labels\"] = batch[\"labels\"].masked_fill(batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100)\n",
    "\n",
    "        # not used during fine-tuning\n",
    "        del batch[\"decoder_attention_mask\"]\n",
    "\n",
    "        # round down target lengths to multiple of reduction factor\n",
    "        if model.config.reduction_factor > 1:\n",
    "            target_lengths = torch.tensor([len(feature[\"input_values\"]) for feature in label_features])\n",
    "            target_lengths = target_lengths.new(\n",
    "                [length - length % model.config.reduction_factor for length in target_lengths]\n",
    "            )\n",
    "            max_length = max(target_lengths)\n",
    "            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n",
    "\n",
    "        # also add in the speaker embeddings\n",
    "        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpeechT5 ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ã‚³ãƒ¼ãƒ€éƒ¨åˆ†ã¸ã®å…¥åŠ›ãŒ 2 åˆ†ã® 1 ã«å‰Šæ¸›ã•ã‚Œã¾ã™ã€‚ã¤ã¾ã‚Šã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒç ´æ£„ã•ã‚Œã¾ã™ã€‚\n",
    "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰ã®ä»–ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã€‚æ¬¡ã«ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã¯ 2 å€ã®é•·ã•ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ä»¥æ¥\n",
    "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ãŒå¥‡æ•°ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã€ãƒ‡ãƒ¼ã‚¿ç…§åˆæ©Ÿèƒ½ã¯ãƒãƒƒãƒã®æœ€å¤§é•·ã‚’åˆ‡ã‚Šæ¨ã¦ã¦ã€\n",
    "2ã®å€æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = TTSDataCollatorWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰ã«ä½¿ç”¨ã—ãŸã®ã¨åŒã˜ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5ForTextToSpeech\n",
    "\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`use_cache=True`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã€å‹¾é…ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã«ç„¡åŠ¹ã«ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã›ã‚“ã€‚ä»£ã‚ã‚Šã«ã€\n",
    "æå¤±ã ã‘ã‚’è¦‹ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"speecht5_finetuned_voxpopuli_nl\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=2,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    label_names=[\"labels\"],\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trainer`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã‚’ãã‚Œã«æ¸¡ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯æ•°æ™‚é–“ã‹ã‹ã‚Šã¾ã™ã€‚ GPU ã«å¿œã˜ã¦ã€\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã™ã‚‹ã¨ãã«ã€CUDA ã®ã€Œãƒ¡ãƒ¢ãƒªä¸è¶³ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å ´åˆã€æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™\n",
    "`per_device_train_batch_size`ã‚’ 2 å€ã«å¢—åˆ†ã—ã€`gradient_accumulation_steps`ã‚’ 2 å€ã«å¢—ã‚„ã—ã¦è£œæ­£ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã«ã¯ã€å¿…ãšãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨ã¨ã‚‚ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(\"YOUR_ACCOUNT_NAME/speecht5_finetuned_voxpopuli_nl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸã®ã§ã€ãã‚Œã‚’æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚\n",
    "ã¾ãšã€å¯¾å¿œã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ãã‚Œã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ `\"text-to-speech\"` ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†\n",
    "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"YOUR_ACCOUNT_NAME/speecht5_finetuned_voxpopuli_nl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¸Œæœ›ã™ã‚‹ã‚ªãƒ©ãƒ³ãƒ€èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚ä¾‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hallo allemaal, ik praat nederlands. groetjes aan iedereen!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ SpeechT5 ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ãŒå¿…è¦ã§ã™ã€‚ãƒ†ã‚¹ãƒˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¾‹ã‹ã‚‰å–å¾—ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[\"test\"][304]\n",
    "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«æ¸¡ã™ã“ã¨ãŒã§ãã€æ®‹ã‚Šã¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå‡¦ç†ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': array([-6.82714235e-05, -4.26525949e-04,  1.06134125e-04, ...,\n",
       "        -1.22392643e-03, -7.76011671e-04,  3.29112721e-04], dtype=float32),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_params = {\"speaker_embeddings\": speaker_embeddings}\n",
    "output = pipe(text, forward_params=forward_params)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãã®å¾Œã€çµæœã‚’èãã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(output['audio'], rate=output['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ãªãã¦ã‚‚åŒã˜æ¨è«–çµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€ã‚ˆã‚Šå¤šãã®æ‰‹é †ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "ğŸ¤— ãƒãƒ–ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"YOUR_ACCOUNT/speecht5_finetuned_voxpopuli_nl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ä¾‹ã‚’é¸æŠã—ã¦ã€ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[\"test\"][304]\n",
    "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å®šç¾©ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hallo allemaal, ik praat nederlands. groetjes aan iedereen!\"\n",
    "inputs = processor(text=text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã®ã“ã¨ã‚’è¡Œã†å ´åˆã¯ã€ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’è¦–è¦šåŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(spectrogram.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_logmelspectrogram_2.png\" alt=\"Generated log-mel spectrogram\"/>\n",
    "</div>\n",
    "\n",
    "æœ€å¾Œã«ã€ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ã‚µã‚¦ãƒ³ãƒ‰ã«å¤‰æ›ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    speech = vocoder(spectrogram)\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "Audio(speech.numpy(), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç§ãŸã¡ã®çµŒé¨“ã§ã¯ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æº€è¶³ã®ã„ãçµæœã‚’å¾—ã‚‹ã®ã¯é›£ã—ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®å“è³ª\n",
    "åŸ‹ã‚è¾¼ã¿ã¯é‡è¦ãªè¦ç´ ã§ã‚ã‚‹ã‚ˆã†ã§ã™ã€‚ SpeechT5 ã¯è‹±èªã® x ãƒ™ã‚¯ãƒˆãƒ«ã§äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™\n",
    "è‹±èªã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€‚åˆæˆéŸ³å£°ã®éŸ³è³ªãŒæ‚ªã„å ´åˆã¯ã€åˆ¥ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã‚’é•·ãã™ã‚‹ã¨ã€çµæœã®è³ªã‚‚å‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã‚Œã§ã‚‚ã€ãã®ã‚¹ãƒ”ãƒ¼ãƒã¯æ˜ã‚‰ã‹ã«è‹±èªã§ã¯ãªãã‚ªãƒ©ãƒ³ãƒ€èªã§ã™ã€‚\n",
    "è©±è€…ã®éŸ³å£°ç‰¹æ€§ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¾ã™ (ä¾‹ã®å…ƒã®éŸ³å£°ã¨æ¯”è¼ƒ)ã€‚\n",
    "ã‚‚ã† 1 ã¤å®Ÿé¨“ã™ã¹ãã“ã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆã§ã™ã€‚ãŸã¨ãˆã°ã€`config.reduction_factor = 1`ã‚’ä½¿ç”¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚\n",
    "ã“ã‚Œã«ã‚ˆã‚ŠçµæœãŒæ”¹å–„ã•ã‚Œã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "æœ€å¾Œã«ã€å€«ç†çš„é…æ…®ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ãŒä¸å¯æ¬ ã§ã™ã€‚ TTS ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã«ã¯æ•°å¤šãã®æœ‰ç”¨ãªç”¨é€”ãŒã‚ã‚Šã¾ã™ãŒã€\n",
    "ã¾ãŸã€çŸ¥ã‚‰ãªã„ã†ã¡ã«èª°ã‹ã®å£°ã‚’å½è£…ã™ã‚‹ãªã©ã€æ‚ªæ„ã®ã‚ã‚‹ç›®çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚ãŠé¡˜ã„ã—ã¾ã™\n",
    "TTS ã¯è³¢æ˜ã‹ã¤è²¬ä»»ã‚’æŒã£ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
