{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–‡æ›¸ã«ã‚ˆã‚‹è³ªå•å¿œç­”ã¯ã€æ–‡æ›¸ã«ã‚ˆã‚‹è¦–è¦šçš„ãªè³ªå•å¿œç­”ã¨ã‚‚å‘¼ã°ã‚Œã€ä»¥ä¸‹ã‚’æä¾›ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚\n",
    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”»åƒã«é–¢ã™ã‚‹è³ªå•ã¸ã®å›ç­”ã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¯é€šå¸¸ã€ç”»åƒã¨ç”»åƒã®çµ„ã¿åˆã‚ã›ã§ã™ã€‚\n",
    "è³ªå•ãŒã‚ã‚Šã€å‡ºåŠ›ã¯è‡ªç„¶è¨€èªã§è¡¨ç¾ã•ã‚ŒãŸå›ç­”ã§ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ä»¥ä¸‹ã‚’å«ã‚€è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚\n",
    "ãƒ†ã‚­ã‚¹ãƒˆã€å˜èªã®ä½ç½® (å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹)ã€ãŠã‚ˆã³ç”»åƒè‡ªä½“ã€‚\n",
    "\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚\n",
    "\n",
    "- [DocVQA ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://huggingface.co/datasets/nielsr/docvqa_1200_examples_donut) ã® [LayoutLMv2](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/layoutlmv2) ã‚’å¾®èª¿æ•´ã—ã¾ã™ã€‚\n",
    "- å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ã“ã®ã‚¿ã‚¹ã‚¯ã¨äº’æ›æ€§ã®ã‚ã‚‹ã™ã¹ã¦ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€[ã‚¿ã‚¹ã‚¯ãƒšãƒ¼ã‚¸](https://huggingface.co/tasks/image-to-text) ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "LayoutLMv2 ã¯ã€æœ€å¾Œã®éè¡¨ç¤ºã®ãƒ˜ãƒƒãƒ€ãƒ¼ã®ä¸Šã«è³ªå•å¿œç­”ãƒ˜ãƒƒãƒ‰ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ã¾ã™ã€‚\n",
    "ãƒˆãƒ¼ã‚¯ãƒ³ã®çŠ¶æ…‹ã‚’èª¿ã¹ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®é–‹å§‹ãƒˆãƒ¼ã‚¯ãƒ³ã¨çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½ç½®ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚\n",
    "ç­”ãˆã€‚è¨€ã„æ›ãˆã‚Œã°ã€å•é¡Œã¯æŠ½å‡ºçš„è³ªå•å¿œç­”ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚ã¤ã¾ã‚Šã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ã¦ã€ã©ã®éƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹ã‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚\n",
    "ã®æƒ…å ±ãŒè³ªå•ã«ç­”ãˆã¾ã™ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ OCR ã‚¨ãƒ³ã‚¸ãƒ³ã®å‡ºåŠ›ã‹ã‚‰å–å¾—ã•ã‚Œã¾ã™ã€‚ã“ã“ã§ã¯ Google ã® Tesseract ã§ã™ã€‚\n",
    "\n",
    "å§‹ã‚ã‚‹å‰ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ LayoutLMv2 ã¯ detectron2ã€torchvisionã€tesseract ã«ä¾å­˜ã—ã¾ã™ã€‚\n",
    "\n",
    "```bash\n",
    "pip install -q transformers datasets\n",
    "```\n",
    "\n",
    "```bash\n",
    "pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "pip install torchvision\n",
    "```\n",
    "\n",
    "```bash\n",
    "sudo apt install tesseract-ocr\n",
    "pip install -q pytesseract\n",
    "```\n",
    "\n",
    "ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã‚‰ã€ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã—ã¾ã™ã€‚\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ Hugging Face ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã€ğŸ¤— ãƒãƒ–ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã„ãã¤ã‹ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’å®šç¾©ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"microsoft/layoutlmv2-base-uncased\"\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ğŸ¤— Hub ã«ã‚ã‚‹å‰å‡¦ç†ã•ã‚ŒãŸ DocVQA ã®å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãƒ•ãƒ«ã«ä½¿ã„ãŸã„å ´åˆã¯ã€\n",
    "DocVQA ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€[DocVQA ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸](https://rrc.cvc.uab.es/?ch=17) ã§ç™»éŒ²ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚ãã†ã™ã‚Œã°ã€\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã‚’é€²ã‚ã¦ã€[ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ–¹æ³•](https://huggingface.co/docs/datasets/loading#local-and-remote-files) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'image', 'query', 'answers', 'words', 'bounding_boxes', 'answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'image', 'query', 'answers', 'words', 'bounding_boxes', 'answer'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nielsr/docvqa_1200_examples\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã”è¦§ã®ã¨ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã™ã§ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã«åˆ†å‰²ã•ã‚Œã¦ã„ã¾ã™ã€‚ç†è§£ã™ã‚‹ãŸã‚ã«ãƒ©ãƒ³ãƒ€ãƒ ãªä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†\n",
    "æ©Ÿèƒ½ã‚’å‚™ãˆãŸè‡ªåˆ†è‡ªèº«ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å€‹ã€…ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¡¨ã™å†…å®¹ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚\n",
    "* `id`: ã‚µãƒ³ãƒ—ãƒ«ã®ID\n",
    "* `image`: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”»åƒã‚’å«ã‚€ PIL.Image.Image ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "* `query`: è³ªå•æ–‡å­—åˆ— - ã„ãã¤ã‹ã®è¨€èªã§ã®è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è³ªå•\n",
    "* `answers`: ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã£ã¦æä¾›ã•ã‚ŒãŸæ­£è§£ã®ãƒªã‚¹ãƒˆ\n",
    "* `words` ã¨ `bounding_boxes`: OCR ã®çµæœã€‚ã“ã“ã§ã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚\n",
    "* `answer`: åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨ä¸€è‡´ã™ã‚‹ç­”ãˆã€‚ã“ã“ã§ã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚\n",
    "\n",
    "è‹±èªã®è³ªå•ã ã‘ã‚’æ®‹ã—ã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹`answer`æ©Ÿèƒ½ã‚’å‰Šé™¤ã—ã¾ã—ã‚‡ã†ã€‚\n",
    "ã¾ãŸã€ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã£ã¦æä¾›ã•ã‚ŒãŸã‚»ãƒƒãƒˆã‹ã‚‰æœ€åˆã®å›ç­”ã‚’å–å¾—ã—ã¾ã™ã€‚ã‚ã‚‹ã„ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = dataset.map(lambda example: {\"question\": example[\"query\"][\"en\"]}, remove_columns=[\"query\"])\n",
    "updated_dataset = updated_dataset.map(\n",
    "    lambda example: {\"answer\": example[\"answers\"][0]}, remove_columns=[\"answer\", \"answers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ä½¿ç”¨ã™ã‚‹ LayoutLMv2 ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã€`max_position_embeddings = 512` ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ (\n",
    "ã“ã®æƒ…å ±ã¯ã€[ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã® `config.json` ãƒ•ã‚¡ã‚¤ãƒ«](https://huggingface.co/microsoft/layoutlmv2-base-uncased/blob/main/config.json#L18)) ã§è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚\n",
    "ä¾‹ã‚’çœç•¥ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒã€ç­”ãˆãŒå¤§ããªæ–‡æ›¸ã®æœ€å¾Œã«ã‚ã‚Šã€çµå±€çœç•¥ã•ã‚Œã¦ã—ã¾ã†ã¨ã„ã†çŠ¶æ³ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€\n",
    "ã“ã“ã§ã¯ã€åŸ‹ã‚è¾¼ã¿ãŒ 512 ã‚’è¶…ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã„ãã¤ã‹ã®ä¾‹ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ã»ã¨ã‚“ã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒé•·ã„å ´åˆã¯ã€ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚° ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æˆ¦ç•¥ã‚’å®Ÿè£…ã§ãã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = updated_dataset.filter(lambda x: len(x[\"words\"]) + len(x[\"question\"].split()) < 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®æ™‚ç‚¹ã§ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ OCR æ©Ÿèƒ½ã‚‚å‰Šé™¤ã—ã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã‚‰ã¯ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã® OCR ã®çµæœã§ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã€‚ã“ã‚Œã‚‰ã¯å…¥åŠ›è¦ä»¶ã¨ä¸€è‡´ã—ãªã„ãŸã‚ã€ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã•ã‚‰ã«å‡¦ç†ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã€‚ä»£ã‚ã‚Šã«ã€OCR ã¨ OCR ã®ä¸¡æ–¹ã®å…ƒã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ `LayoutLMv2Processor` ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚\n",
    "ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã€‚ã“ã®ã‚ˆã†ã«ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæƒ³ã•ã‚Œã‚‹å…¥åŠ›ã¨ä¸€è‡´ã™ã‚‹å…¥åŠ›ã‚’å–å¾—ã—ã¾ã™ã€‚ç”»åƒã‚’æ‰‹å‹•ã§åŠ å·¥ã—ãŸã„å ´åˆã¯ã€\n",
    "ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ãªå…¥åŠ›å½¢å¼ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã‹ã‚’çŸ¥ã‚‹ã«ã¯ã€[`LayoutLMv2` ãƒ¢ãƒ‡ãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://huggingface.co/docs/transformers/main/ja/tasks/../model_doc/layoutlmv2) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = updated_dataset.remove_columns(\"words\")\n",
    "updated_dataset = updated_dataset.remove_columns(\"bounding_boxes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«ã€ç”»åƒã‚µãƒ³ãƒ—ãƒ«ã‚’ç¢ºèªã—ãªã„ã¨ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯å®Œäº†ã—ã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset[\"train\"][11][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "     <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/docvqa_example.jpg\" alt=\"DocVQA Image Example\"/>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–‡æ›¸ã®è³ªå•ã«ç­”ãˆã‚‹ã‚¿ã‚¹ã‚¯ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ãŸã‚ã€å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‹ã‚‰ã®å…¥åŠ›ãŒç¢ºå®Ÿã«è¡Œã‚ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã«å¾“ã£ã¦å‰å‡¦ç†ã•ã‚Œã¾ã™ã€‚ã¾ãšã€`LayoutLMv2Processor` ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã§ãã‚‹ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã¨ãƒ†ã‚­ã‚¹ãƒˆ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’å†…éƒ¨ã§çµ„ã¿åˆã‚ã›ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing document images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ãšã€ãƒ—ãƒ­ã‚»ãƒƒã‚µã‹ã‚‰ã® `image_processor` ã‚’åˆ©ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”»åƒã‚’æº–å‚™ã—ã¾ã—ã‚‡ã†ã€‚\n",
    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã¯ç”»åƒã®ã‚µã‚¤ã‚ºã‚’ 224x224 ã«å¤‰æ›´ã—ã€ã‚«ãƒ©ãƒ¼ ãƒãƒ£ãƒãƒ«ã®é †åºãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚\n",
    "tesseract ã‚’ä½¿ç”¨ã—ã¦ OCR ã‚’é©ç”¨ã—ã€å˜èªã¨æ­£è¦åŒ–ã•ã‚ŒãŸå¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã™ã¹ã¦ã€ã¾ã•ã«å¿…è¦ãªã‚‚ã®ã§ã™ã€‚\n",
    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”»åƒå‡¦ç†ã‚’ç”»åƒã®ãƒãƒƒãƒã«é©ç”¨ã—ã€OCR ã®çµæœã‚’è¿”ã™é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = processor.image_processor\n",
    "\n",
    "\n",
    "def get_ocr_words_and_boxes(examples):\n",
    "    images = [image.convert(\"RGB\") for image in examples[\"image\"]]\n",
    "    encoded_inputs = image_processor(images)\n",
    "\n",
    "    examples[\"image\"] = encoded_inputs.pixel_values\n",
    "    examples[\"words\"] = encoded_inputs.words\n",
    "    examples[\"boxes\"] = encoded_inputs.boxes\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®å‰å‡¦ç†ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«é«˜é€Ÿã«é©ç”¨ã™ã‚‹ã«ã¯ã€`map` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_ocr = updated_dataset.map(get_ocr_words_and_boxes, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”»åƒã« OCR ã‚’é©ç”¨ã—ãŸã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒ¢ãƒ‡ãƒ«ç”¨ã«æº–å‚™ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ã“ã‚Œã«ã¯ã€å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å–å¾—ã—ãŸå˜èªã¨ãƒœãƒƒã‚¯ã‚¹ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã® `input_ids`ã€`attention_mask`ã€\n",
    "`token_type_ids`ã¨`bbox`ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ã™ã‚‹ã«ã¯ã€ãƒ—ãƒ­ã‚»ãƒƒã‚µã‹ã‚‰ã®`Tokenizer`ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‰è¿°ã®å‰å‡¦ç†ã«åŠ ãˆã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ã‚‚ã‚ã‚Šã¾ã™ã€‚ `xxxForQuestionAnswering` ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ\n",
    "ğŸ¤— Transformers ã§ã¯ã€ãƒ©ãƒ™ãƒ«ã¯ `start_positions` ã¨ `end_positions` ã§æ§‹æˆã•ã‚Œã€ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒãã®ä½ç½®ã«ã‚ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "é–‹å§‹ç‚¹ã¨ã€ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå›ç­”ã®æœ€å¾Œã«ã‚ã‚‹ã‹ã€‚\n",
    "\n",
    "ãã‚Œã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚ã‚ˆã‚Šå¤§ããªãƒªã‚¹ãƒˆ (å˜èªãƒªã‚¹ãƒˆ) å†…ã®ã‚µãƒ–ãƒªã‚¹ãƒˆ (å˜èªã«åˆ†å‰²ã•ã‚ŒãŸå›ç­”) ã‚’æ¤œç´¢ã§ãã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®é–¢æ•°ã¯ã€`words_list` ã¨ `answer_list` ã¨ã„ã† 2 ã¤ã®ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚æ¬¡ã«ã€`words_list`ã‚’åå¾©å‡¦ç†ã—ã¦ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚\n",
    "`words_list` (words_list[i]) å†…ã®ç¾åœ¨ã®å˜èªãŒã€answer_list (answer_list[0]) ã®æœ€åˆã®å˜èªã¨ç­‰ã—ã„ã‹ã©ã†ã‹ã€ãŠã‚ˆã³\n",
    "ç¾åœ¨ã®å˜èªã‹ã‚‰å§‹ã¾ã‚Šã€`answer_list` ã¨åŒã˜é•·ã•ã® `words_list` ã®ã‚µãƒ–ãƒªã‚¹ãƒˆã¯ã€`to answer_list` ã¨ç­‰ã—ããªã‚Šã¾ã™ã€‚\n",
    "ã“ã®æ¡ä»¶ãŒ true ã®å ´åˆã€ä¸€è‡´ãŒè¦‹ã¤ã‹ã£ãŸã“ã¨ã‚’æ„å‘³ã—ã€é–¢æ•°ã¯ä¸€è‡´ã¨ãã®é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (idx) ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚\n",
    "ã¨ãã®çµ‚äº†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (idx + len(answer_list) - 1)ã€‚è¤‡æ•°ã®ä¸€è‡´ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€é–¢æ•°ã¯æœ€åˆã®ã‚‚ã®ã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€é–¢æ•°ã¯ (`None`ã€0ã€ãŠã‚ˆã³ 0) ã‚’è¿”ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfinder(words_list, answer_list):\n",
    "    matches = []\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    for idx, i in enumerate(range(len(words_list))):\n",
    "        if words_list[i] == answer_list[0] and words_list[i : i + len(answer_list)] == answer_list:\n",
    "            matches.append(answer_list)\n",
    "            start_indices.append(idx)\n",
    "            end_indices.append(idx + len(answer_list) - 1)\n",
    "    if matches:\n",
    "        return matches[0], start_indices[0], end_indices[0]\n",
    "    else:\n",
    "        return None, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®é–¢æ•°ãŒç­”ãˆã®ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ã€ä¾‹ã§ä½¿ç”¨ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question:  Who is in  cc in this letter?\n",
       "Words: ['wie', 'baw', 'brown', '&', 'williamson', 'tobacco', 'corporation', 'research', '&', 'development', 'internal', 'correspondence', 'to:', 'r.', 'h.', 'honeycutt', 'ce:', 't.f.', 'riehl', 'from:', '.', 'c.j.', 'cook', 'date:', 'may', '8,', '1995', 'subject:', 'review', 'of', 'existing', 'brainstorming', 'ideas/483', 'the', 'major', 'function', 'of', 'the', 'product', 'innovation', 'graup', 'is', 'to', 'develop', 'marketable', 'nove!', 'products', 'that', 'would', 'be', 'profitable', 'to', 'manufacture', 'and', 'sell.', 'novel', 'is', 'defined', 'as:', 'of', 'a', 'new', 'kind,', 'or', 'different', 'from', 'anything', 'seen', 'or', 'known', 'before.', 'innovation', 'is', 'defined', 'as:', 'something', 'new', 'or', 'different', 'introduced;', 'act', 'of', 'innovating;', 'introduction', 'of', 'new', 'things', 'or', 'methods.', 'the', 'products', 'may', 'incorporate', 'the', 'latest', 'technologies,', 'materials', 'and', 'know-how', 'available', 'to', 'give', 'then', 'a', 'unique', 'taste', 'or', 'look.', 'the', 'first', 'task', 'of', 'the', 'product', 'innovation', 'group', 'was', 'to', 'assemble,', 'review', 'and', 'categorize', 'a', 'list', 'of', 'existing', 'brainstorming', 'ideas.', 'ideas', 'were', 'grouped', 'into', 'two', 'major', 'categories', 'labeled', 'appearance', 'and', 'taste/aroma.', 'these', 'categories', 'are', 'used', 'for', 'novel', 'products', 'that', 'may', 'differ', 'from', 'a', 'visual', 'and/or', 'taste/aroma', 'point', 'of', 'view', 'compared', 'to', 'canventional', 'cigarettes.', 'other', 'categories', 'include', 'a', 'combination', 'of', 'the', 'above,', 'filters,', 'packaging', 'and', 'brand', 'extensions.', 'appearance', 'this', 'category', 'is', 'used', 'for', 'novel', 'cigarette', 'constructions', 'that', 'yield', 'visually', 'different', 'products', 'with', 'minimal', 'changes', 'in', 'smoke', 'chemistry', 'two', 'cigarettes', 'in', 'cne.', 'emulti-plug', 'te', 'build', 'yaur', 'awn', 'cigarette.', 'eswitchable', 'menthol', 'or', 'non', 'menthol', 'cigarette.', '*cigarettes', 'with', 'interspaced', 'perforations', 'to', 'enable', 'smoker', 'to', 'separate', 'unburned', 'section', 'for', 'future', 'smoking.', 'Â«short', 'cigarette,', 'tobacco', 'section', '30', 'mm.', 'Â«extremely', 'fast', 'buming', 'cigarette.', 'Â«novel', 'cigarette', 'constructions', 'that', 'permit', 'a', 'significant', 'reduction', 'iretobacco', 'weight', 'while', 'maintaining', 'smoking', 'mechanics', 'and', 'visual', 'characteristics.', 'higher', 'basis', 'weight', 'paper:', 'potential', 'reduction', 'in', 'tobacco', 'weight.', 'Â«more', 'rigid', 'tobacco', 'column;', 'stiffing', 'agent', 'for', 'tobacco;', 'e.g.', 'starch', '*colored', 'tow', 'and', 'cigarette', 'papers;', 'seasonal', 'promotions,', 'e.g.', 'pastel', 'colored', 'cigarettes', 'for', 'easter', 'or', 'in', 'an', 'ebony', 'and', 'ivory', 'brand', 'containing', 'a', 'mixture', 'of', 'all', 'black', '(black', 'paper', 'and', 'tow)', 'and', 'ail', 'white', 'cigarettes.', '499150498']\n",
       "Answer:  T.F. Riehl\n",
       "start_index 17\n",
       "end_index 18"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset_with_ocr[\"train\"][1]\n",
    "words = [word.lower() for word in example[\"words\"]]\n",
    "match, word_idx_start, word_idx_end = subfinder(words, example[\"answer\"].lower().split())\n",
    "print(\"Question: \", example[\"question\"])\n",
    "print(\"Words:\", words)\n",
    "print(\"Answer: \", example[\"answer\"])\n",
    "print(\"start_index\", word_idx_start)\n",
    "print(\"end_index\", word_idx_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãŸã ã—ã€ã‚µãƒ³ãƒ—ãƒ«ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã¨ã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CLS] who is in cc in this letter? [SEP] wie baw brown & williamson tobacco corporation research & development ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer(example[\"question\"], example[\"words\"], example[\"boxes\"])\n",
    "tokenizer.decode(encoding[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå…¥åŠ›å†…ã§ç­”ãˆã®ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "* `token_type_ids` ã¯ã€ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒè³ªå•ã®ä¸€éƒ¨ã§ã‚ã‚Šã€ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ–‡æ›¸ã®å˜èªã®ä¸€éƒ¨ã§ã‚ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "* `tokenizer.cls_token_id` ã¯ã€å…¥åŠ›ã®å…ˆé ­ã§ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "* `word_ids` ã¯ã€å…ƒã® `words` ã§è¦‹ã¤ã‹ã£ãŸå›ç­”ã‚’ã€å®Œå…¨ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå…¥åŠ›å†…ã®åŒã˜å›ç­”ã¨ç…§åˆã—ã¦åˆ¤æ–­ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå…¥åŠ›å†…ã®å¿œç­”ã®é–‹å§‹/çµ‚äº†ä½ç½®ã€‚\n",
    "\n",
    "ã“ã‚Œã‚’å¿µé ­ã«ç½®ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(examples, max_length=512):\n",
    "    questions = examples[\"question\"]\n",
    "    words = examples[\"words\"]\n",
    "    boxes = examples[\"boxes\"]\n",
    "    answers = examples[\"answer\"]\n",
    "\n",
    "    # encode the batch of examples and initialize the start_positions and end_positions\n",
    "    encoding = tokenizer(questions, words, boxes, max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # loop through the examples in the batch\n",
    "    for i in range(len(questions)):\n",
    "        cls_index = encoding[\"input_ids\"][i].index(tokenizer.cls_token_id)\n",
    "\n",
    "        # find the position of the answer in example's words\n",
    "        words_example = [word.lower() for word in words[i]]\n",
    "        answer = answers[i]\n",
    "        match, word_idx_start, word_idx_end = subfinder(words_example, answer.lower().split())\n",
    "\n",
    "        if match:\n",
    "            # if match is found, use `token_type_ids` to find where words start in the encoding\n",
    "            token_type_ids = encoding[\"token_type_ids\"][i]\n",
    "            token_start_index = 0\n",
    "            while token_type_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(encoding[\"input_ids\"][i]) - 1\n",
    "            while token_type_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            word_ids = encoding.word_ids(i)[token_start_index : token_end_index + 1]\n",
    "            start_position = cls_index\n",
    "            end_position = cls_index\n",
    "\n",
    "            # loop over word_ids and increase `token_start_index` until it matches the answer position in words\n",
    "            # once it matches, save the `token_start_index` as the `start_position` of the answer in the encoding\n",
    "            for id in word_ids:\n",
    "                if id == word_idx_start:\n",
    "                    start_position = token_start_index\n",
    "                else:\n",
    "                    token_start_index += 1\n",
    "\n",
    "            # similarly loop over `word_ids` starting from the end to find the `end_position` of the answer\n",
    "            for id in word_ids[::-1]:\n",
    "                if id == word_idx_end:\n",
    "                    end_position = token_end_index\n",
    "                else:\n",
    "                    token_end_index -= 1\n",
    "\n",
    "            start_positions.append(start_position)\n",
    "            end_positions.append(end_position)\n",
    "\n",
    "        else:\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "\n",
    "    encoding[\"image\"] = examples[\"image\"]\n",
    "    encoding[\"start_positions\"] = start_positions\n",
    "    encoding[\"end_positions\"] = end_positions\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®å‰å‡¦ç†é–¢æ•°ãŒå®Œæˆã—ãŸã®ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_dataset = dataset_with_ocr[\"train\"].map(\n",
    "    encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr[\"train\"].column_names\n",
    ")\n",
    "encoded_test_dataset = dataset_with_ocr[\"test\"].map(\n",
    "    encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr[\"test\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹å¾´ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ã‹ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='uint8', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'bbox': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'start_positions': Value(dtype='int64', id=None),\n",
       " 'end_positions': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–‡æ›¸ã®è³ªå•å›ç­”ã®è©•ä¾¡ã«ã¯ã€å¤§é‡ã®å¾Œå‡¦ç†ãŒå¿…è¦ã§ã™ã€‚éå‰°æ‘‚å–ã‚’é¿ã‘ã‚‹ãŸã‚ã«\n",
    "ç¾æ™‚ç‚¹ã§ã¯ã€ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—ã‚’çœç•¥ã—ã¦ã„ã¾ã™ã€‚ [Trainer](https://huggingface.co/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer) ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«è©•ä¾¡æå¤±ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã€\n",
    "ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¤ã„ã¦ã¾ã£ãŸãã‚ã‹ã‚‰ãªã„ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ½å‡ºçš„è³ªå•å¿œç­”ã¯é€šå¸¸ã€F1/å®Œå…¨ä¸€è‡´ã‚’ä½¿ç”¨ã—ã¦è©•ä¾¡ã•ã‚Œã¾ã™ã€‚\n",
    "è‡ªåˆ†ã§å®Ÿè£…ã—ãŸã„å ´åˆã¯ã€[è³ªå•å¿œç­”ã®ç« ](https://huggingface.co/course/chapter7/7?fw=pt#postprocessing) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ã‚‹ãŸã‚ã«ãƒã‚°ãƒ•ã‚§ã‚¤ã‚¹ã‚³ãƒ¼ã‚¹ã®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãŠã‚ã§ã¨ã†ï¼ã“ã®ã‚¬ã‚¤ãƒ‰ã®æœ€ã‚‚é›£ã—ã„éƒ¨åˆ†ã‚’ç„¡äº‹ã«ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã§ããŸã®ã§ã€ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯æ¬¡ã®æ‰‹é †ãŒå«ã¾ã‚Œã¾ã™ã€‚\n",
    "* å‰å‡¦ç†ã¨åŒã˜ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€[AutoModelForDocumentQuestionAnswering](https://huggingface.co/docs/transformers/main/ja/model_doc/auto#transformers.AutoModelForDocumentQuestionAnswering) ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "* [TrainingArguments](https://huggingface.co/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments) ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "* ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã“ã§ã¯ `DefaultDataCollatâ€‹â€‹or` ãŒé©åˆ‡ã«æ©Ÿèƒ½ã—ã¾ã™ã€‚\n",
    "* ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã¨ã¨ã‚‚ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã‚’ [Trainer](https://huggingface.co/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer) ã«æ¸¡ã—ã¾ã™ã€‚\n",
    "* [train()](https://huggingface.co/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train) ã‚’å‘¼ã³å‡ºã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForDocumentQuestionAnswering\n",
    "\n",
    "model = AutoModelForDocumentQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TrainingArguments](https://huggingface.co/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments) ã§ã€`output_dir` ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å ´æ‰€ã‚’æŒ‡å®šã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’æ§‹æˆã—ã¾ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã—ãŸã„å ´åˆã¯ã€`push_to_hub`ã‚’`True`ã«è¨­å®šã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€Hugging Face ã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™)ã€‚\n",
    "ã“ã®å ´åˆã€`output_dir`ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ãƒªãƒã‚¸ãƒˆãƒªã®åå‰ã«ã‚‚ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# REPLACE THIS WITH YOUR REPO ID\n",
    "repo_id = \"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_id,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=20,\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚µãƒ³ãƒ—ãƒ«ã‚’ã¾ã¨ã‚ã¦ãƒãƒƒãƒå‡¦ç†ã™ã‚‹ãŸã‚ã®å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«ã€ã™ã¹ã¦ã‚’ã¾ã¨ã‚ã¦ã€[train()](https://huggingface.co/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train) ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    processing_class=processor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— Hub ã«è¿½åŠ ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒ‡ãƒ« ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã€`push_to_hub` ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.create_model_card()\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LayoutLMv2 ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€ğŸ¤— ãƒãƒ–ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã®ã§ã€ãã‚Œã‚’æ¨è«–ã«ä½¿ç”¨ã§ãã¾ã™ã€‚ã‚‚ã£ã¨ã‚‚å˜ç´”ãª\n",
    "æ¨è«–ç”¨ã«å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™æ–¹æ³•ã¯ã€ãã‚Œã‚’ [Pipeline](https://huggingface.co/docs/transformers/main/ja/main_classes/pipelines#transformers.Pipeline) ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚\n",
    "\n",
    "ä¾‹ã‚’æŒ™ã’ã¦ã¿ã¾ã—ã‚‡ã†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is â€˜presidingâ€™ TRRF GENERAL SESSION (PART 1)?'\n",
       "['TRRF Vice President', 'lee a. waller']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"test\"][2]\n",
    "question = example[\"query\"][\"en\"]\n",
    "image = example[\"image\"]\n",
    "print(question)\n",
    "print(example[\"answers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è³ªå•ã¸ã®å›ç­”ã‚’æ–‡æ›¸åŒ–ã—ã€ç”»åƒã¨è³ªå•ã®çµ„ã¿åˆã‚ã›ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9949808120727539,\n",
       "  'answer': 'Lee A. Waller',\n",
       "  'start': 55,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"document-question-answering\", model=\"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\")\n",
    "qa_pipeline(image, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¿…è¦ã«å¿œã˜ã¦ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
    "1. ç”»åƒã¨è³ªå•ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ç”¨ã«æº–å‚™ã—ã¾ã™ã€‚\n",
    "2. ãƒ¢ãƒ‡ãƒ«ã‚’é€šã˜ã¦çµæœã¾ãŸã¯å‰å‡¦ç†ã‚’è»¢é€ã—ã¾ã™ã€‚\n",
    "3. ãƒ¢ãƒ‡ãƒ«ã¯`start_logits`ã¨`end_logits`ã‚’è¿”ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã€ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿œç­”ã®å…ˆé ­ã«ã‚ã‚‹ã®ã‹ã‚’ç¤ºã—ã€\n",
    "ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå›ç­”ã®æœ€å¾Œã«ã‚ã‚Šã¾ã™ã‹ã€‚ã©ã¡ã‚‰ã‚‚å½¢çŠ¶ (batch_sizeã€sequence_length) ã‚’æŒã¡ã¾ã™ã€‚\n",
    "4. `start_logits` ã¨ `end_logits` ã®ä¸¡æ–¹ã®æœ€å¾Œã®æ¬¡å…ƒã§ argmax ã‚’å–å¾—ã—ã€äºˆæ¸¬ã•ã‚Œã‚‹ `start_idx` ã¨ `end_idx` ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "5. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lee a. waller'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor\n",
    "from transformers import AutoModelForDocumentQuestionAnswering\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\")\n",
    "model = AutoModelForDocumentQuestionAnswering.from_pretrained(\"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoding = processor(image.convert(\"RGB\"), question, return_tensors=\"pt\")\n",
    "    outputs = model(**encoding)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    predicted_start_idx = start_logits.argmax(-1).item()\n",
    "    predicted_end_idx = end_logits.argmax(-1).item()\n",
    "\n",
    "processor.tokenizer.decode(encoding.input_ids.squeeze()[predicted_start_idx : predicted_end_idx + 1])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
