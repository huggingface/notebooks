{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dKE8SIt9C-w?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dKE8SIt9C-w?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ç”»åƒã®å€‹ã€…ã®ãƒ”ã‚¯ã‚»ãƒ«ã«ãƒ©ãƒ™ãƒ«ã¾ãŸã¯ã‚¯ãƒ©ã‚¹ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯ã„ãã¤ã‹ã®ã‚¿ã‚¤ãƒ—ãŒã‚ã‚Šã¾ã™ãŒã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®å ´åˆã€åŒã˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€æ„ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é–“ã®åŒºåˆ¥ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚ä¸¡æ–¹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«åŒã˜ãƒ©ãƒ™ãƒ«ãŒä»˜ã‘ã‚‰ã‚Œã¾ã™ (ãŸã¨ãˆã°ã€`car-1`ã¨`car-2`ã®ä»£ã‚ã‚Šã«`car`)ã€‚ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸€èˆ¬çš„ãªç¾å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯ã€æ­©è¡Œè€…ã‚„é‡è¦ãªäº¤é€šæƒ…å ±ã‚’è­˜åˆ¥ã™ã‚‹ãŸã‚ã®è‡ªå‹•é‹è»¢è»Šã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€åŒ»ç™‚ç”»åƒå†…ã®ç´°èƒã¨ç•°å¸¸ã®è­˜åˆ¥ã€è¡›æ˜Ÿç”»åƒã‹ã‚‰ã®ç’°å¢ƒå¤‰åŒ–ã®ç›£è¦–ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚\n",
    "\n",
    "1. [SceneParse150](https://huggingface.co/datasets/scene_parse_150) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® [SegFormer](https://huggingface.co/docs/transformers/main/en/model_doc/segformer#segformer) ã‚’å¾®èª¿æ•´ã—ã¾ã™ã€‚\n",
    "2. å¾®èª¿æ•´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "<Tip>\n",
    "\n",
    "ã“ã®ã‚¿ã‚¹ã‚¯ã¨äº’æ›æ€§ã®ã‚ã‚‹ã™ã¹ã¦ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€[ã‚¿ã‚¹ã‚¯ãƒšãƒ¼ã‚¸](https://huggingface.co/tasks/image-segmentation) ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "å§‹ã‚ã‚‹å‰ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "```bash\n",
    "pip install -q datasets transformers evaluate\n",
    "```\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã§ãã‚‹ã‚ˆã†ã«ã€Hugging Face ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SceneParse150 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ãšã€SceneParse150 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å°ã•ã„ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã•ã‚‰ã«æ™‚é–“ã‚’è²»ã‚„ã™å‰ã«ã€å®Ÿé¨“ã—ã¦ã™ã¹ã¦ãŒæ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹æ©Ÿä¼šãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"scene_parse_150\", split=\"train[:50]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® `train` åˆ†å‰²ã‚’ãƒˆãƒ¬ã‚¤ãƒ³ ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=0.2)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x683 at 0x7F9B0C201F90>,\n",
       " 'annotation': <PIL.PngImagePlugin.PngImageFile image mode=L size=512x683 at 0x7F9B0C201DD0>,\n",
       " 'scene_category': 368}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `image`: ã‚·ãƒ¼ãƒ³ã® PIL ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚\n",
    "- `annotation`: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ãƒãƒƒãƒ—ã® PIL ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§ã‚‚ã‚ã‚Šã¾ã™ã€‚\n",
    "- `scene_category`: \"kitchen\"ã‚„\"office\"ãªã©ã®ç”»åƒã‚·ãƒ¼ãƒ³ã‚’èª¬æ˜ã™ã‚‹ã‚«ãƒ†ã‚´ãƒª IDã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€`image`ã¨`annotation`ã®ã¿ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚ã©ã¡ã‚‰ã‚‚ PIL ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚\n",
    "\n",
    "ã¾ãŸã€ãƒ©ãƒ™ãƒ« ID ã‚’ãƒ©ãƒ™ãƒ« ã‚¯ãƒ©ã‚¹ã«ãƒãƒƒãƒ—ã™ã‚‹è¾æ›¸ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã‚Œã¯ã€å¾Œã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã™ã‚‹ã¨ãã«å½¹ç«‹ã¡ã¾ã™ã€‚ãƒãƒ–ã‹ã‚‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€`id2label` ãŠã‚ˆã³ `label2id` ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"ade20k-id2label.json\"\n",
    "id2label = json.loads(Path(hf_hub_download(repo_id, filename, repo_type=\"dataset\")).read_text())\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "num_labels = len(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€SegFormer ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ç”»åƒã¨æ³¨é‡ˆã‚’æº–å‚™ã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚ˆã†ãªä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ ã‚¯ãƒ©ã‚¹ã¨ã—ã¦ã‚¼ãƒ­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãŸã ã—ã€å®Ÿéš›ã«ã¯èƒŒæ™¯ã‚¯ãƒ©ã‚¹ã¯ 150 å€‹ã®ã‚¯ãƒ©ã‚¹ã«å«ã¾ã‚Œã¦ã„ãªã„ãŸã‚ã€`do_reduce_labels=True`ã‚’è¨­å®šã—ã¦ã™ã¹ã¦ã®ãƒ©ãƒ™ãƒ«ã‹ã‚‰ 1 ã¤ã‚’å¼•ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¼ãƒ­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ `255` ã«ç½®ãæ›ãˆã‚‰ã‚Œã‚‹ãŸã‚ã€SegFormer ã®æå¤±é–¢æ•°ã«ã‚ˆã£ã¦ç„¡è¦–ã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"nvidia/mit-b0\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint, do_reduce_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ã‚’éå­¦ç¿’ã«å¯¾ã—ã¦ã‚ˆã‚Šå …ç‰¢ã«ã™ã‚‹ãŸã‚ã«ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€[`tf.image`](https://www.tensorflow.org/api_docs/python/tf/image) ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã®è‰²ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´ã—ã¾ã™ãŒã€ä»»æ„ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ç”»åƒ\n",
    "å¥½ããªå›³æ›¸é¤¨ã€‚\n",
    "2 ã¤ã®åˆ¥ã€…ã®å¤‰æ›é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "- ç”»åƒæ‹¡å¼µã‚’å«ã‚€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿å¤‰æ›\n",
    "- ğŸ¤— Transformers ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ ãƒ“ã‚¸ãƒ§ãƒ³ ãƒ¢ãƒ‡ãƒ«ã¯ãƒãƒ£ãƒãƒ«å„ªå…ˆã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æƒ³å®šã—ã¦ã„ã‚‹ãŸã‚ã€ç”»åƒã‚’è»¢ç½®ã™ã‚‹ã ã‘ã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å¤‰æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def aug_transforms(image):\n",
    "    image = tf.keras.utils.img_to_array(image)\n",
    "    image = tf.image.random_brightness(image, 0.25)\n",
    "    image = tf.image.random_contrast(image, 0.5, 2.0)\n",
    "    image = tf.image.random_saturation(image, 0.75, 1.25)\n",
    "    image = tf.image.random_hue(image, 0.1)\n",
    "    image = tf.transpose(image, (2, 0, 1))\n",
    "    return image\n",
    "\n",
    "\n",
    "def transforms(image):\n",
    "    image = tf.keras.utils.img_to_array(image)\n",
    "    image = tf.transpose(image, (2, 0, 1))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒ¢ãƒ‡ãƒ«ã®ç”»åƒã¨æ³¨é‡ˆã®ãƒãƒƒãƒã‚’æº–å‚™ã™ã‚‹ 2 ã¤ã®å‰å‡¦ç†é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ãŒé©ç”¨ã•ã‚Œã¾ã™\n",
    "ç”»åƒå¤‰æ›ã‚’è¡Œã„ã€ä»¥å‰ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ `image_processor` ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’ `pixel_values` ã«å¤‰æ›ã—ã€\n",
    "`labels`ã¸ã®æ³¨é‡ˆã€‚ `ImageProcessor` ã¯ã€ç”»åƒã®ã‚µã‚¤ã‚ºå¤‰æ›´ã¨æ­£è¦åŒ–ã‚‚å‡¦ç†ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transforms(example_batch):\n",
    "    images = [aug_transforms(x.convert(\"RGB\")) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [transforms(x.convert(\"RGB\")) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«å‰å‡¦ç†å¤‰æ›ã‚’é©ç”¨ã™ã‚‹ã«ã¯ã€ğŸ¤— Datasets `set_transform` é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "å¤‰æ›ã¯ã‚ªãƒ³ã‚¶ãƒ•ãƒ©ã‚¤ã§é©ç”¨ã•ã‚Œã‚‹ãŸã‚ã€é«˜é€Ÿã§æ¶ˆè²»ã™ã‚‹ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒå°‘ãªããªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚ã‚‹ã¨ã€å¤šãã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚ ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã€è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã™ã°ã‚„ããƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€[Mean Intersection over Union](https://huggingface.co/spaces/evaluate-metric/accuracy) (IoU) ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ (ğŸ¤— Evaluate [ã‚¯ã‚¤ãƒƒã‚¯ ãƒ„ã‚¢ãƒ¼](https://huggingface.co/docs/evaluate/a_quick_tour) ã‚’å‚ç…§ã—ã¦ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¨ˆç®—ã™ã‚‹æ–¹æ³•ã®è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ `compute` ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚äºˆæ¸¬ã‚’æ¬¡ã®ã‚ˆã†ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™\n",
    "æœ€åˆã«ãƒ­ã‚¸ãƒƒãƒˆã‚’ä½œæˆã—ã€æ¬¡ã« `compute` ã‚’å‘¼ã³å‡ºã™å‰ã«ãƒ©ãƒ™ãƒ«ã®ã‚µã‚¤ã‚ºã«ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«å†å½¢æˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = tf.transpose(logits, perm=[0, 2, 3, 1])\n",
    "    logits_resized = tf.image.resize(\n",
    "        logits,\n",
    "        size=tf.shape(labels)[1:],\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "\n",
    "    pred_labels = tf.argmax(logits_resized, axis=-1)\n",
    "    metrics = metric.compute(\n",
    "        predictions=pred_labels,\n",
    "        references=labels,\n",
    "        num_labels=num_labels,\n",
    "        ignore_index=-1,\n",
    "        reduce_labels=image_processor.do_reduce_labels,\n",
    "    )\n",
    "\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "    return {\"val_\" + k: v for k, v in metrics.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§`compute_metrics`é–¢æ•°ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã¨ãã«ã“ã®é–¢æ•°ã«æˆ»ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "Keras ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã¾ãš [åŸºæœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/main/ja/tasks/./training#train-a-tensorflow-model-with-keras) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "</Tip>\n",
    "\n",
    "TensorFlow ã§ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã«ã¯ã€æ¬¡ã®æ‰‹é †ã«å¾“ã„ã¾ã™ã€‚\n",
    "1. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "2. äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚\n",
    "3. ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ `tf.data.Dataset` ã«å¤‰æ›ã—ã¾ã™ã€‚\n",
    "4. ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¾ã™ã€‚\n",
    "5. ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ ã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™\n",
    "6. `fit()` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "ã¾ãšã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã€å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 2\n",
    "num_epochs = 50\n",
    "num_train_steps = len(train_ds) * num_epochs\n",
    "learning_rate = 6e-5\n",
    "weight_decay_rate = 0.01\n",
    "\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒ©ãƒ™ãƒ« ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã¨ã‚‚ã« [TFAutoModelForSemanticSegmentation](https://huggingface.co/docs/transformers/main/ja/model_doc/auto#transformers.TFAutoModelForSemanticSegmentation) ã‚’ä½¿ç”¨ã—ã¦ SegFormer ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ãã‚Œã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¾ã™ã€‚\n",
    "ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã€‚ Transformers ãƒ¢ãƒ‡ãƒ«ã«ã¯ã™ã¹ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ã‚¹ã‚¯é–¢é€£ã®æå¤±é–¢æ•°ãŒã‚ã‚‹ãŸã‚ã€æ¬¡ã®å ´åˆã‚’é™¤ãã€æå¤±é–¢æ•°ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ã¯ãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSemanticSegmentation\n",
    "\n",
    "model = TFAutoModelForSemanticSegmentation.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "model.compile(optimizer=optimizer)  # No loss argument!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_tf_dataset` ã¨ `DefaultDataCollatâ€‹â€‹or` ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ `tf.data.Dataset` å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = train_ds.to_tf_dataset(\n",
    "    columns=[\"pixel_values\", \"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = test_ds.to_tf_dataset(\n",
    "    columns=[\"pixel_values\", \"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "äºˆæ¸¬ã‹ã‚‰ç²¾åº¦ã‚’è¨ˆç®—ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã«ã¯ã€[Keras callbacks](https://huggingface.co/docs/transformers/main/ja/tasks/../main_classes/keras_callbacks) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "`compute_metrics` é–¢æ•°ã‚’ [KerasMetricCallback](https://huggingface.co/docs/transformers/main/ja/main_classes/keras_callbacks#transformers.KerasMetricCallback) ã«æ¸¡ã—ã¾ã™ã€‚\n",
    "ãã—ã¦ [PushToHubCallback](https://huggingface.co/docs/transformers/main/ja/main_classes/keras_callbacks#transformers.PushToHubCallback) ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=compute_metrics, eval_dataset=tf_eval_dataset, batch_size=batch_size, label_cols=[\"labels\"]\n",
    ")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(output_dir=\"scene_segmentation\", tokenizer=image_processor)\n",
    "\n",
    "callbacks = [metric_callback, push_to_hub_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¤ã„ã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã‚¨ãƒãƒƒã‚¯æ•°ã€\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    callbacks=callbacks,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãŠã‚ã§ã¨ã†ï¼ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€ğŸ¤— Hub ã§å…±æœ‰ã—ã¾ã—ãŸã€‚ã“ã‚Œã§æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸã®ã§ã€ãã‚Œã‚’æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚\n",
    "\n",
    "æ¨è«–ã®ãŸã‚ã«ç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ds[0][\"image\"]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-image.png\" alt=\"Image of bedroom\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”»åƒã‚’å‰å‡¦ç†ã—ã€å…¥åŠ›ã‚’ TensorFlow ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"MariaK/scene_segmentation\")\n",
    "inputs = image_processor(image, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã€`logits`ã‚’è¿”ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSemanticSegmentation\n",
    "\n",
    "model = TFAutoModelForSemanticSegmentation.from_pretrained(\"MariaK/scene_segmentation\")\n",
    "logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒ­ã‚¸ãƒƒãƒˆã‚’å…ƒã®ç”»åƒã‚µã‚¤ã‚ºã«å†ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€ã‚¯ãƒ©ã‚¹æ¬¡å…ƒã« argmax ã‚’é©ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.transpose(logits, [0, 2, 3, 1])\n",
    "\n",
    "upsampled_logits = tf.image.resize(\n",
    "    logits,\n",
    "    # We reverse the shape of `image` because `image.size` returns width and height.\n",
    "    image.size[::-1],\n",
    ")\n",
    "\n",
    "pred_seg = tf.math.argmax(upsampled_logits, axis=-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çµæœã‚’è¦–è¦šåŒ–ã™ã‚‹ã«ã¯ã€[ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã‚«ãƒ©ãƒ¼ ãƒ‘ãƒ¬ãƒƒãƒˆ](https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51) ã‚’ã€ãã‚Œãã‚Œã‚’ãƒãƒƒãƒ—ã™ã‚‹ `ade_palette()` ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¹ã‚’ RGB å€¤ã«å¤‰æ›ã—ã¾ã™ã€‚æ¬¡ã«ã€ç”»åƒã¨äºˆæ¸¬ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ãƒãƒƒãƒ—ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ—ãƒ­ãƒƒãƒˆã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "color_seg = np.zeros((pred_seg.shape[0], pred_seg.shape[1], 3), dtype=np.uint8)\n",
    "palette = np.array(ade_palette())\n",
    "for label, color in enumerate(palette):\n",
    "    color_seg[pred_seg == label, :] = color\n",
    "color_seg = color_seg[..., ::-1]  # convert to BGR\n",
    "\n",
    "img = np.array(image) * 0.5 + color_seg * 0.5  # plot the image with the segmentation map\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-preds.png\" alt=\"Image of bedroom overlaid with segmentation map\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
