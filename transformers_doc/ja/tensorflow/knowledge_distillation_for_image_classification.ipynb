{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çŸ¥è­˜ã®è’¸ç•™ã¯ã€ã‚ˆã‚Šå¤§è¦æ¨¡ã§è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ« (æ•™å¸«) ã‹ã‚‰ã‚ˆã‚Šå°è¦æ¨¡ã§å˜ç´”ãªãƒ¢ãƒ‡ãƒ« (ç”Ÿå¾’) ã«çŸ¥è­˜ã‚’ä¼é”ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹æ‰‹æ³•ã§ã™ã€‚ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã«çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ã«ã¯ã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ (ã“ã®å ´åˆã¯ç”»åƒåˆ†é¡) ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€ç”»åƒåˆ†é¡ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã‚‹ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã—ã¾ã™ã€‚æ¬¡ã«ã€å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€ãã®å‡ºåŠ›ã¨æ•™å¸«ã®å‡ºåŠ›ã®å·®ã‚’æœ€å°é™ã«æŠ‘ãˆã€å‹•ä½œã‚’æ¨¡å€£ã—ã¾ã™ã€‚ã“ã‚Œã¯ [Distilling the Knowledge in a Neural Network by Hinton et al](https://huggingface.co/papers/1503.02531) ã§æœ€åˆã«å°å…¥ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®çŸ¥è­˜ã®è’¸ç•™ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã«ã¯ [Beans ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://huggingface.co/datasets/beans) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€[å¾®èª¿æ•´ã•ã‚ŒãŸ ViT ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/merve/vit-mobilenet-beans-224) (æ•™å¸«ãƒ¢ãƒ‡ãƒ«) ã‚’æŠ½å‡ºã—ã¦ [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224) (å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«) ğŸ¤— Transformers ã® [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "è’¸ç•™ã¨ãƒ—ãƒ­ã‚»ã‚¹ã®è©•ä¾¡ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "```bash\n",
    "pip install transformers datasets accelerate tensorboard evaluate --upgrade\n",
    "```\n",
    "\n",
    "ã“ã®ä¾‹ã§ã¯ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦`merve/beans-vit-224`ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€Bean ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åŸºã¥ã„ã¦å¾®èª¿æ•´ã•ã‚ŒãŸ`google/vit-base-patch16-224-in21k`ã«åŸºã¥ãç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸ MobileNetV2 ã«æŠ½å‡ºã—ã¾ã™ã€‚\n",
    "\n",
    "æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"beans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®å ´åˆã€åŒã˜è§£åƒåº¦ã§åŒã˜å‡ºåŠ›ãŒè¿”ã•ã‚Œã‚‹ãŸã‚ã€ã©ã¡ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚ `dataset`ã®`map()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã™ã¹ã¦ã®åˆ†å‰²ã«å‰å‡¦ç†ã‚’é©ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "teacher_processor = AutoImageProcessor.from_pretrained(\"merve/beans-vit-224\")\n",
    "\n",
    "def process(examples):\n",
    "    processed_inputs = teacher_processor(examples[\"image\"])\n",
    "    return processed_inputs\n",
    "\n",
    "processed_datasets = dataset.map(process, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŸºæœ¬çš„ã«ã€æˆ‘ã€…ã¯ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸMobileNetï¼‰ãŒæ•™å¸«ãƒ¢ãƒ‡ãƒ«ï¼ˆå¾®èª¿æ•´ã•ã‚ŒãŸãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›å™¨ï¼‰ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã‚’æœ›ã‚€ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã¾ãšæ•™å¸«ã¨ç”Ÿå¾’ã‹ã‚‰ãƒ­ã‚¸ãƒƒãƒˆå‡ºåŠ›ã‚’å¾—ã‚‹ã€‚æ¬¡ã«ã€ãã‚Œãã‚Œã®ã‚½ãƒ•ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é‡è¦åº¦ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿`temperature`ã§åˆ†å‰²ã™ã‚‹ã€‚`lambda`ã¨å‘¼ã°ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯è’¸ç•™ãƒ­ã‚¹ã®é‡è¦åº¦ã‚’é‡ã‚‹ã€‚ã“ã®ä¾‹ã§ã¯ã€`temperature=5`ã€`lambda=0.5`ã¨ã™ã‚‹ã€‚ç”Ÿå¾’ã¨æ•™å¸«ã®é–“ã®ç™ºæ•£ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«ã€Kullback-Leiblerç™ºæ•£æå¤±ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚2ã¤ã®ãƒ‡ãƒ¼ã‚¿Pã¨QãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯Qã‚’ä½¿ã£ã¦Pã‚’è¡¨ç¾ã™ã‚‹ãŸã‚ã«ã©ã‚Œã ã‘ã®ä½™åˆ†ãªæƒ…å ±ãŒå¿…è¦ã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚ã‚‚ã—2ã¤ãŒåŒã˜ã§ã‚ã‚Œã°ã€Qã‹ã‚‰Pã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«å¿…è¦ãªä»–ã®æƒ…å ±ã¯ãªã„ã®ã§ã€ãã‚Œã‚‰ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã‚¼ãƒ­ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ImageDistilTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.teacher.to(device)\n",
    "        self.teacher.eval()\n",
    "        self.temperature = temperature\n",
    "        self.lambda_param = lambda_param\n",
    "\n",
    "    def compute_loss(self, student, inputs, return_outputs=False):\n",
    "        student_output = self.student(**inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          teacher_output = self.teacher(**inputs)\n",
    "\n",
    "        # Compute soft targets for teacher and student\n",
    "        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n",
    "        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n",
    "\n",
    "        # Compute the loss\n",
    "        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n",
    "\n",
    "        # Compute the true label loss\n",
    "        student_target_loss = student_output.loss\n",
    "\n",
    "        # Calculate final loss\n",
    "        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss\n",
    "        return (loss, student_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€Hugging Face Hub ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã€`trainer`ã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ Hugging Face Hub ã«ãƒ—ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹`TrainingArguments`ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my-awesome-model\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id=repo_name,\n",
    "    )\n",
    "\n",
    "num_labels = len(processed_datasets[\"train\"].features[\"labels\"].names)\n",
    "\n",
    "# initialize models\n",
    "teacher_model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"merve/beans-vit-224\",\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# training MobileNetV2 from scratch\n",
    "student_config = MobileNetV2Config()\n",
    "student_config.num_labels = num_labels\n",
    "student_model = MobileNetV2ForImageClassification(student_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_metrics` é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã§ãã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®`accuracy`ã¨`f1`ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))\n",
    "    return {\"accuracy\": acc[\"accuracy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šç¾©ã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦`Trainer`ã‚’åˆæœŸåŒ–ã—ã¾ã—ã‚‡ã†ã€‚ãƒ‡ãƒ¼ã‚¿ç…§åˆè£…ç½®ã‚‚åˆæœŸåŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "trainer = ImageDistilTrainer(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    training_args=training_args,\n",
    "    train_dataset=processed_datasets[\"train\"],\n",
    "    eval_dataset=processed_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=teacher_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    temperature=5,\n",
    "    lambda_param=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(processed_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã¯ 72% ã«é”ã—ã¾ã™ã€‚è’¸ç•™åŠ¹ç‡ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ãŸã‚ã«ã€åŒã˜ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ Bean ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ MobileNet ã‚’æœ€åˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ 63% ã®ç²¾åº¦ã‚’è¦³å¯Ÿã—ã¾ã—ãŸã€‚èª­è€…ã®çš†æ§˜ã«ã¯ã€ã•ã¾ã–ã¾ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã€å­¦ç”Ÿã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€è’¸ç•™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è©¦ã—ã¦ã„ãŸã ãã€ãã®çµæœã‚’å ±å‘Šã—ã¦ã„ãŸã ãã‚ˆã†ãŠå‹§ã‚ã—ã¾ã™ã€‚æŠ½å‡ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ­ã‚°ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ [ã“ã®ãƒªãƒã‚¸ãƒˆãƒª](https://huggingface.co/merve/vit-mobilenet-beans-224) ã«ã‚ã‚Šã€æœ€åˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ MobileNetV2 ã¯ã“ã® [ãƒªãƒã‚¸ãƒˆãƒª](https://huggingface.co/merve/resnet-mobilenet-beans-5)ã€‚"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
