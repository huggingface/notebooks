# Hugging Face Transformers Amazon SageMaker Examples

Example Jupyter notebooks that demonstrate how to build, train, and deploy [Hugging Face Transformers](https://github.com/huggingface/transformers) using [Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) and the [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/).


## üõ†Ô∏è Setup


The quickest setup to run example notebooks includes:
- An [AWS account](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-account.html)
- Proper [IAM User and Role](http://docs.aws.amazon.com/sagemaker/latest/dg/authentication-and-access-control.html) setup
- An [Amazon SageMaker Notebook Instance](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)
- An [S3 bucket](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-config-permissions.html)

## üìì Examples

| Notebook                                                                                                                                                                               | Type      | Description                                                                                                                                                                                                                |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [01 Getting started with PyTorch](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb)                                    | Training  | Getting started end-to-end example on how to fine-tune a pre-trained Hugging Face Transformer for Text-Classification using PyTorch                                                                                        |
| [02 getting started with TensorFlow](https://github.com/huggingface/notebooks/blob/main/sagemaker/02_getting_started_tensorflow/sagemaker-notebook.ipynb)                              | Training  | Getting started end-to-end example on how to fine-tune a pre-trained Hugging Face Transformer for Text-Classification using TensorFlow                                                                                     |
| [03 Distributed Training: Data Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb)            | Training  | End-to-end example on how to use distributed training with data-parallelism strategy for fine-tuning a pre-trained Hugging Face Transformer for Question-Answering using Amazon SageMaker Data Parallelism                 |
| [04 Distributed Training: Model Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb)          | Training  | End-to-end example on how to use distributed training with model-parallelism strategy to pre-trained Hugging Face Transformer using Amazon SageMaker Model Parallelism                                                     |
| [05 How to use Spot Instances & Checkpointing](https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb)                                | Training  | End-to-end example on how to use Spot Instances and Checkpointing to reduce training cost                                                                                                                                  |
| [06 Experiment Tracking with SageMaker Metrics](https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb)                            | Training  | End-to-end example on how to use SageMaker metrics to track your experiments and training jobs                                                                                                                             |
| [07 Distributed Training: Data Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb) | Training  | End-to-end example on how to use Amazon SageMaker Data Parallelism with TensorFlow                                                                                                                                         |
| [08 Distributed Training: Summarization with T5/BART](https://github.com/huggingface/notebooks/blob/main/sagemaker/08_distributed_summarization_bart_t5/sagemaker-notebook.ipynb)      | Training  | End-to-end example on how to fine-tune BART/T5 for Summarization using Amazon SageMaker Data Parallelism                                                                                                                   |
| [09 Vision: Fine-tune ViT](https://github.com/huggingface/notebooks/blob/main/sagemaker/09_image_classification_vision_transformer/sagemaker-notebook.ipynb)                           | Training  | End-to-end example on how to fine-tune Vision Transformer for Image-Classification                                                                                                                                         |
| [10 Deploy HF Transformer from Amazon S3](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)                 | Inference | End-to-end example on how to deploy a model from Amazon S3                                                                                                                                                                 |
| [11 Deploy HF Transformer from Hugging Face Hub](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)  | Inference | End-to-end example on how to deploy a model from the Hugging Face Hub                                                                                                                                                      |
| [12 Batch Processing with Amazon SageMaker Batch Transform](https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb)        | Inference | End-to-end example on how to do batch processing with Amazon SageMaker Batch Transform                                                                                                                                     |
| [13 Autoscaling SageMaker Endpoints](https://github.com/huggingface/notebooks/blob/main/sagemaker/13_deploy_and_autoscaling_transformers/sagemaker-notebook.ipynb)                     | Inference | End-to-end example on how to use autoscaling for a HF Endpoint                                                                                                                                                             |
| [14 Fine-tune and push to Hub](https://github.com/huggingface/notebooks/blob/main/sagemaker/14_train_and_push_to_hub/sagemaker-notebook.ipynb)                                         | Training  | End-to-end example on how to use the Hugging Face Hub as MLOps backend for saving checkpoints during training                                                                                                              |
| [15 Training Compiler](https://github.com/huggingface/notebooks/blob/main/sagemaker/15_training_compiler/sagemaker-notebook.ipynb)                                                     | Training  | End-to-end example on how to use Amazon SageMaker Training Compiler to speed up training time                                                                                                                              |
| [16 Asynchronous Inference](https://github.com/huggingface/notebooks/blob/main/sagemaker/16_async_inference_hf_hub/sagemaker-notebook.ipynb)                                           | Inference | End-to-end example on how to use Amazon SageMaker Asynchronous Inference endpoints with Hugging Face Transformers                                                                                                          |
| [17 Custom inference.py script](https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb)                                      | Inference | End-to-end example on how to create a custom inference.py for Sentence Transformers and sentence embeddings                                                                                                                |
| [18 AWS Inferentia](https://github.com/huggingface/notebooks/blob/main/sagemaker/18_inferentia_inference/sagemaker-notebook.ipynb)                                                     | Inference | End-to-end example on how to AWS Inferentia to speed up inference time                                                                                                                                                     |
| [19 Serverless Inference](https://github.com/huggingface/notebooks/blob/main/sagemaker/19_serverless_inference/sagemaker-notebook.ipynb)                                               | Inference | Serverless Inference example to save cost                                                                                                                                                                                  |
| [20 Automatic Speech Recognition](https://github.com/huggingface/notebooks/blob/main/sagemaker/20_automatic_speech_recognition_inference/sagemaker-notebook.ipynb)                     | Inference | Example how to do speech recognition with wav2vec2                                                                                                                                                                         |
| [21 Image Segmentation](https://github.com/huggingface/notebooks/blob/main/sagemaker/21_image_segmantation/sagemaker-notebook.ipynb)                                                   | Inference | Example how to do image segmentation with segformer                                                                                                                                                                        |
| [22 Accelerate AWS SageMaker Integration examples](https://github.com/huggingface/notebooks/blob/main/sagemaker/22_accelerate_sagemaker_examples/README.md)                            | Training  | End-to-end examples on how to use AWS SageMaker integration of Accelerate                                                                                                                                                  |
| [23 Stable Diffusion](https://github.com/huggingface/notebooks/blob/main/sagemaker/23_stable_diffusion_inference/sagemaker-notebook.ipynb)                                             | Inference | Example how to generate images with stable diffusion                                                                                                                                                                       |
| [24 Train BLOOM with PEFT](https://github.com/huggingface/notebooks/blob/main/sagemaker/24_train_bloom_peft_lora/sagemaker-notebook.ipynb)                                             | Training  | Example how to train BLOOM on a single GPU using PEFT & LoRA                                                                                                                                                               |
| [25 PyTorch FSDP model parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/25_pytorch_fsdp_model_parallelism/sagemaker-notebook.ipynb)                           | Training  | Example how to train LLMs on multi-node multi GPU with PyTorch FSDP                                                                                                                                                        |
| [26 Document AI Donut](https://github.com/huggingface/notebooks/blob/main/sagemaker/26_document_ai_donut/sagemaker-notebook.ipynb)                                                     | Training  | In this tutorial, you will learn how to fine-tune and deploy [Donut-base](https://huggingface.co/naver-clova-ix/donut-base) for document-understand/document-parsing using Hugging Face Transformers and Amazon SageMaker. |
| [27 Deploy Large Language Models](https://github.com/huggingface/notebooks/blob/main/sagemaker/27_deploy_large_language_models/sagemaker-notebook.ipynb)                               | Inference | Learn how to deploy LLMs with the Hugging Face LLM DLC                                                                                                                                                                     |
| [28 Train LLMs with QLora](https://github.com/huggingface/notebooks/blob/main/notebooks/sagemaker/28_train_llms_with_qlora/sagemaker-notebook.ipynb)                                   | Training  | Example on how to fine-tune LLMs using Q-Lora                                                                                                                                                                              |
| [29 Deploy LLMs with Inferentia2](https://github.com/huggingface/notebooks/blob/main/notebooks/sagemaker/29_deploy_llms_on_inferentia2/sagemaker-notebook.ipynb)                       | Inference | Learn how to deploy LLMs using AWS Inferentia2                                                                                                                                                                             |
| [30 Evaluate LLMs with ligtheval](https://github.com/huggingface/notebooks/blob/main/notebooks/sagemaker/30_evaluate_llms_with_lighteval/sagemaker-notebook.ipynb)                     | Inference | Learn how to evaluate LLMs using Hugging Face LightEval                                                                                                                                                                    |
| [31 Deploy Embedding Models with TEI](https://github.com/huggingface/notebooks/blob/main/notebooks/sagemaker/31_deploy_embedding_models/sagemaker-notebook.ipynb)                      | Inference | Learn how to deploy Embedding models for RAG applications with Hugging Face TEI                                                                                                                                            |
| [32 Train and deploy Embedding Models](https://github.com/huggingface/notebooks/blob/main/notebooks/sagemaker/32_train_deploy_embedding_models/sagemaker-notebook.ipynb)                      | Train & Inference | Learn how to train and deploy embedding models with Sentence Transformers and TEI                                                                                                                                            |